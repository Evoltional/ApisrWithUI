import collections
import json
import os
import shutil
import subprocess
import sys
import tempfile
import threading
import time
import tkinter as tk
import warnings
from datetime import datetime
from pathlib import Path
from tkinter import ttk, filedialog, messagebox
from tkinter.scrolledtext import ScrolledText

import cv2
import imagehash
import numpy as np
import torch
from PIL import Image
from skimage.metrics import structural_similarity as ssim

warnings.filterwarnings('ignore')

# æ·»åŠ APISRé¡¹ç›®è·¯å¾„
sys.path.append('.')

# ç›´æ¥ä»architectureå¯¼å…¥æ¨¡å‹
try:
    from architecture.rrdb import RRDBNet
    from architecture.grl import GRL
    from architecture.dat import DAT
    from architecture.cunet import UNet_Full
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å‹æ¶æ„æ—¶å‡ºé”™: {e}")
    print("è¯·ç¡®ä¿architectureæ¨¡å—åœ¨Pythonè·¯å¾„ä¸­")
    sys.exit(1)

from moviepy import VideoFileClip
from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter


class ModernButton(ttk.Button):
    """ç°ä»£åŒ–æŒ‰é’®æ ·å¼"""

    def __init__(self, master=None, **kwargs):
        super().__init__(master, **kwargs)
        self.configure(style='Accent.TButton')


class APISRVideoProcessor:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("APISR è§†é¢‘è¶…åˆ†è¾¨ç‡å¤„ç†å·¥å…·")
        self.root.geometry("1200x800")

        # è®¾ç½®çª—å£å›¾æ ‡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        try:
            self.root.iconbitmap('icon.ico')
        except:
            pass

        # è®¾ç½®ä¸»é¢˜é¢œè‰²
        self.bg_color = "#f5f5f7"
        self.sidebar_color = "#2c3e50"
        self.accent_color = "#3498db"
        self.success_color = "#27ae60"
        self.warning_color = "#f39c12"
        self.danger_color = "#e74c3c"

        # é…ç½®æ–‡ä»¶è·¯å¾„
        self.config_file = "apisr_config.json"

        # åˆå§‹åŒ–å˜é‡
        self.input_paths = []  # æ”¹ä¸ºå­˜å‚¨å¤šä¸ªè§†é¢‘è·¯å¾„çš„åˆ—è¡¨
        self.output_dir = tk.StringVar()
        self.model_var = tk.StringVar(value="GRL")
        self.scale_var = tk.StringVar(value="4")
        self.segment_duration = tk.StringVar(value="20")
        self.downsample_threshold = tk.StringVar(value="720")
        self.float16_var = tk.BooleanVar(value=False)
        self.crop_for_4x_var = tk.BooleanVar(value=True)
        self.hash_threshold_var = tk.StringVar(value="3")
        self.ssim_threshold_var = tk.StringVar(value="0.98")
        self.enable_dup_detect_var = tk.BooleanVar(value=True)
        self.use_ssim_var = tk.BooleanVar(value=True)
        self.use_hash_var = tk.BooleanVar(value=True)
        self.test_mode_var = tk.BooleanVar(value=False)
        self.enable_history_var = tk.BooleanVar(value=True)
        self.history_size_var = tk.StringVar(value="20")  # é»˜è®¤å€¼æ”¹ä¸º20
        self.immediate_merge_var = tk.BooleanVar(value=False)  # æ–°å¢ï¼šç«‹å³åˆæˆè§†é¢‘é€‰é¡¹
        self.video_encoder_mode = tk.StringVar(value="auto")  # æ–°å¢ï¼šè§†é¢‘ç¼–ç å™¨æ¨¡å¼
        self.last_test_mode_state = False  # è®°å½•ä¸Šä¸€æ¬¡çš„æµ‹è¯•æ¨¡å¼çŠ¶æ€

        # è®¾ç½®æ ·å¼
        self.setup_styles()

        # æ¨¡å‹ä¿¡æ¯
        self.models = {
            "GRL": {"scale": [4], "weight": "pretrained/4x_APISR_GRL_GAN_generator.pth"},
            "DAT": {"scale": [4], "weight": "pretrained/4x_APISR_DAT_GAN_generator.pth"},
            "RRDB": {"scale": [2, 4], "weight": {
                "2": "pretrained/2x_APISR_RRDB_GAN_generator.pth",
                "4": "pretrained/4x_APISR_RRDB_GAN_generator.pth"
            }},
            "CUNET": {"scale": [4], "weight": "pretrained/4x_APISR_CUNET_GAN_generator.pth"}
        }

        # å¤„ç†å™¨çŠ¶æ€
        self.processing = False
        self.paused = False
        self.stopped = False
        self.generator = None
        self.weight_dtype = torch.float32

        # è¿›åº¦æ¢å¤ç›¸å…³
        self.current_video_index = 0  # æ–°å¢ï¼šå½“å‰å¤„ç†è§†é¢‘ç´¢å¼•
        self.current_segment_index = 0
        self.current_frame_in_segment = 0
        self.total_segments = 0
        self.segments = []
        self.processed_segments = []

        # é‡å¤å¸§æ£€æµ‹ç›¸å…³
        self.dup_frame_count = 0

        # æ–°å¢ï¼šå†å²å¸§ç¼“å­˜ç³»ç»Ÿ
        self.init_history_cache()

        # ä¸´æ—¶æ–‡ä»¶è·¯å¾„
        self.temp_base_dir = None
        self.current_segment_frames_dir = None
        self.video_base_name = None
        self.is_test_mode_folder = False  # æ–°å¢ï¼šæ ‡è®°æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼æ–‡ä»¶å¤¹

        # çº¿ç¨‹æ§åˆ¶
        self.processing_thread = None
        self.pause_event = threading.Event()
        self.stop_event = threading.Event()
        self.processing_lock = threading.Lock()

        # æ–°å¢ï¼šæš‚åœæ—¶çš„å†…å­˜ä¼˜åŒ–
        self.pause_lock = threading.Lock()
        self.pause_cv = threading.Condition(self.pause_lock)
        self.should_sleep = False

        # æ–°å¢ï¼šå†…å­˜ç›‘æ§
        self.monitor_thread = None
        self.memory_check_interval = 30  # 30ç§’æ£€æŸ¥ä¸€æ¬¡å†…å­˜

        # è®¾ç½®å†å²å¸§æ•°é‡éªŒè¯
        self.setup_history_size_validation()

        self.setup_ui()

        # è®¾ç½®åˆå§‹æ¨¡å‹
        self.on_model_change()

        # åŠ è½½é…ç½®æ–‡ä»¶
        self.load_config()

        # ç»‘å®šé…ç½®ä¿å­˜äº‹ä»¶
        self.setup_config_save_bindings()

        # è·Ÿè¸ªæµ‹è¯•æ¨¡å¼å˜åŒ–
        self.test_mode_var.trace('w', self.on_test_mode_changed)

    def on_test_mode_changed(self, *args):
        """æµ‹è¯•æ¨¡å¼å˜åŒ–æ—¶çš„å¤„ç†"""
        current_state = self.test_mode_var.get()

        # å¦‚æœä»éæµ‹è¯•æ¨¡å¼åˆ‡æ¢åˆ°æµ‹è¯•æ¨¡å¼
        if current_state and not self.last_test_mode_state:
            # å¼¹å‡ºç¡®è®¤çª—å£
            response = messagebox.askyesno("ç¡®è®¤æµ‹è¯•æ¨¡å¼",
                                           "æµ‹è¯•æ¨¡å¼ä»…è¿›è¡Œé‡å¤å¸§æ£€æµ‹ï¼Œä¸è¿›è¡Œè¶…åˆ†è¾¨ç‡å¤„ç†ï¼Œä¸”ä¼šåˆ›å»ºå•ç‹¬çš„æµ‹è¯•æ–‡ä»¶å¤¹ã€‚\n\n"
                                           "æ˜¯å¦ç¡®è®¤å¯ç”¨æµ‹è¯•æ¨¡å¼ï¼Ÿ")

            if not response:
                # ç”¨æˆ·å–æ¶ˆï¼Œæ¢å¤åŸæ¥çš„çŠ¶æ€
                self.test_mode_var.set(False)
                return
            else:
                self.log("æµ‹è¯•æ¨¡å¼å·²å¯ç”¨ - ä»…è¿›è¡Œé‡å¤å¸§æ£€æµ‹ï¼Œä¸è¿›è¡Œè¶…åˆ†è¾¨ç‡å¤„ç†")

        # å¦‚æœä»æµ‹è¯•æ¨¡å¼åˆ‡æ¢åˆ°éæµ‹è¯•æ¨¡å¼
        elif not current_state and self.last_test_mode_state:
            response = messagebox.askyesno("é€€å‡ºæµ‹è¯•æ¨¡å¼",
                                           "é€€å‡ºæµ‹è¯•æ¨¡å¼å°†åˆ é™¤æµ‹è¯•æ¨¡å¼äº§ç”Ÿçš„ä¸´æ—¶æ–‡ä»¶ã€‚\n\n"
                                           "æ˜¯å¦ç¡®è®¤é€€å‡ºæµ‹è¯•æ¨¡å¼ï¼Ÿ")

            if response:
                # æ¸…ç†æµ‹è¯•æ¨¡å¼çš„ä¸´æ—¶æ–‡ä»¶
                self.cleanup_test_mode_files()
                self.log("å·²é€€å‡ºæµ‹è¯•æ¨¡å¼ï¼Œæµ‹è¯•æ–‡ä»¶å·²æ¸…ç†")
            else:
                # ç”¨æˆ·å–æ¶ˆï¼Œæ¢å¤æµ‹è¯•æ¨¡å¼
                self.test_mode_var.set(True)
                return

        # æ›´æ–°çŠ¶æ€è®°å½•
        self.last_test_mode_state = current_state

        # è‡ªåŠ¨ä¿å­˜é…ç½®
        self.save_config()

    def cleanup_test_mode_files(self):
        """æ¸…ç†æµ‹è¯•æ¨¡å¼äº§ç”Ÿçš„ä¸´æ—¶æ–‡ä»¶"""
        output_dir = self.output_dir.get()
        if not output_dir or not os.path.exists(output_dir):
            return

        # æŸ¥æ‰¾æ‰€æœ‰æµ‹è¯•æ¨¡å¼çš„ä¸´æ—¶ç›®å½•
        test_temp_dirs = []
        for item in os.listdir(output_dir):
            item_path = os.path.join(output_dir, item)
            if os.path.isdir(item_path) and item.endswith("_test_temp"):
                test_temp_dirs.append(item_path)

        if test_temp_dirs:
            self.log(f"æ‰¾åˆ° {len(test_temp_dirs)} ä¸ªæµ‹è¯•æ¨¡å¼ä¸´æ—¶ç›®å½•")
            for temp_dir in test_temp_dirs:
                try:
                    shutil.rmtree(temp_dir)
                    self.log(f"å·²æ¸…ç†æµ‹è¯•ä¸´æ—¶ç›®å½•: {os.path.basename(temp_dir)}")
                except Exception as e:
                    self.log(f"æ¸…ç†æµ‹è¯•ä¸´æ—¶ç›®å½•æ—¶å‡ºé”™: {e}")

    def setup_history_size_validation(self):
        """è®¾ç½®å†å²å¸§æ•°é‡è¾“å…¥çš„éªŒè¯ - ä¿®æ”¹ï¼šç§»é™¤åŸæ¥çš„traceéªŒè¯ï¼Œæ”¹ä¸ºç„¦ç‚¹ç¦»å¼€æ—¶è°ƒæ•´"""

        # åˆ›å»ºéªŒè¯å‡½æ•°ï¼Œç¡®ä¿åªèƒ½è¾“å…¥æ•´æ•°
        def validate_integer_input(action, value_if_allowed):
            if action == '1':  # æ’å…¥æ“ä½œ
                if value_if_allowed == '':
                    return True
                try:
                    int(value_if_allowed)
                    return True
                except ValueError:
                    return False
            return True

        vcmd = (self.root.register(validate_integer_input), '%d', '%P')

        # åœ¨setup_uiä¸­åˆ›å»ºè¾“å…¥æ¡†æ—¶ä½¿ç”¨è¿™ä¸ªéªŒè¯å‡½æ•°
        self.history_validation_command = vcmd

    def adjust_history_size(self, event=None):
        """è°ƒæ•´å†å²å¸§æ•°é‡ä¸ºæœ€æ¥è¿‘çš„10çš„å€æ•°"""
        try:
            current_value = self.history_size_var.get()

            # å¦‚æœä¸ºç©ºï¼Œè®¾ç½®ä¸ºé»˜è®¤å€¼20
            if not current_value:
                self.history_size_var.set("20")
                return

            # è½¬æ¢ä¸ºæ•´æ•°
            history_size = int(current_value)

            # é™åˆ¶èŒƒå›´åœ¨1-200ä¹‹é—´
            if history_size < 1:
                history_size = 10  # æœ€å°å€¼è®¾ä¸º10
            elif history_size > 200:
                history_size = 200

            # è°ƒæ•´ä¸ºæœ€æ¥è¿‘çš„10çš„å€æ•°
            history_size = round(history_size / 10) * 10

            # ç¡®ä¿è°ƒæ•´åä»åœ¨æœ‰æ•ˆèŒƒå›´å†…
            if history_size < 10:
                history_size = 10
            elif history_size > 200:
                history_size = 200

            # æ›´æ–°å˜é‡
            new_value = str(history_size)
            if new_value != current_value:
                self.history_size_var.set(new_value)
                self.log(f"å†å²å¸§æ•°é‡å·²è°ƒæ•´ä¸º: {new_value} (æœ€æ¥è¿‘çš„10çš„å€æ•°)")

        except ValueError:
            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œè®¾ä¸ºé»˜è®¤å€¼20
            self.history_size_var.set("20")

    def setup_styles(self):
        """è®¾ç½®UIæ ·å¼"""
        style = ttk.Style()
        style.theme_use('clam')
        style.configure('TFrame', background=self.bg_color)
        style.configure('TLabel', background=self.bg_color, font=('Segoe UI', 9))
        style.configure('TButton', font=('Segoe UI', 9), padding=5)
        style.configure('Accent.TButton', background=self.accent_color,
                        foreground='white', font=('Segoe UI', 9, 'bold'))
        style.configure('TProgressbar', thickness=15, background=self.accent_color)
        style.configure('TLabelframe', background=self.bg_color, borderwidth=2)
        style.configure('TLabelframe.Label', background=self.bg_color,
                        font=('Segoe UI', 10, 'bold'))

    def init_history_cache(self):
        """åˆå§‹åŒ–å†å²å¸§ç¼“å­˜ - ä¿®å¤ç‰ˆæœ¬"""
        # æ£€æŸ¥å†å²å¸§å¼€å…³
        if not self.enable_history_var.get():
            # å¦‚æœå†å²å¸§åŠŸèƒ½å…³é—­ï¼Œä½¿ç”¨é»˜è®¤å€¼1ï¼ˆåªä¸å‰ä¸€å¸§æ¯”è¾ƒï¼‰
            history_size = 1
        else:
            try:
                history_size = int(self.history_size_var.get())
                # ç¡®ä¿å†å²å¸§æ•°é‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
                if history_size < 1:
                    history_size = 10
                    self.history_size_var.set("10")
                elif history_size > 200:  # ä¸Šé™æ”¹ä¸º200
                    history_size = 200
                    self.history_size_var.set("200")
            except:
                history_size = 20  # é»˜è®¤å€¼
                self.history_size_var.set("20")

        # ç¡®ä¿dequeæœ‰æœ€å¤§é•¿åº¦é™åˆ¶
        self.frame_history = collections.deque(maxlen=history_size)
        self.frame_hash_history = collections.deque(maxlen=history_size)

        if self.use_ssim_var.get():
            self.frame_thumbnail_history = collections.deque(maxlen=history_size)
        else:
            self.frame_thumbnail_history = None

        self.frame_sr_history = collections.deque(maxlen=history_size)
        self.frame_idx_history = collections.deque(maxlen=history_size)

    def clear_history_cache(self):
        """æ¸…ç©ºå†å²ç¼“å­˜"""
        if hasattr(self, 'frame_history'):
            self.frame_history.clear()
        if hasattr(self, 'frame_hash_history'):
            self.frame_hash_history.clear()
        if hasattr(self, 'frame_thumbnail_history') and self.frame_thumbnail_history:
            self.frame_thumbnail_history.clear()
        if hasattr(self, 'frame_sr_history'):
            self.frame_sr_history.clear()
        if hasattr(self, 'frame_idx_history'):
            self.frame_idx_history.clear()

    def setup_ui(self):
        """è®¾ç½®UIå¸ƒå±€"""
        # ä¸»å®¹å™¨
        main_container = ttk.Frame(self.root)
        main_container.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

        # æ ‡é¢˜
        title_frame = ttk.Frame(main_container)
        title_frame.pack(fill=tk.X, pady=(0, 10))

        title_label = tk.Label(title_frame, text="APISR è§†é¢‘è¶…åˆ†è¾¨ç‡å¤„ç†å·¥å…·",
                               font=('Segoe UI', 18, 'bold'),
                               foreground=self.sidebar_color,
                               background=self.bg_color)
        title_label.pack(side=tk.LEFT)

        version_label = tk.Label(title_frame, text="v2.0",  # ç‰ˆæœ¬æ›´æ–°åˆ°2.0
                                 font=('Segoe UI', 9),
                                 foreground='#7f8c8d',
                                 background=self.bg_color)
        version_label.pack(side=tk.RIGHT)

        # ä¸»å†…å®¹åŒºåŸŸ - ä½¿ç”¨PanedWindowå®ç°å¯è°ƒæ•´å¤§å°çš„åˆ†å‰²
        paned_window = tk.PanedWindow(main_container, orient=tk.HORIZONTAL, sashwidth=8, sashrelief=tk.RAISED)
        paned_window.pack(fill=tk.BOTH, expand=True, pady=(0, 10))

        # å·¦ä¾§å‚æ•°é¢æ¿
        left_frame = ttk.Frame(paned_window)
        paned_window.add(left_frame, width=500, minsize=400)

        # å³ä¾§æ—¥å¿—é¢æ¿
        right_frame = ttk.Frame(paned_window)
        paned_window.add(right_frame, width=600, minsize=400)

        # è®¾ç½®é¢æ¿
        self.setup_left_panel(left_frame)
        self.setup_right_panel(right_frame)

        # è¿›åº¦æ¡åŒºåŸŸ
        progress_frame = ttk.Frame(main_container)
        progress_frame.pack(fill=tk.X, pady=(0, 5))

        # è¿›åº¦ä¿¡æ¯
        progress_info_frame = ttk.Frame(progress_frame)
        progress_info_frame.pack(fill=tk.X, pady=(0, 3))

        self.progress_info = ttk.Label(progress_info_frame, text="å‡†å¤‡å¼€å§‹å¤„ç†",
                                       font=('Segoe UI', 10, 'bold'),
                                       foreground=self.sidebar_color)
        self.progress_info.pack(side=tk.LEFT, anchor=tk.W)

        self.detailed_progress_info = ttk.Label(progress_info_frame, text="",
                                                font=('Segoe UI', 9),
                                                foreground='#7f8c8d')
        self.detailed_progress_info.pack(side=tk.RIGHT, anchor=tk.E)

        # è¿›åº¦æ¡
        self.progress_var = tk.DoubleVar()
        self.progress_bar = ttk.Progressbar(progress_frame, variable=self.progress_var,
                                            maximum=100, length=600,
                                            style='TProgressbar')
        self.progress_bar.pack(fill=tk.X, pady=(0, 5))

        # æ§åˆ¶æŒ‰é’®åŒºåŸŸ
        control_frame = ttk.Frame(main_container)
        control_frame.pack(fill=tk.X, pady=(5, 5))

        # å·¦ä¾§æŒ‰é’®ç»„
        left_btn_frame = ttk.Frame(control_frame)
        left_btn_frame.pack(side=tk.LEFT)

        self.process_btn = ModernButton(left_btn_frame, text="â–¶ å¼€å§‹å¤„ç†",
                                        command=self.start_processing, width=12)
        self.process_btn.pack(side=tk.LEFT, padx=2)

        self.pause_btn = ttk.Button(left_btn_frame, text="â¸ æš‚åœ",
                                    command=self.toggle_pause, width=12, state='disabled')
        self.pause_btn.pack(side=tk.LEFT, padx=2)

        self.stop_btn = ttk.Button(left_btn_frame, text="â¹ åœæ­¢",
                                   command=self.stop_processing, width=12, state='disabled')
        self.stop_btn.pack(side=tk.LEFT, padx=2)

        # ä¸­é—´ç»Ÿè®¡ä¿¡æ¯
        center_btn_frame = ttk.Frame(control_frame)
        center_btn_frame.pack(side=tk.LEFT, padx=20)

        self.dup_info = tk.Label(center_btn_frame, text="é‡å¤å¸§: 0",
                                 font=('Segoe UI', 9),
                                 foreground=self.warning_color,
                                 background=self.bg_color)
        self.dup_info.pack()

        # å³ä¾§æŒ‰é’®ç»„
        right_btn_frame = ttk.Frame(control_frame)
        right_btn_frame.pack(side=tk.RIGHT)

        ttk.Button(right_btn_frame, text="ğŸ“‚ æ‰“å¼€ç›®å½•",
                   command=self.open_output_dir, width=12).pack(side=tk.RIGHT, padx=2)

        ttk.Button(right_btn_frame, text="æ¸…ç†ä¸´æ—¶æ–‡ä»¶",
                   command=self.cleanup_temp_files, width=12).pack(side=tk.RIGHT, padx=2)

        ttk.Button(right_btn_frame, text="æ¸…ç©ºæ—¥å¿—",
                   command=self.clear_log, width=12).pack(side=tk.RIGHT, padx=2)

        # åº•éƒ¨çŠ¶æ€æ 
        status_bar = ttk.Frame(main_container, height=20)
        status_bar.pack(fill=tk.X, pady=(5, 0))

        self.status_label = tk.Label(status_bar, text="å‡†å¤‡å°±ç»ª",
                                     font=('Segoe UI', 9),
                                     foreground=self.success_color,
                                     background=self.bg_color)
        self.status_label.pack(side=tk.LEFT, padx=10)

        gpu_info = self.get_gpu_info()
        self.gpu_label = tk.Label(status_bar, text=gpu_info,
                                  font=('Segoe UI', 9),
                                  foreground='#7f8c8d',
                                  background=self.bg_color)
        self.gpu_label.pack(side=tk.RIGHT, padx=10)

    def setup_config_save_bindings(self):
        """è®¾ç½®é…ç½®è‡ªåŠ¨ä¿å­˜çš„äº‹ä»¶ç»‘å®š"""
        # ä¸ºæ‰€æœ‰é‡è¦å˜é‡æ·»åŠ traceï¼Œå½“å€¼æ”¹å˜æ—¶è‡ªåŠ¨ä¿å­˜é…ç½®
        variables_to_trace = [
            (self.model_var, 'w'),
            (self.scale_var, 'w'),
            (self.segment_duration, 'w'),
            (self.downsample_threshold, 'w'),
            (self.hash_threshold_var, 'w'),
            (self.ssim_threshold_var, 'w'),
            (self.history_size_var, 'w'),
            (self.video_encoder_mode, 'w'),  # æ–°å¢ï¼šè§†é¢‘ç¼–ç å™¨æ¨¡å¼
        ]

        for var, mode in variables_to_trace:
            var.trace(mode, lambda *args: self.save_config())

        # ä¸ºBooleanVaræ·»åŠ å›è°ƒ
        boolean_vars = [
            self.float16_var,
            self.crop_for_4x_var,
            self.enable_dup_detect_var,
            self.use_ssim_var,
            self.use_hash_var,
            self.immediate_merge_var,
            self.test_mode_var,
            self.enable_history_var,
        ]

        for var in boolean_vars:
            var.trace('w', lambda *args: self.save_config())

    def setup_left_panel(self, parent):
        """è®¾ç½®å·¦ä¾§å‚æ•°é¢æ¿"""
        # åˆ›å»ºä¸»æ¡†æ¶
        main_frame = ttk.Frame(parent)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)

        # ä½¿ç”¨gridå¸ƒå±€ï¼Œ4è¡Œ2åˆ—
        for i in range(4):
            main_frame.grid_rowconfigure(i, weight=1, pad=2)
        for i in range(2):
            main_frame.grid_columnconfigure(i, weight=1, pad=5)

        row = 0

        # 1. æ–‡ä»¶è®¾ç½®éƒ¨åˆ† - å ç”¨ä¸€è¡Œä¸¤åˆ—
        file_frame = ttk.LabelFrame(main_frame, text="æ–‡ä»¶è®¾ç½®", padding=8)
        file_frame.grid(row=row, column=0, columnspan=2, sticky="nsew", padx=2, pady=2)
        file_frame.grid_columnconfigure(1, weight=1)

        # è¾“å…¥æ–‡ä»¶ - ç´§å‡‘å¸ƒå±€
        ttk.Label(file_frame, text="è¾“å…¥è§†é¢‘:", font=('Segoe UI', 9)).grid(row=0, column=0, sticky=tk.W, pady=(0, 2))

        input_btn_frame = ttk.Frame(file_frame)
        input_btn_frame.grid(row=0, column=1, sticky=tk.W, pady=(0, 2))

        ttk.Button(input_btn_frame, text="é€‰æ‹©è§†é¢‘æ–‡ä»¶",
                   command=self.select_input_files, width=18).pack(side=tk.LEFT)

        # åˆ›å»ºæ ‡ç­¾æ˜¾ç¤ºé€‰æ‹©çš„è§†é¢‘æ•°é‡
        self.input_info_label = tk.Label(input_btn_frame, text="æœªé€‰æ‹©è§†é¢‘",
                                         font=('Segoe UI', 8),
                                         foreground='#7f8c8d',
                                         background=self.bg_color)
        self.input_info_label.pack(side=tk.LEFT, padx=(10, 0))

        # è¾“å‡ºç›®å½• - ç´§å‡‘å¸ƒå±€
        ttk.Label(file_frame, text="è¾“å‡ºç›®å½•:", font=('Segoe UI', 9)).grid(row=1, column=0, sticky=tk.W, pady=(2, 0))

        output_entry_frame = ttk.Frame(file_frame)
        output_entry_frame.grid(row=1, column=1, sticky=tk.EW, pady=(2, 0))
        output_entry_frame.grid_columnconfigure(0, weight=1)

        output_entry = ttk.Entry(output_entry_frame, textvariable=self.output_dir, font=('Segoe UI', 9))
        output_entry.grid(row=0, column=0, sticky=tk.EW, padx=(0, 5))
        ttk.Button(output_entry_frame, text="æµè§ˆ", command=self.select_output_dir, width=8).grid(row=0, column=1)

        row += 1

        # 2. æ¨¡å‹å‚æ•°éƒ¨åˆ†
        model_frame = ttk.LabelFrame(main_frame, text="æ¨¡å‹å‚æ•°", padding=8)
        model_frame.grid(row=row, column=0, sticky="nsew", padx=2, pady=2)

        # ä½¿ç”¨gridå¸ƒå±€å†…éƒ¨æ§ä»¶
        ttk.Label(model_frame, text="é€‰æ‹©æ¨¡å‹:").grid(row=0, column=0, sticky=tk.W, pady=2, padx=(0, 5))
        model_combo = ttk.Combobox(model_frame, textvariable=self.model_var,
                                   values=list(self.models.keys()),
                                   state="readonly", width=12, font=('Segoe UI', 9))
        model_combo.grid(row=0, column=1, sticky=tk.W, pady=2)
        model_combo.bind('<<ComboboxSelected>>', self.on_model_change)

        ttk.Label(model_frame, text="ç¼©æ”¾å› å­:").grid(row=1, column=0, sticky=tk.W, pady=2, padx=(0, 5))
        self.scale_combo = ttk.Combobox(model_frame, textvariable=self.scale_var,
                                        state="readonly", width=12, font=('Segoe UI', 9))
        self.scale_combo.grid(row=1, column=1, sticky=tk.W, pady=2)

        ttk.Label(model_frame, text="åˆ†æ®µæ—¶é•¿(ç§’):").grid(row=2, column=0, sticky=tk.W, pady=2, padx=(0, 5))
        ttk.Entry(model_frame, textvariable=self.segment_duration,
                  width=12, font=('Segoe UI', 9)).grid(row=2, column=1, sticky=tk.W, pady=2)

        ttk.Label(model_frame, text="ä¸‹é‡‡æ ·é˜ˆå€¼:").grid(row=3, column=0, sticky=tk.W, pady=2, padx=(0, 5))
        ttk.Entry(model_frame, textvariable=self.downsample_threshold,
                  width=12, font=('Segoe UI', 9)).grid(row=3, column=1, sticky=tk.W, pady=2)

        # 3. æ€§èƒ½è®¾ç½®éƒ¨åˆ† - ä¿®æ”¹ï¼šç®€åŒ–äº†å†…å®¹
        perf_frame = ttk.LabelFrame(main_frame, text="æ€§èƒ½è®¾ç½®", padding=8)
        perf_frame.grid(row=row, column=1, sticky="nsew", padx=2, pady=2)

        ttk.Label(perf_frame, text="æ•°æ®ç±»å‹:").grid(row=0, column=0, sticky=tk.W, pady=2, padx=(0, 5))
        ttk.Checkbutton(perf_frame, text="FP16åŠ é€Ÿ",
                        variable=self.float16_var).grid(row=0, column=1, sticky=tk.W, pady=2)

        ttk.Label(perf_frame, text="è§†é¢‘ç¼–ç :").grid(row=1, column=0, sticky=tk.W, pady=2, padx=(0, 5))
        encoder_combo = ttk.Combobox(perf_frame, textvariable=self.video_encoder_mode,
                                     values=["auto", "opencv", "ffmpeg"], width=10, state="readonly")
        encoder_combo.grid(row=1, column=1, sticky=tk.W, pady=2)

        # æ·»åŠ ä¸¤è¡Œç©ºè¡Œä»¥ä¿æŒå¸ƒå±€å¹³è¡¡
        ttk.Label(perf_frame, text="").grid(row=2, column=0, pady=2)
        ttk.Label(perf_frame, text="").grid(row=3, column=0, pady=2)

        row += 1

        # 4. é‡å¤å¸§æ£€æµ‹éƒ¨åˆ† - å ç”¨ä¸€è¡Œä¸¤åˆ—
        dup_frame = ttk.LabelFrame(main_frame, text="é‡å¤å¸§æ£€æµ‹è®¾ç½®", padding=8)
        dup_frame.grid(row=row, column=0, columnspan=2, sticky="nsew", padx=2, pady=2)

        # å¯ç”¨æ£€æµ‹
        ttk.Checkbutton(dup_frame, text="å¯ç”¨é‡å¤å¸§æ£€æµ‹",
                        variable=self.enable_dup_detect_var).grid(row=0, column=0, sticky=tk.W, pady=2, columnspan=2)

        # æ£€æµ‹æ–¹æ³•
        method_frame = ttk.Frame(dup_frame)
        method_frame.grid(row=1, column=0, columnspan=2, sticky=tk.W, pady=2)
        ttk.Checkbutton(method_frame, text="å“ˆå¸Œæ£€æµ‹",
                        variable=self.use_hash_var, width=10).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Checkbutton(method_frame, text="SSIMæ£€æµ‹",
                        variable=self.use_ssim_var, width=10).pack(side=tk.LEFT)

        # å“ˆå¸Œé˜ˆå€¼
        ttk.Label(dup_frame, text="å“ˆå¸Œé˜ˆå€¼:").grid(row=2, column=0, sticky=tk.W, pady=2)
        hash_frame = ttk.Frame(dup_frame)
        hash_frame.grid(row=2, column=1, sticky=tk.W, pady=2)
        ttk.Entry(hash_frame, textvariable=self.hash_threshold_var,
                  width=8, font=('Segoe UI', 9)).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Label(hash_frame, text="(0-10)", foreground='#7f8c8d', font=('Segoe UI', 8)).pack(side=tk.LEFT)

        # SSIMé˜ˆå€¼
        ttk.Label(dup_frame, text="SSIMé˜ˆå€¼:").grid(row=3, column=0, sticky=tk.W, pady=2)
        ssim_frame = ttk.Frame(dup_frame)
        ssim_frame.grid(row=3, column=1, sticky=tk.W, pady=2)
        ttk.Entry(ssim_frame, textvariable=self.ssim_threshold_var,
                  width=8, font=('Segoe UI', 9)).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Label(ssim_frame, text="(0.9-1.0)", foreground='#7f8c8d', font=('Segoe UI', 8)).pack(side=tk.LEFT)

        # å†å²å¸§è®¾ç½®
        ttk.Label(dup_frame, text="å†å²å¸§è®¾ç½®:").grid(row=4, column=0, sticky=tk.W, pady=2)
        history_setting_frame = ttk.Frame(dup_frame)
        history_setting_frame.grid(row=4, column=1, sticky=tk.W, pady=2)

        # å†å²å¸§å¼€å…³
        self.history_check = ttk.Checkbutton(history_setting_frame, text="å¯ç”¨",
                                             variable=self.enable_history_var,
                                             command=self.toggle_history_settings)
        self.history_check.pack(side=tk.LEFT, padx=(0, 10))

        # å†å²å¸§æ•°é‡è¾“å…¥æ¡†
        history_size_frame = ttk.Frame(history_setting_frame)
        history_size_frame.pack(side=tk.LEFT)

        ttk.Label(history_size_frame, text="æ•°é‡:").pack(side=tk.LEFT, padx=(0, 5))

        # åˆ›å»ºå†å²å¸§æ•°é‡è¾“å…¥æ¡† - ä¿®æ”¹ï¼šä½¿ç”¨éªŒè¯å‘½ä»¤å¹¶ç»‘å®šç„¦ç‚¹ç¦»å¼€äº‹ä»¶
        self.history_entry = ttk.Entry(history_size_frame, textvariable=self.history_size_var,
                                       width=6, font=('Segoe UI', 9),
                                       validate='key', validatecommand=self.history_validation_command,
                                       state='normal' if self.enable_history_var.get() else 'disabled')
        self.history_entry.pack(side=tk.LEFT, padx=(0, 5))

        # ç»‘å®šç„¦ç‚¹ç¦»å¼€äº‹ä»¶
        self.history_entry.bind('<FocusOut>', self.adjust_history_size)

        ttk.Label(history_size_frame, text="(1-200)", foreground='#7f8c8d', font=('Segoe UI', 8)).pack(side=tk.LEFT)

        row += 1

        # 5. å…¶ä»–é€‰é¡¹å’Œè¯´æ˜ä¿¡æ¯éƒ¨åˆ†
        bottom_frame = ttk.Frame(main_frame)
        bottom_frame.grid(row=row, column=0, columnspan=2, sticky="nsew", pady=(2, 0))
        bottom_frame.grid_columnconfigure(0, weight=1)
        bottom_frame.grid_columnconfigure(1, weight=1)

        # å¤„ç†é€‰é¡¹éƒ¨åˆ†
        options_frame = ttk.LabelFrame(bottom_frame, text="å¤„ç†é€‰é¡¹", padding=8)
        options_frame.grid(row=0, column=0, sticky="nsew", padx=(0, 5), pady=0)

        ttk.Checkbutton(options_frame, text="æµ‹è¯•æ¨¡å¼(ä»…é‡å¤å¸§æ£€æµ‹)",
                        variable=self.test_mode_var).pack(anchor=tk.W, pady=2)

        # æ–°å¢ï¼šç«‹å³åˆæˆè§†é¢‘é€‰é¡¹
        ttk.Checkbutton(options_frame, text="ç«‹å³åˆæˆè§†é¢‘",
                        variable=self.immediate_merge_var).pack(anchor=tk.W, pady=2)

        # è¯´æ˜ä¿¡æ¯éƒ¨åˆ†
        info_frame = ttk.LabelFrame(bottom_frame, text="è¯´æ˜", padding=8)
        info_frame.grid(row=0, column=1, sticky="nsew", padx=(5, 0), pady=0)

        info_text = """1. æ”¯æŒæ‰¹é‡å¤„ç†å¤šä¸ªè§†é¢‘
2. å“ˆå¸Œé˜ˆå€¼è¶Šå°ï¼ŒSSIMé˜ˆå€¼è¶Šå¤§ï¼Œé‡å¤æ£€æµ‹è¶Šä¸¥æ ¼
3. å–æ¶ˆé‡å¤å¸§è¯†åˆ«ä¼šåˆ‡æ¢ç›´æ¥å¤„ç†è§†é¢‘æ¨¡å¼ï¼Œæ— æ³•æš‚åœ
4. å¯åˆ©ç”¨æµ‹è¯•æ¨¡å¼è‡ªè¡Œè°ƒæ•´å‚æ•°
5. é…ç½®è‡ªåŠ¨ä¿å­˜
6. è¿›åº¦æ ¹æ®ä¸´æ—¶æ–‡ä»¶è¯»å–ï¼Œè¯·ä¸è¦æŒªåŠ¨ä¸´æ—¶æ–‡ä»¶
7. æ‰€æœ‰è§†é¢‘ç‰‡æ®µå¤„ç†å®Œåéƒ½ä¼šç«‹å³åˆæˆè§†é¢‘
8. å¼€å¯ç«‹å³åˆæˆåŠŸèƒ½ä¼šåœ¨æ¯ä¸ªç‰‡æ®µå®Œæˆååˆå¹¶åˆ°æ•´ä½“è§†é¢‘"""

        info_label = tk.Label(info_frame, text=info_text,
                              font=('Segoe UI', 8),
                              foreground='#7f8c8d',
                              background=self.bg_color,
                              justify=tk.LEFT)
        info_label.pack(anchor=tk.W)

    def setup_right_panel(self, parent):
        """è®¾ç½®å³ä¾§æ—¥å¿—é¢æ¿"""
        log_frame = ttk.LabelFrame(parent, text="å¤„ç†æ—¥å¿—", padding=8)
        log_frame.pack(fill=tk.BOTH, expand=True)

        self.log_text = ScrolledText(log_frame, height=28, width=60,
                                     font=('Consolas', 9),
                                     bg='#2c3e50', fg='white',
                                     insertbackground='white')
        self.log_text.pack(fill=tk.BOTH, expand=True)

    def toggle_history_settings(self):
        """åˆ‡æ¢å†å²å¸§è®¾ç½®çš„çŠ¶æ€"""
        if self.enable_history_var.get():
            self.history_entry.config(state='normal')
            self.log("å†å²å¸§åŠŸèƒ½å·²å¯ç”¨")
        else:
            self.history_entry.config(state='disabled')
            self.log("å†å²å¸§åŠŸèƒ½å·²ç¦ç”¨")

    def get_gpu_info(self):
        """è·å–GPUä¿¡æ¯"""
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024 ** 3
            return f"GPU: {gpu_name} ({gpu_memory:.1f}GB)"
        return "æ— å¯ç”¨GPU"

    def on_model_change(self, event=None):
        """å½“æ¨¡å‹æ”¹å˜æ—¶æ›´æ–°å¯ç”¨ç¼©æ”¾å› å­"""
        model = self.model_var.get()
        if model in self.models:
            scales = self.models[model]["scale"]
            self.scale_combo['values'] = scales
            if str(scales[0]) in self.scale_var.get():
                self.scale_var.set(str(scales[0]))
            else:
                self.scale_var.set(str(scales[0]))

    def select_input_files(self):
        """é€‰æ‹©å¤šä¸ªè¾“å…¥è§†é¢‘æ–‡ä»¶"""
        filenames = filedialog.askopenfilenames(
            title="é€‰æ‹©è§†é¢‘æ–‡ä»¶",
            filetypes=[
                ("è§†é¢‘æ–‡ä»¶", "*.mp4 *.avi *.mov *.mkv *.flv *.wmv"),
                ("æ‰€æœ‰æ–‡ä»¶", "*.*")
            ]
        )

        if filenames:
            # æŒ‰æ–‡ä»¶åæ’åº
            self.input_paths = sorted(list(filenames))

            # æ›´æ–°æ˜¾ç¤ºä¿¡æ¯
            if len(self.input_paths) == 1:
                file_name = os.path.basename(self.input_paths[0])
                if len(file_name) > 20:
                    file_name = file_name[:17] + "..."
                self.input_info_label.config(text=f"å·²é€‰æ‹©: {file_name}")
            else:
                self.input_info_label.config(text=f"å·²é€‰æ‹© {len(self.input_paths)} ä¸ªè§†é¢‘")
                self.log(f"å·²é€‰æ‹© {len(self.input_paths)} ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œå°†æŒ‰ä»¥ä¸‹é¡ºåºå¤„ç†:")
                for i, path in enumerate(self.input_paths):
                    self.log(f"  {i + 1}. {os.path.basename(path)}")

            # è‡ªåŠ¨è®¾ç½®è¾“å‡ºç›®å½•ï¼ˆä»¥ç¬¬ä¸€ä¸ªè§†é¢‘çš„ç›®å½•ä¸ºå‡†ï¼‰
            if not self.output_dir.get():
                output_path = Path(self.input_paths[0]).parent / "APISR_Output"
                self.output_dir.set(str(output_path))

    def select_output_dir(self):
        """é€‰æ‹©è¾“å‡ºç›®å½•"""
        directory = filedialog.askdirectory(title="é€‰æ‹©è¾“å‡ºç›®å½•")
        if directory:
            self.output_dir.set(directory)

    def open_output_dir(self):
        """æ‰“å¼€è¾“å‡ºç›®å½•"""
        output_dir = self.output_dir.get()
        if output_dir and os.path.exists(output_dir):
            try:
                if sys.platform == "win32":
                    os.startfile(output_dir)
                elif sys.platform == "darwin":
                    subprocess.Popen(["open", output_dir])
                else:
                    subprocess.Popen(["xdg-open", output_dir])
            except Exception as e:
                self.log(f"æ‰“å¼€ç›®å½•å¤±è´¥: {e}")

    def setup_temp_dirs(self, video_path):
        """è®¾ç½®ä¸´æ—¶ç›®å½•ç»“æ„ - åŸºäºè§†é¢‘æ–‡ä»¶åå’Œæµ‹è¯•æ¨¡å¼"""
        output_dir = self.output_dir.get()
        if not output_dir:
            return None

        # è·å–è§†é¢‘åŸºç¡€åç§°
        video_name = Path(video_path).stem

        # æ ¹æ®æµ‹è¯•æ¨¡å¼æ·»åŠ åç¼€
        if self.test_mode_var.get():
            temp_dir_suffix = "_test_temp"
            self.is_test_mode_folder = True
        else:
            temp_dir_suffix = "_temp"
            self.is_test_mode_folder = False

        # åŸºäºè§†é¢‘æ–‡ä»¶ååˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir_name = f"{video_name}{temp_dir_suffix}"
        self.temp_base_dir = os.path.join(output_dir, temp_dir_name)

        # åˆ›å»ºæ ‡å‡†åŒ–çš„ç›®å½•ç»“æ„ - åˆ é™¤05_logsç›¸å…³
        dirs = {
            'base': self.temp_base_dir,
            'original_segments': os.path.join(self.temp_base_dir, "01_original_segments"),
            'audio': os.path.join(self.temp_base_dir, "02_audio"),
            'segment_frames': os.path.join(self.temp_base_dir, "03_segment_frames"),  # ç›´æ¥æ”¾ç½®before/afteræ–‡ä»¶å¤¹
            'processed_segments': os.path.join(self.temp_base_dir, "04_processed_segments"),
            'immediate_merge': os.path.join(self.temp_base_dir, "05_immediate_merge")  # æ–°å¢ï¼šç«‹å³åˆæˆç›®å½•
        }

        # åˆ›å»ºç›®å½•
        for path in dirs.values():
            os.makedirs(path, exist_ok=True)

        return dirs

    def setup_segment_frame_dirs(self, segment_path):
        """ä¸ºå½“å‰ç‰‡æ®µè®¾ç½®å¸§ç›®å½• - æ ¹æ®01_original_segmentsé‡Œçš„æ–‡ä»¶åæ¥å‘½å"""
        if not self.temp_base_dir:
            return None, None

        # ä»segment_pathä¸­è·å–æ–‡ä»¶åï¼ˆä¸å¸¦æ‰©å±•åï¼‰
        segment_name = Path(segment_path).stem  # ä¾‹å¦‚ï¼šsegment_000

        # ç›´æ¥åœ¨03_segment_framesä¸‹åˆ›å»ºå¸¦å‰åç¼€çš„æ–‡ä»¶å¤¹
        before_dir = os.path.join(self.temp_base_dir, "03_segment_frames", f"{segment_name}_before")
        after_dir = os.path.join(self.temp_base_dir, "03_segment_frames", f"{segment_name}_after")

        os.makedirs(before_dir, exist_ok=True)
        os.makedirs(after_dir, exist_ok=True)

        return before_dir, after_dir

    def cleanup_segment_frame_dirs(self, segment_path):
        """æ¸…ç†å½“å‰ç‰‡æ®µçš„å¸§ç›®å½•"""
        if not self.temp_base_dir:
            return

        # ä»segment_pathä¸­è·å–æ–‡ä»¶åï¼ˆä¸å¸¦æ‰©å±•åï¼‰
        segment_name = Path(segment_path).stem

        # æ¸…ç†beforeå’Œafteræ–‡ä»¶å¤¹
        before_dir = os.path.join(self.temp_base_dir, "03_segment_frames", f"{segment_name}_before")
        after_dir = os.path.join(self.temp_base_dir, "03_segment_frames", f"{segment_name}_after")

        for dir_path in [before_dir, after_dir]:
            if os.path.exists(dir_path):
                try:
                    shutil.rmtree(dir_path)
                except Exception as e:
                    pass

    def cleanup_temp_files(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        output_dir = self.output_dir.get()
        if output_dir:
            # æŸ¥æ‰¾æ‰€æœ‰åŸºäºè§†é¢‘æ–‡ä»¶åçš„ä¸´æ—¶ç›®å½•
            temp_dirs = []
            for item in os.listdir(output_dir):
                item_path = os.path.join(output_dir, item)
                if os.path.isdir(item_path) and (item.endswith("_temp") or item.endswith("_test_temp")):
                    temp_dirs.append(item_path)

            if temp_dirs:
                response = messagebox.askyesno("æ¸…ç†ä¸´æ—¶æ–‡ä»¶",
                                               f"æ‰¾åˆ° {len(temp_dirs)} ä¸ªä¸´æ—¶ç›®å½•ã€‚æ˜¯å¦æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶ï¼Ÿ\n"
                                               f"ï¼ˆåŒ…æ‹¬æ™®é€šæ¨¡å¼å’Œæµ‹è¯•æ¨¡å¼çš„ä¸´æ—¶æ–‡ä»¶ï¼‰")
                if response:
                    for temp_dir in temp_dirs:
                        try:
                            shutil.rmtree(temp_dir)
                            self.log(f"å·²æ¸…ç†ä¸´æ—¶ç›®å½•: {os.path.basename(temp_dir)}")
                        except Exception as e:
                            self.log(f"æ¸…ç†ä¸´æ—¶ç›®å½•æ—¶å‡ºé”™: {e}")
                    messagebox.showinfo("æ¸…ç†å®Œæˆ", "ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ")
            else:
                messagebox.showinfo("æ¸…ç†ä¸´æ—¶æ–‡ä»¶", "æ²¡æœ‰æ‰¾åˆ°ä¸´æ—¶æ–‡ä»¶")

    def log(self, message):
        """æ·»åŠ æ—¥å¿—"""
        if not hasattr(self, 'log_text'):
            # å¦‚æœlog_textè¿˜ä¸å­˜åœ¨ï¼Œå…ˆæ‰“å°åˆ°æ§åˆ¶å°
            print(f"[åˆå§‹åŒ–] {message}")
            return

        timestamp = datetime.now().strftime("%H:%M:%S")
        self.log_text.insert(tk.END, f"[{timestamp}] {message}\n")
        self.log_text.see(tk.END)
        self.root.update_idletasks()

    def clear_log(self):
        """æ¸…ç©ºæ—¥å¿—"""
        self.log_text.delete(1.0, tk.END)

    def update_status(self, message, color="black"):
        """æ›´æ–°çŠ¶æ€"""
        colors = {
            "black": "#2c3e50",
            "green": self.success_color,
            "blue": self.accent_color,
            "orange": self.warning_color,
            "red": self.danger_color
        }
        self.status_label.config(text=message, foreground=colors.get(color, color))
        self.root.update_idletasks()

    def update_progress_info(self):
        """æ›´æ–°è¿›åº¦ä¿¡æ¯"""
        if self.total_segments > 0:
            info = f"è§†é¢‘ {self.current_video_index + 1}/{len(self.input_paths)} - ç‰‡æ®µ {self.current_segment_index + 1}/{self.total_segments}"
            self.progress_info.config(text=info)
            self.root.update_idletasks()

    def update_detailed_progress(self, current_frame, total_frames):
        """æ›´æ–°è¯¦ç»†è¿›åº¦ä¿¡æ¯"""
        if total_frames > 0:
            percentage = current_frame / total_frames * 100
            info = f"å½“å‰ç‰‡æ®µ: ç¬¬ {current_frame}/{total_frames} å¸§ ({percentage:.1f}%)"
            self.detailed_progress_info.config(text=info)
            self.root.update_idletasks()

    def update_dup_info(self, dup_count):
        """æ›´æ–°é‡å¤å¸§ä¿¡æ¯"""
        self.dup_info.config(text=f"é‡å¤å¸§: {dup_count}")
        self.root.update_idletasks()

    def update_progress(self, value):
        """æ›´æ–°è¿›åº¦æ¡"""
        self.progress_var.set(value)
        self.root.update_idletasks()

    def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if os.path.exists(self.config_file):
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)

                # å®‰å…¨çš„æ•°å€¼åŠ è½½å‡½æ•°
                def safe_get_int(key, default, config_dict):
                    value = config_dict.get(key, default)
                    try:
                        return int(value)
                    except (ValueError, TypeError):
                        return default

                def safe_get_float(key, default, config_dict):
                    value = config_dict.get(key, default)
                    try:
                        return float(value)
                    except (ValueError, TypeError):
                        return default

                # è®¾ç½®å˜é‡ï¼Œä½¿ç”¨å®‰å…¨è½¬æ¢
                if 'model' in config:
                    self.model_var.set(config['model'])
                if 'scale' in config:
                    self.scale_var.set(str(safe_get_int('scale', 4, config)))
                if 'segment_duration' in config:
                    self.segment_duration.set(str(safe_get_int('segment_duration', 20, config)))
                if 'downsample_threshold' in config:
                    self.downsample_threshold.set(str(safe_get_int('downsample_threshold', 720, config)))
                if 'float16' in config:
                    self.float16_var.set(config['float16'])
                if 'crop_for_4x' in config:
                    self.crop_for_4x_var.set(config['crop_for_4x'])
                if 'hash_threshold' in config:
                    self.hash_threshold_var.set(str(safe_get_int('hash_threshold', 3, config)))
                if 'ssim_threshold' in config:
                    self.ssim_threshold_var.set(str(safe_get_float('ssim_threshold', 0.98, config)))
                if 'enable_dup_detect' in config:
                    self.enable_dup_detect_var.set(config['enable_dup_detect'])
                if 'use_ssim' in config:
                    self.use_ssim_var.set(config['use_ssim'])
                if 'use_hash' in config:
                    self.use_hash_var.set(config['use_hash'])
                if 'test_mode' in config:
                    self.test_mode_var.set(config['test_mode'])
                    self.last_test_mode_state = config['test_mode']
                if 'enable_history' in config:
                    self.enable_history_var.set(config['enable_history'])
                if 'history_size' in config:
                    self.history_size_var.set(str(safe_get_int('history_size', 20, config)))
                if 'immediate_merge' in config:
                    self.immediate_merge_var.set(config['immediate_merge'])
                if 'video_encoder_mode' in config:
                    self.video_encoder_mode.set(config['video_encoder_mode'])

                self.log(f"å·²ä» {self.config_file} åŠ è½½é…ç½®")

                # æ›´æ–°UIçŠ¶æ€
                self.on_model_change()
                self.toggle_history_settings()

            except Exception as e:
                self.log(f"åŠ è½½é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                import traceback
                self.log(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        else:
            self.log("æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")

    def save_config(self):
        """ä¿å­˜é…ç½®æ–‡ä»¶ï¼ˆæ°¸è¿œè‡ªåŠ¨ä¿å­˜ï¼‰"""
        try:
            # ä½¿ç”¨é»˜è®¤å€¼å¤„ç†ç©ºå­—ç¬¦ä¸²æˆ–æ— æ•ˆè¾“å…¥
            def get_int_value(var, default):
                value = var.get()
                try:
                    return int(value) if value else default
                except ValueError:
                    return default

            def get_float_value(var, default):
                value = var.get()
                try:
                    return float(value) if value else default
                except ValueError:
                    return default

            # è·å–æ‰€æœ‰é…ç½®å€¼ï¼Œä½¿ç”¨é»˜è®¤å€¼å¤„ç†ç©ºå­—ç¬¦ä¸²
            config = {
                'model': self.model_var.get(),
                'scale': get_int_value(self.scale_var, 4),
                'segment_duration': get_int_value(self.segment_duration, 20),
                'downsample_threshold': get_int_value(self.downsample_threshold, 720),
                'float16': self.float16_var.get(),
                'crop_for_4x': self.crop_for_4x_var.get(),
                'hash_threshold': get_int_value(self.hash_threshold_var, 3),
                'ssim_threshold': get_float_value(self.ssim_threshold_var, 0.98),
                'enable_dup_detect': self.enable_dup_detect_var.get(),
                'use_ssim': self.use_ssim_var.get(),
                'use_hash': self.use_hash_var.get(),
                'test_mode': self.test_mode_var.get(),
                'enable_history': self.enable_history_var.get(),
                'history_size': get_int_value(self.history_size_var, 20),
                'immediate_merge': self.immediate_merge_var.get(),
                'video_encoder_mode': self.video_encoder_mode.get(),
                'last_saved': datetime.now().strftime("%Y-%m-%d %H:%M:%S")  # ä¿®æ­£äº†æ—¥æœŸæ ¼å¼é”™è¯¯
            }

            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=4, ensure_ascii=False)

        except Exception as e:
            self.log(f"ä¿å­˜é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            # æ‰“å°è¯¦ç»†é”™è¯¯ä¿¡æ¯ä»¥å¸®åŠ©è°ƒè¯•
            import traceback
            self.log(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    # ============================================================
    # å†…å­˜ç›‘æ§å’Œæ¸…ç†å‡½æ•°
    # ============================================================

    def add_memory_monitoring(self):
        """æ·»åŠ å†…å­˜ä½¿ç”¨ç›‘æ§åŠŸèƒ½"""
        try:
            if torch.cuda.is_available():
                import GPUtil
                gpus = GPUtil.getGPUs()
                if gpus:
                    gpu = gpus[0]
                    self.log(f"GPUå†…å­˜ä½¿ç”¨: {gpu.memoryUsed}MB / {gpu.memoryTotal}MB ({gpu.memoryUtil * 100:.1f}%)")
        except ImportError:
            # å¦‚æœGPUtilä¸å¯ç”¨ï¼Œè·³è¿‡
            pass
        except Exception as e:
            # ç›‘æ§å‡ºé”™æ—¶ä¸ä¸­æ–­å¤„ç†
            pass

    def start_memory_monitor(self):
        """å¯åŠ¨å†…å­˜ç›‘æ§çº¿ç¨‹"""

        def monitor_loop():
            while self.processing:
                time.sleep(self.memory_check_interval)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
                try:
                    if not self.paused and not self.stopped:
                        self.add_memory_monitoring()
                except:
                    pass

        self.monitor_thread = threading.Thread(target=monitor_loop, daemon=True)
        self.monitor_thread.start()

    def cleanup_memory(self):
        """æ¸…ç†å†…å­˜"""
        try:
            # æ¸…ç†GPUå†…å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()

            # æ¸…ç†Pythonå†…å­˜
            import gc
            gc.collect()

            # æ¸…ç†OpenCVç¼“å†²åŒºï¼ˆå¦‚æœæœ‰ï¼‰
            try:
                cv2.destroyAllWindows()
            except:
                pass

        except Exception as e:
            self.log(f"å†…å­˜æ¸…ç†æ—¶å‡ºé”™: {e}")

    # ============================================================
    # æ¨¡å‹åŠ è½½å‡½æ•°ï¼ˆä»test_utils.pyæ•´åˆï¼‰
    # ============================================================

    def load_rrdb(self, generator_weight_PATH, scale, print_options=False):
        '''åŠ è½½RRDBæ¨¡å‹'''
        start_time = time.time()

        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint_g = torch.load(generator_weight_PATH)

        # æŸ¥æ‰¾ç”Ÿæˆå™¨æƒé‡
        if 'params_ema' in checkpoint_g:
            # å¯¹äºå®˜æ–¹çš„ESRNET/ESRGANæƒé‡
            weight = checkpoint_g['params_ema']
            generator = RRDBNet(3, 3, scale=scale)  # é»˜è®¤å—æ•°ä¸º6

        elif 'params' in checkpoint_g:
            # å¯¹äºå®˜æ–¹çš„ESRNET/ESRGANæƒé‡
            weight = checkpoint_g['params']
            generator = RRDBNet(3, 3, scale=scale)

        elif 'model_state_dict' in checkpoint_g:
            # å¯¹äºä¸ªäººè®­ç»ƒçš„æƒé‡
            weight = checkpoint_g['model_state_dict']
            generator = RRDBNet(3, 3, scale=scale)

        else:
            raise ValueError("This weight is not supported")

        # å¤„ç†torch.compileæƒé‡é”®é‡å‘½å
        old_keys = [key for key in weight]
        for old_key in old_keys:
            if old_key[:10] == "_orig_mod.":
                new_key = old_key[10:]
                weight[new_key] = weight[old_key]
                del weight[old_key]

        generator.load_state_dict(weight)
        generator = generator.eval().cuda()

        # æ‰“å°é€‰é¡¹ä»¥æ˜¾ç¤ºä½¿ç”¨äº†å“ªäº›è®¾ç½®
        if print_options:
            if 'opt' in checkpoint_g:
                for key in checkpoint_g['opt']:
                    value = checkpoint_g['opt'][key]
                    print(f'{key} : {value}')

        elapsed = time.time() - start_time
        self.log(f"RRDBæ¨¡å‹åŠ è½½è€—æ—¶: {elapsed:.2f}ç§’")

        return generator

    def load_cunet(self, generator_weight_PATH, scale, print_options=False):
        '''åŠ è½½CUNETæ¨¡å‹'''
        start_time = time.time()

        if scale != 2:
            raise NotImplementedError("We only support 2x in CUNET")

        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint_g = torch.load(generator_weight_PATH)

        # æŸ¥æ‰¾ç”Ÿæˆå™¨æƒé‡
        if 'model_state_dict' in checkpoint_g:
            # å¯¹äºä¸ªäººè®­ç»ƒçš„æƒé‡
            weight = checkpoint_g['model_state_dict']
            loss = checkpoint_g["lowest_generator_weight"]
            if "iteration" in checkpoint_g:
                iteration = checkpoint_g["iteration"]
            else:
                iteration = "NAN"
            generator = UNet_Full()
            # generator = torch.compile(generator)  # torch.compile
            self.log(f"the generator weight is {loss} at iteration {iteration}")

        else:
            raise ValueError("This weight is not supported")

        # å¤„ç†torch.compileæƒé‡é”®é‡å‘½å
        old_keys = [key for key in weight]
        for old_key in old_keys:
            if old_key[:10] == "_orig_mod.":
                new_key = old_key[10:]
                weight[new_key] = weight[old_key]
                del weight[old_key]

        generator.load_state_dict(weight)
        generator = generator.eval().cuda()

        # æ‰“å°é€‰é¡¹ä»¥æ˜¾ç¤ºä½¿ç”¨äº†å“ªäº›è®¾ç½®
        if print_options:
            if 'opt' in checkpoint_g:
                for key in checkpoint_g['opt']:
                    value = checkpoint_g['opt'][key]
                    print(f'{key} : {value}')

        elapsed = time.time() - start_time
        self.log(f"CUNETæ¨¡å‹åŠ è½½è€—æ—¶: {elapsed:.2f}ç§’")

        return generator

    def load_grl(self, generator_weight_PATH, scale=4):
        '''åŠ è½½GRLæ¨¡å‹'''
        start_time = time.time()

        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint_g = torch.load(generator_weight_PATH)

        # æŸ¥æ‰¾ç”Ÿæˆå™¨æƒé‡
        if 'model_state_dict' in checkpoint_g:
            weight = checkpoint_g['model_state_dict']

            # GRL tinyæ¨¡å‹ï¼ˆæ³¨æ„ï¼štiny2ç‰ˆæœ¬ï¼‰
            generator = GRL(
                upscale=scale,
                img_size=64,
                window_size=8,
                depths=[4, 4, 4, 4],
                embed_dim=64,
                num_heads_window=[2, 2, 2, 2],
                num_heads_stripe=[2, 2, 2, 2],
                mlp_ratio=2,
                qkv_proj_type="linear",
                anchor_proj_type="avgpool",
                anchor_window_down_factor=2,
                out_proj_type="linear",
                conv_type="1conv",
                upsampler="nearest+conv",  # æ›´æ”¹
            ).cuda()

        else:
            raise ValueError("This weight is not supported")

        generator.load_state_dict(weight)
        generator = generator.eval().cuda()

        # è®¡ç®—å‚æ•°æ•°é‡
        num_params = 0
        for p in generator.parameters():
            if p.requires_grad:
                num_params += p.numel()

        elapsed = time.time() - start_time
        self.log(f"GRLæ¨¡å‹åŠ è½½è€—æ—¶: {elapsed:.2f}ç§’")
        self.log(f"GRLæ¨¡å‹å‚æ•°æ•°é‡: {num_params / 10 ** 6: 0.2f}M")

        return generator

    def load_dat(self, generator_weight_PATH, scale=4):
        '''åŠ è½½DATæ¨¡å‹'''
        start_time = time.time()

        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint_g = torch.load(generator_weight_PATH)

        # æŸ¥æ‰¾ç”Ÿæˆå™¨æƒé‡
        if 'model_state_dict' in checkpoint_g:
            weight = checkpoint_g['model_state_dict']

            # é»˜è®¤çš„DATå°æ¨¡å‹
            generator = DAT(upscale=4,
                            in_chans=3,
                            img_size=64,
                            img_range=1.,
                            depth=[6, 6, 6, 6, 6, 6],
                            embed_dim=180,
                            num_heads=[6, 6, 6, 6, 6, 6],
                            expansion_factor=2,
                            resi_connection='1conv',
                            split_size=[8, 16],
                            upsampler='pixelshuffledirect',
                            ).cuda()

        else:
            raise ValueError("This weight is not supported")

        generator.load_state_dict(weight)
        generator = generator.eval().cuda()

        # è®¡ç®—å‚æ•°æ•°é‡
        num_params = 0
        for p in generator.parameters():
            if p.requires_grad:
                num_params += p.numel()

        elapsed = time.time() - start_time
        self.log(f"DATæ¨¡å‹åŠ è½½è€—æ—¶: {elapsed:.2f}ç§’")
        self.log(f"DATæ¨¡å‹å‚æ•°æ•°é‡: {num_params / 10 ** 6: 0.2f}M")

        return generator

    # ============================================================
    # é‡å¤å¸§æ£€æµ‹å‡½æ•°
    # ============================================================

    def calculate_frame_hash(self, frame):
        """è®¡ç®—å¸§çš„æ„ŸçŸ¥å“ˆå¸Œå€¼ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        start_time = time.time()

        # å…ˆç¼©å°å›¾åƒä»¥å‡å°‘è®¡ç®—é‡
        h, w = frame.shape[:2]
        if h > 360 or w > 480:
            new_h = 360
            new_w = int(w * (360 / h))
            frame_resized = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        else:
            frame_resized = frame

        frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
        pil_img = Image.fromarray(frame_rgb)

        # ä½¿ç”¨æ›´é«˜æ•ˆçš„å“ˆå¸Œæ–¹æ³•
        frame_hash = imagehash.phash(pil_img, hash_size=8)  # å‡å°å“ˆå¸Œå¤§å°ä»¥æé«˜è®¡ç®—é€Ÿåº¦

        elapsed = time.time() - start_time
        return frame_hash, elapsed

    def calculate_ssim_fast(self, frame1, frame2):
        """å¿«é€Ÿè®¡ç®—SSIMï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        start_time = time.time()

        # å°†å›¾åƒç¼©å°ä»¥åŠ é€Ÿè®¡ç®—
        h1, w1 = frame1.shape[:2]
        h2, w2 = frame2.shape[:2]

        # ä½¿ç”¨è¾ƒå°çš„å›ºå®šå°ºå¯¸
        target_size = (180, 320)  # 16:9çš„æ¯”ä¾‹

        # å¦‚æœå›¾åƒæ¯”ç›®æ ‡å°ºå¯¸å¤§ï¼Œåˆ™ç¼©å°
        if h1 > target_size[0] or w1 > target_size[1]:
            scale_factor = min(target_size[0] / h1, target_size[1] / w1)
            new_h = int(h1 * scale_factor)
            new_w = int(w1 * scale_factor)
            gray1 = cv2.resize(cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY), (new_w, new_h))
        else:
            gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)

        if h2 > target_size[0] or w2 > target_size[1]:
            scale_factor = min(target_size[0] / h2, target_size[1] / w2)
            new_h = int(h2 * scale_factor)
            new_w = int(w2 * scale_factor)
            gray2 = cv2.resize(cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY), (new_w, new_h))
        else:
            gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)

        try:
            ssim_value, _ = ssim(gray1, gray2, full=True, data_range=255)
            elapsed = time.time() - start_time
            return ssim_value, elapsed
        except:
            return 0.0, time.time() - start_time

    def check_frame_duplicate_enhanced(self, frame, frame_idx):
        """å¢å¼ºç‰ˆé‡å¤å¸§æ£€æµ‹ï¼Œæ£€æŸ¥æœ€è¿‘Nå¸§"""
        if not self.enable_dup_detect_var.get() or not self.frame_history:
            return False, None, None, None

        total_start_time = time.time()
        history_size = len(self.frame_history)

        current_hash = None
        current_thumbnail = None

        # è®¡ç®—å½“å‰å¸§çš„ä¿¡æ¯ï¼ˆæŒ‰éœ€è®¡ç®—ï¼‰
        hash_time = 0
        if self.use_hash_var.get():
            hash_start = time.time()
            current_hash, hash_time = self.calculate_frame_hash(frame)
            hash_time = time.time() - hash_start

        ssim_thumbnail_time = 0
        if self.use_ssim_var.get():
            # ä¿å­˜ç¼©ç•¥å›¾ç”¨äºSSIMè®¡ç®—
            thumb_start = time.time()
            h, w = frame.shape[:2]
            if h > 180 or w > 320:
                new_h = 180
                new_w = int(w * (180 / h))
                current_thumbnail = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
            else:
                current_thumbnail = frame.copy()
            ssim_thumbnail_time = time.time() - thumb_start

        # è·å–é˜ˆå€¼
        hash_threshold = int(self.hash_threshold_var.get())
        ssim_threshold = float(self.ssim_threshold_var.get())

        # ä»æœ€è¿‘å¸§å¼€å§‹æ£€æŸ¥ï¼ˆæ—¶é—´ä¸Šè¶Šæ¥è¿‘è¶Šå¯èƒ½é‡å¤ï¼‰
        best_match_idx = -1
        best_match_reason = ""
        best_hash_diff = None
        best_ssim_value = None
        detected_hash_diff = None
        detected_ssim_value = None

        # éå†å†å²å¸§ï¼ˆä»æœ€è¿‘çš„å¼€å§‹ï¼‰
        compare_start = time.time()
        ssim_compare_time = 0
        hash_compare_time = 0

        for i, (hist_frame, hist_hash, hist_thumbnail, hist_sr_result, hist_frame_idx) in enumerate(
                zip(self.frame_history, self.frame_hash_history,
                    self.frame_thumbnail_history if self.use_ssim_var.get() else [None] * len(self.frame_history),
                    self.frame_sr_history,
                    self.frame_idx_history)):

            # è·³è¿‡æ— æ•ˆè®°å½•
            if hist_frame is None or hist_sr_result is None:
                continue

            # å¦‚æœä½¿ç”¨å“ˆå¸Œæ£€æµ‹
            if self.use_hash_var.get() and current_hash is not None and hist_hash is not None:
                hash_compare_start = time.time()
                hash_diff = current_hash - hist_hash
                hash_compare_time += time.time() - hash_compare_start

                # è®°å½•å“ˆå¸Œå·®å€¼ï¼ˆç”¨äºæ—¥å¿—è¾“å‡ºï¼‰
                detected_hash_diff = hash_diff

                if hash_diff <= hash_threshold:
                    # å¦‚æœåŒæ—¶å¯ç”¨äº†SSIMæ£€æµ‹ï¼Œéœ€è¦éªŒè¯SSIM
                    if self.use_ssim_var.get():
                        ssim_compare_start = time.time()
                        ssim_value, ssim_elapsed = self.calculate_ssim_fast(frame, hist_frame)
                        ssim_compare_time += ssim_elapsed

                        # è®°å½•SSIMå€¼ï¼ˆç”¨äºæ—¥å¿—è¾“å‡ºï¼‰
                        detected_ssim_value = ssim_value

                        if ssim_value >= ssim_threshold:
                            best_match_idx = i
                            best_match_reason = f"å“ˆå¸Œ({hash_diff})å’ŒSSIM({ssim_value:.3f})åŒ¹é…"
                            best_hash_diff = hash_diff
                            best_ssim_value = ssim_value
                            break
                    else:
                        # åªä½¿ç”¨å“ˆå¸Œæ£€æµ‹
                        best_match_idx = i
                        best_match_reason = f"å“ˆå¸ŒåŒ¹é…(å·®å¼‚:{hash_diff})"
                        best_hash_diff = hash_diff
                        break
            # å¦‚æœåªä½¿ç”¨SSIMæ£€æµ‹
            elif self.use_ssim_var.get() and current_thumbnail is not None and hist_thumbnail is not None:
                ssim_compare_start = time.time()
                ssim_value, ssim_elapsed = self.calculate_ssim_fast(frame, hist_frame)
                ssim_compare_time += ssim_elapsed

                # è®°å½•SSIMå€¼ï¼ˆç”¨äºæ—¥å¿—è¾“å‡ºï¼‰
                detected_ssim_value = ssim_value

                if ssim_value >= ssim_threshold:
                    best_match_idx = i
                    best_match_reason = f"SSIMåŒ¹é…({ssim_value:.3f})"
                    best_ssim_value = ssim_value
                    break

        compare_time = time.time() - compare_start
        total_elapsed = time.time() - total_start_time

        # æ„å»ºæ£€æµ‹å€¼å­—ç¬¦ä¸²
        detection_values = []
        if self.use_hash_var.get() and detected_hash_diff is not None:
            detection_values.append(f"å“ˆå¸Œå·®: {detected_hash_diff}")
        if self.use_ssim_var.get() and detected_ssim_value is not None:
            detection_values.append(f"SSIM: {detected_ssim_value:.3f}")

        detection_str = "ï¼Œ".join(detection_values)

        if best_match_idx >= 0:
            # æ‰¾åˆ°åŒ¹é…çš„å¸§
            matched_sr_result = self.frame_sr_history[best_match_idx]
            matched_frame_idx = self.frame_idx_history[best_match_idx]

            # æ„å»ºè¯¦ç»†çš„æ—¶é—´ç»Ÿè®¡
            time_stats = []
            if hash_time > 0:
                time_stats.append(f"å“ˆå¸Œ:{hash_time:.3f}s")
            if ssim_thumbnail_time > 0:
                time_stats.append(f"ç¼©ç•¥å›¾:{ssim_thumbnail_time:.3f}s")
            if hash_compare_time > 0:
                time_stats.append(f"å“ˆå¸Œæ¯”è¾ƒ:{hash_compare_time:.3f}s")
            if ssim_compare_time > 0:
                time_stats.append(f"SSIMæ¯”è¾ƒ:{ssim_compare_time:.3f}s")

            time_str = "ï¼Œ".join(time_stats) if time_stats else ""

            # æ„å»ºæ—¥å¿—æ¶ˆæ¯
            log_message = f"å¸§ {frame_idx:04d}: ä¸å¸§ {matched_frame_idx:04d} é‡å¤"
            if detection_str:
                log_message += f" ({detection_str})"
            if time_str:
                log_message += f" [{time_str}]"
            log_message += f" - æ€»è€—æ—¶:{total_elapsed:.3f}s"

            self.log(log_message)

            self.dup_frame_count += 1
            self.update_dup_info(self.dup_frame_count)

            # æ›´æ–°å†å²å¸§ä¿¡æ¯ï¼ˆå°†åŒ¹é…å¸§ç§»åˆ°æœ€è¿‘ä½ç½®ï¼‰
            if best_match_idx > 0:  # å¦‚æœä¸æ˜¯å·²ç»åœ¨æœ€å‰é¢
                # é‡æ–°æ’åˆ—å†å²è®°å½•ï¼Œå°†åŒ¹é…å¸§ç§»åˆ°æœ€è¿‘ä½ç½®
                items_to_move = [
                    self.frame_history[best_match_idx],
                    self.frame_hash_history[best_match_idx],
                    self.frame_thumbnail_history[best_match_idx] if self.use_ssim_var.get() else None,
                    self.frame_sr_history[best_match_idx],
                    self.frame_idx_history[best_match_idx]
                ]

                # ç§»é™¤åŒ¹é…å¸§
                del self.frame_history[best_match_idx]
                del self.frame_hash_history[best_match_idx]
                if self.use_ssim_var.get():
                    del self.frame_thumbnail_history[best_match_idx]
                del self.frame_sr_history[best_match_idx]
                del self.frame_idx_history[best_match_idx]

                # æ’å…¥åˆ°æœ€å‰é¢ï¼ˆæœ€è¿‘ä½ç½®ï¼‰
                self.frame_history.appendleft(items_to_move[0])
                self.frame_hash_history.appendleft(items_to_move[1])
                if self.use_ssim_var.get():
                    self.frame_thumbnail_history.appendleft(items_to_move[2])
                self.frame_sr_history.appendleft(items_to_move[3])
                self.frame_idx_history.appendleft(items_to_move[4])

            return True, matched_sr_result.copy(), current_hash, current_thumbnail

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…å¸§
        else:
            # æ„å»ºè¯¦ç»†çš„æ—¶é—´ç»Ÿè®¡
            time_stats = []
            if hash_time > 0:
                time_stats.append(f"å“ˆå¸Œ:{hash_time:.3f}s")
            if ssim_thumbnail_time > 0:
                time_stats.append(f"ç¼©ç•¥å›¾:{ssim_thumbnail_time:.3f}s")
            if hash_compare_time > 0:
                time_stats.append(f"å“ˆå¸Œæ¯”è¾ƒ:{hash_compare_time:.3f}s")
            if ssim_compare_time > 0:
                time_stats.append(f"SSIMæ¯”è¾ƒ:{ssim_compare_time:.3f}s")

            time_str = "ï¼Œ".join(time_stats) if time_stats else ""

            # æ„å»ºæ—¥å¿—æ¶ˆæ¯
            log_message = f"å¸§ {frame_idx:04d}: æœªé‡å¤"
            if detection_str:
                log_message += f" ({detection_str})"
            if time_str:
                log_message += f" [{time_str}]"

            # åªåœ¨æ£€æµ‹è€—æ—¶è¾ƒé•¿æ—¶è¾“å‡ºæ—¥å¿—
            if total_elapsed > 0.05:  # åªè®°å½•è€—æ—¶è¾ƒé•¿çš„æ£€æµ‹
                log_message += f" - æ€»è€—æ—¶:{total_elapsed:.3f}s"
                self.log(log_message)

        return False, None, current_hash, current_thumbnail

    def add_frame_to_history(self, frame, frame_hash, frame_thumbnail, sr_result, frame_idx):
        """æ·»åŠ å¸§åˆ°å†å²è®°å½•"""
        # æ·»åŠ å¸§æ•°æ®
        self.frame_history.append(frame.copy())
        self.frame_hash_history.append(frame_hash)
        if self.use_ssim_var.get():
            self.frame_thumbnail_history.append(frame_thumbnail)

        self.frame_sr_history.append(sr_result.copy() if sr_result is not None else None)
        self.frame_idx_history.append(frame_idx)

    # ============================================================
    # è§†é¢‘å¤„ç†å‡½æ•°
    # ============================================================

    def extract_audio(self, video_path, audio_path):
        """æå–éŸ³é¢‘"""
        start_time = time.time()

        cmd = [
            'ffmpeg', '-y',
            '-i', video_path,
            '-vn',
            '-acodec', 'copy',
            '-loglevel', 'quiet',
            audio_path
        ]

        try:
            subprocess.run(cmd, check=True, capture_output=True, text=True)

            elapsed = time.time() - start_time
            self.log(f"éŸ³é¢‘æå–è€—æ—¶: {elapsed:.2f}ç§’")
            return True
        except subprocess.CalledProcessError as e:
            self.log(f"æå–éŸ³é¢‘å¤±è´¥: {e.stderr}")
            return False

    def split_video_by_keyframes(self, video_path, segment_duration, output_dir):
        """æŒ‰å…³é”®å¸§åˆ†å‰²è§†é¢‘"""
        self.log(f"å¼€å§‹åˆ†å‰²è§†é¢‘: {os.path.basename(video_path)}")
        start_time = time.time()

        segments = []

        # åˆ›å»ºåˆ†æ®µç›®å½•
        segment_dir = os.path.join(output_dir, "01_original_segments")
        os.makedirs(segment_dir, exist_ok=True)

        # ä½¿ç”¨ffmpegåˆ†å‰²è§†é¢‘
        segment_pattern = os.path.join(segment_dir, "segment_%03d.mp4")

        cmd = [
            'ffmpeg', '-y',
            '-i', video_path,
            '-c', 'copy',
            '-map', '0',
            '-segment_time', str(segment_duration),
            '-f', 'segment',
            '-reset_timestamps', '1',
            '-segment_format', 'mp4',
            '-segment_list', os.path.join(segment_dir, "segments_list.txt"),
            segment_pattern
        ]

        try:
            subprocess.run(cmd, check=True, capture_output=True, text=True)

            # è·å–ç”Ÿæˆçš„åˆ†æ®µæ–‡ä»¶
            for f in sorted(os.listdir(segment_dir)):
                if f.startswith("segment_") and f.endswith(".mp4"):
                    segment_file = os.path.join(segment_dir, f)
                    segments.append(segment_file)

            elapsed = time.time() - start_time
            self.log(f"è§†é¢‘åˆ†å‰²å®Œæˆï¼Œå…±{len(segments)}æ®µï¼Œè€—æ—¶: {elapsed:.2f}ç§’")

        except subprocess.CalledProcessError as e:
            self.log(f"è§†é¢‘åˆ†å‰²å¤±è´¥: {e.stderr}")
            return []

        return segments

    def load_model(self):
        """åŠ è½½æ¨¡å‹ï¼ˆæµ‹è¯•æ¨¡å¼ä¸‹ä¸åŠ è½½ï¼‰"""
        if self.test_mode_var.get():
            self.log("æµ‹è¯•æ¨¡å¼ï¼šè·³è¿‡æ¨¡å‹åŠ è½½")
            return None

        model_name = self.model_var.get()
        scale = int(self.scale_var.get())

        # ç¡®å®šæƒé‡è·¯å¾„
        if model_name == "RRDB":
            weight_path = self.models[model_name]["weight"][str(scale)]
        else:
            weight_path = self.models[model_name]["weight"]

        # æ£€æŸ¥æƒé‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(weight_path):
            raise FileNotFoundError(f"æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {weight_path}")

        self.log(f"åŠ è½½æ¨¡å‹: {model_name}, ç¼©æ”¾: {scale}x")
        self.log(f"æƒé‡æ–‡ä»¶: {weight_path}")

        # è®¾ç½®æ•°æ®ç±»å‹
        if self.float16_var.get():
            torch.backends.cudnn.benchmark = True
            self.weight_dtype = torch.float16
            self.log("ä½¿ç”¨FP16æ¨ç†æ¨¡å¼ï¼ˆåŠ é€Ÿï¼‰")
        else:
            self.weight_dtype = torch.float32
            self.log("ä½¿ç”¨FP32æ¨ç†æ¨¡å¼ï¼ˆè´¨é‡ä¼˜å…ˆï¼‰")

        # åŠ è½½æ¨¡å‹
        model_load_start = time.time()
        if model_name == "GRL":
            generator = self.load_grl(weight_path, scale=scale)
        elif model_name == "DAT":
            generator = self.load_dat(weight_path, scale=scale)
        elif model_name == "RRDB":
            generator = self.load_rrdb(weight_path, scale=scale)
        elif model_name == "CUNET":
            generator = self.load_cunet(weight_path, scale=scale)
        else:
            raise ValueError(f"æœªçŸ¥æ¨¡å‹: {model_name}")

        generator = generator.to(dtype=self.weight_dtype)
        generator.eval()

        # ç§»åŠ¨åˆ°GPU
        if torch.cuda.is_available():
            generator = generator.cuda()

        model_load_end = time.time()
        self.log(f"æ¨¡å‹åŠ è½½æ€»è€—æ—¶: {model_load_end - model_load_start:.2f}ç§’")

        return generator

    def process_single_frame(self, frame):
        """å¤„ç†å•å¸§å›¾åƒ - ä¿®å¤å†…å­˜æ³„æ¼ç‰ˆæœ¬"""
        start_time = time.time()

        if self.test_mode_var.get():
            # æµ‹è¯•æ¨¡å¼ä¸å¤„ç†ï¼Œç›´æ¥è¿”å›RGBæ ¼å¼
            elapsed = time.time() - start_time
            return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # è¿”å›RGBæ ¼å¼

        from torchvision.transforms import ToTensor

        # é¢„å¤„ç†é˜¶æ®µæ—¶é—´ç»Ÿè®¡
        preprocess_start = time.time()

        # é¢„å¤„ç† - è½¬æ¢ä¸ºRGB
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        h, w, _ = frame_rgb.shape
        original_h, original_w = h, w

        # ä¸‹é‡‡æ ·ï¼ˆå¦‚æœéœ€è¦ï¼‰
        scale = int(self.scale_var.get())
        downsample_threshold = int(self.downsample_threshold.get())

        short_side = min(h, w)

        if downsample_threshold != -1 and short_side > downsample_threshold:
            rescale_factor = short_side / downsample_threshold
            new_w = int(w / rescale_factor)
            new_h = int(h / rescale_factor)
            frame_rgb = cv2.resize(frame_rgb, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
            # ç«‹å³æ¸…ç†ä¸­é—´å˜é‡
            del frame
            frame = None

        # è£å‰ªï¼ˆå¦‚æœéœ€è¦ï¼‰
        if self.crop_for_4x_var.get() and scale == 4:
            h, w, _ = frame_rgb.shape
            if h % 4 != 0:
                frame_rgb = frame_rgb[:4 * (h // 4), :, :]
            if w % 4 != 0:
                frame_rgb = frame_rgb[:, :4 * (w // 4), :]

        preprocess_time = time.time() - preprocess_start

        # æ¨ç†é˜¶æ®µæ—¶é—´ç»Ÿè®¡
        inference_start = time.time()

        # è½¬æ¢ä¸ºtensorå¹¶è¿›è¡Œæ¨ç†
        img_tensor = ToTensor()(frame_rgb).unsqueeze(0)  # å½¢çŠ¶: [1, 3, H, W]

        # ç«‹å³æ¸…ç†ä¸å†éœ€è¦çš„å˜é‡
        del frame_rgb
        frame_rgb = None

        if torch.cuda.is_available():
            img_tensor = img_tensor.cuda()

        img_tensor = img_tensor.to(dtype=self.weight_dtype)

        # æ¨ç†
        with torch.no_grad():
            result = self.generator(img_tensor)

        inference_time = time.time() - inference_start

        # åå¤„ç†é˜¶æ®µæ—¶é—´ç»Ÿè®¡
        postprocess_start = time.time()

        # å°†ç»“æœç§»åŠ¨åˆ°CPUï¼Œå¹¶é‡Šæ”¾GPUå†…å­˜
        result_cpu = result[0].cpu().detach()

        # ç«‹å³æ¸…ç†GPUå˜é‡
        del img_tensor
        del result
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()

        # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œè°ƒæ•´é€šé“é¡ºåºï¼Œå¹¶ç¼©æ”¾åˆ°0-255
        result_np = result_cpu.numpy()
        result_np = np.transpose(result_np, (1, 2, 0))  # ä» [C, H, W] è½¬æ¢ä¸º [H, W, C]
        result_np = np.clip(result_np * 255.0, 0, 255).astype(np.uint8)

        # æ¸…ç†ä¸­é—´å˜é‡
        del result_cpu

        # å¦‚æœéœ€è¦ï¼Œç¼©æ”¾å›åŸå§‹å¤§å°
        if downsample_threshold != -1 and short_side > downsample_threshold:
            output_h = int(original_h * scale)
            output_w = int(original_w * scale)
            result_np = cv2.resize(result_np, (output_w, output_h), interpolation=cv2.INTER_LINEAR)

        postprocess_time = time.time() - postprocess_start
        total_elapsed = time.time() - start_time

        # è®°å½•è¯¦ç»†çš„æ—¶é—´ç»Ÿè®¡ï¼ˆåªè®°å½•è€—æ—¶è¾ƒé•¿çš„å¸§å¤„ç†ï¼‰
        if total_elapsed > 0.2:  # åªè®°å½•è¶…è¿‡200msçš„å¸§å¤„ç†
            self.log(f"å¸§å¤„ç†è€—æ—¶: {total_elapsed:.3f}s [é¢„å¤„ç†:{preprocess_time:.3f}s, "
                     f"æ¨ç†:{inference_time:.3f}s, åå¤„ç†:{postprocess_time:.3f}s]")

        return result_np

    def process_frame_with_enhanced_dup_detect(self, frame, frame_idx):
        """å¤„ç†å•å¸§ï¼ŒåŒ…å«å¢å¼ºçš„é‡å¤å¸§æ£€æµ‹ - ä¿®å¤å†…å­˜æ³„æ¼ç‰ˆæœ¬"""
        start_time = time.time()
        is_duplicate = False

        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤å¸§
            is_duplicate, matched_sr_result, current_hash, current_thumbnail = \
                self.check_frame_duplicate_enhanced(frame, frame_idx)

            if is_duplicate and matched_sr_result is not None:
                # æ‰¾åˆ°é‡å¤å¸§ï¼Œç›´æ¥ä½¿ç”¨å†å²è¶…åˆ†è¾¨ç‡ç»“æœ
                result_np = matched_sr_result.copy()  # åˆ›å»ºå‰¯æœ¬

                # è®¡ç®—å½“å‰å¸§çš„ä¿¡æ¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if current_hash is None and self.use_hash_var.get():
                    current_hash, _ = self.calculate_frame_hash(frame)
                if current_thumbnail is None and self.use_ssim_var.get():
                    h, w = frame.shape[:2]
                    if h > 180 or w > 320:
                        new_h = 180
                        new_w = int(w * (180 / h))
                        current_thumbnail = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
                    else:
                        current_thumbnail = frame.copy()

                # æ·»åŠ å¸§åˆ°å†å²è®°å½•
                self.add_frame_to_history(frame, current_hash, current_thumbnail, result_np, frame_idx)

                total_elapsed = time.time() - start_time
                return result_np, current_hash, current_thumbnail, is_duplicate

            # éé‡å¤å¸§ï¼Œè¿›è¡Œè¶…åˆ†è¾¨ç‡å¤„ç†
            process_start = time.time()
            result_np = self.process_single_frame(frame)
            process_time = time.time() - process_start

            # è®¡ç®—å½“å‰å¸§çš„ä¿¡æ¯
            if self.use_hash_var.get():
                hash_start = time.time()
                if current_hash is None:
                    current_hash, hash_time = self.calculate_frame_hash(frame)
                else:
                    hash_time = time.time() - hash_start
            else:
                hash_time = 0

            if self.use_ssim_var.get() and current_thumbnail is None:
                h, w = frame.shape[:2]
                if h > 180 or w > 320:
                    new_h = 180
                    new_w = int(w * (180 / h))
                    current_thumbnail = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
                else:
                    current_thumbnail = frame.copy()

            # æ›´æ–°å†å²è®°å½•
            self.add_frame_to_history(frame, current_hash, current_thumbnail, result_np, frame_idx)

            total_time = time.time() - start_time

            # å®šæœŸæ¸…ç†å†…å­˜
            if frame_idx % 50 == 0:
                self.cleanup_memory()

            if total_time > 0.3:  # åªè®°å½•è€—æ—¶è¾ƒé•¿çš„å¸§å¤„ç†
                self.log(f"å¸§ {frame_idx:04d}: è¶…åˆ†å¤„ç†è€—æ—¶: {process_time:.3f}sï¼Œæ€»è€—æ—¶: {total_time:.3f}s")

            return result_np, current_hash, current_thumbnail, is_duplicate

        except Exception as e:
            self.log(f"å¸§ {frame_idx} å¤„ç†å‡ºé”™: {e}")
            # å‘ç”Ÿé”™è¯¯æ—¶æ¸…ç†å†…å­˜
            self.cleanup_memory()
            raise

    def detect_progress_from_folders(self):
        """ä»æ–‡ä»¶å¤¹å†…å®¹æ£€æµ‹è¿›åº¦"""
        if not self.temp_base_dir or not os.path.exists(self.temp_base_dir):
            return 0, 0, []

        self.log("å¼€å§‹ä»æ–‡ä»¶å¤¹æ£€æµ‹è¿›åº¦...")

        # 1. ä»04_processed_segmentsæ–‡ä»¶å¤¹è·å–å·²å¤„ç†çš„ç‰‡æ®µ
        processed_dir = os.path.join(self.temp_base_dir, "04_processed_segments")
        processed_segments = []
        if os.path.exists(processed_dir):
            for f in os.listdir(processed_dir):
                if f.startswith("processed_segment_") and f.endswith(".mp4"):
                    # æå–ç‰‡æ®µç¼–å·ï¼Œå¦‚processed_segment_001.mp4 -> 1
                    try:
                        segment_num = int(f.split('_')[2].split('.')[0])
                        processed_segments.append(segment_num)
                    except:
                        pass

        # 2. ä»03_segment_framesæ–‡ä»¶å¤¹è·å–å½“å‰å¤„ç†çš„ç‰‡æ®µå’Œå¸§
        frames_dir = os.path.join(self.temp_base_dir, "03_segment_frames")
        current_segment = 0
        current_frame = 0

        if os.path.exists(frames_dir):
            # æŸ¥æ‰¾æ‰€æœ‰afteræ–‡ä»¶å¤¹
            after_dirs = []
            for item in os.listdir(frames_dir):
                item_path = os.path.join(frames_dir, item)
                if os.path.isdir(item_path) and item.endswith("_after"):
                    after_dirs.append(item_path)

            if after_dirs:
                # æŒ‰æ–‡ä»¶å¤¹åæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
                after_dirs.sort(key=lambda x: os.path.basename(x))

                # å¤„ç†æœ€æ–°çš„afteræ–‡ä»¶å¤¹
                latest_after_dir = after_dirs[-1]
                dir_name = os.path.basename(latest_after_dir)

                # æå–ç‰‡æ®µåç§°ï¼Œå¦‚segment_000_after -> segment_000
                try:
                    current_segment_name = dir_name.replace("_after", "")
                    # ä»segment_000è·å–æ•°å­—éƒ¨åˆ†
                    if current_segment_name.startswith("segment_"):
                        try:
                            current_segment = int(current_segment_name.split('_')[1])
                        except:
                            current_segment = 0
                except:
                    current_segment = 0

                # è®¡ç®—å·²å¤„ç†çš„å¸§æ•°
                if os.path.exists(latest_after_dir):
                    frame_files = [f for f in os.listdir(latest_after_dir)
                                   if f.startswith("frame_") and f.endswith(".png")]
                    if frame_files:
                        # æŒ‰æ–‡ä»¶åæ’åºï¼Œè·å–æœ€å¤§çš„å¸§å·
                        frame_files.sort()
                        last_frame = frame_files[-1]
                        try:
                            current_frame = int(last_frame.split('_')[1].split('.')[0]) + 1
                        except:
                            current_frame = 0

        # 3. ç¡®å®šä¸‹ä¸€ä¸ªè¦å¤„ç†çš„ç‰‡æ®µ
        if processed_segments:
            last_processed = max(processed_segments)
            next_segment = last_processed + 1
        else:
            next_segment = 1

        # å¦‚æœå½“å‰ç‰‡æ®µå·²ç»æœ‰å¸§åœ¨å¤„ç†ï¼Œä½¿ç”¨å½“å‰ç‰‡æ®µ
        if current_frame > 0:
            next_segment = current_segment

        self.log(f"è¿›åº¦æ£€æµ‹ç»“æœ: ä¸‹ä¸€ä¸ªç‰‡æ®µ={next_segment}, å½“å‰å¸§={current_frame}")
        return next_segment, current_frame, processed_segments

    def process_segment_frames(self, segment_path, segment_index):
        """å¤„ç†è§†é¢‘ç‰‡æ®µçš„æ‰€æœ‰å¸§ï¼ˆé€å¸§å¤„ç†ï¼‰- ä¿®å¤ï¼šå§‹ç»ˆç”Ÿæˆè§†é¢‘ç‰‡æ®µå¹¶åˆ é™¤ä¸´æ—¶å¸§æ–‡ä»¶"""
        segment_name = os.path.basename(segment_path)
        self.log(f"å¤„ç†ç‰‡æ®µ {segment_index}: {segment_name}")
        segment_start_time = time.time()

        if self.test_mode_var.get():
            self.log("æµ‹è¯•æ¨¡å¼ï¼šä»…è¿›è¡Œé‡å¤å¸§æ£€æµ‹ï¼Œä¸è¿›è¡Œè¶…åˆ†è¾¨ç‡å¤„ç†")
            # æµ‹è¯•æ¨¡å¼ä¸ç”Ÿæˆè§†é¢‘ï¼Œä½†ä¼šä¿ç•™å¸§æ–‡ä»¶ä¾›æ£€æŸ¥
            return None, None

        # åˆå§‹åŒ–å†å²å¸§ç¼“å­˜
        self.init_history_cache()

        # æ›´æ–°é‡å¤å¸§è®¡æ•°ï¼ˆå·²é‡ç½®ä¸º0ï¼‰
        self.update_dup_info(self.dup_frame_count)

        # ä¸ºå½“å‰ç‰‡æ®µåˆ›å»ºå¸§ç›®å½•ï¼ˆç›´æ¥åˆ›å»ºåœ¨03_segment_framesä¸‹ï¼‰
        setup_start = time.time()
        before_dir, after_dir = self.setup_segment_frame_dirs(segment_path)
        setup_time = time.time() - setup_start

        if not before_dir or not after_dir:
            self.log("é”™è¯¯ï¼šæ— æ³•åˆ›å»ºå¸§ç›®å½•")
            return None, None

        self.log(f"ç›®å½•è®¾ç½®è€—æ—¶: {setup_time:.2f}ç§’")

        # æå–éŸ³é¢‘
        audio_name = segment_name.replace('.mp4', '.aac')
        audio_path = os.path.join(self.temp_base_dir, "02_audio", audio_name)

        audio_start = time.time()
        has_audio = self.extract_audio(segment_path, audio_path)
        audio_time = time.time() - audio_start

        if has_audio:
            self.log(f"éŸ³é¢‘æå–æˆåŠŸï¼Œè€—æ—¶: {audio_time:.2f}ç§’")
        else:
            self.log("è§†é¢‘æ— éŸ³é¢‘æˆ–éŸ³é¢‘æå–å¤±è´¥")

        # è¯»å–è§†é¢‘
        cap_start = time.time()
        cap = cv2.VideoCapture(segment_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        cap_time = time.time() - cap_start

        if total_frames == 0:
            self.log(f"è­¦å‘Š: æ— æ³•è·å–ç‰‡æ®µ {segment_path} çš„å¸§æ•°")
            cap.release()
            return None, None

        # è®¡ç®—è¾“å‡ºå°ºå¯¸
        scale = int(self.scale_var.get())
        downsample_threshold = int(self.downsample_threshold.get())

        short_side = min(height, width)
        if downsample_threshold != -1 and short_side > downsample_threshold:
            rescale_factor = short_side / downsample_threshold
        else:
            rescale_factor = 1

        # è¾“å‡ºå°ºå¯¸
        output_width = int(width * scale / rescale_factor)
        output_height = int(height * scale / rescale_factor)

        self.log(f"è§†é¢‘ä¿¡æ¯è·å–è€—æ—¶: {cap_time:.2f}ç§’")
        self.log(f"è¾“å…¥å°ºå¯¸: {width}x{height}, è¾“å‡ºå°ºå¯¸: {output_width}x{output_height}")

        # æ˜¾ç¤ºæ£€æµ‹å‚æ•°
        if self.enable_dup_detect_var.get():
            methods = []
            if self.use_hash_var.get():
                methods.append(f"å“ˆå¸Œ(é˜ˆå€¼:{self.hash_threshold_var.get()})")
            if self.use_ssim_var.get():
                methods.append(f"SSIM(é˜ˆå€¼:{self.ssim_threshold_var.get()})")

            if self.enable_history_var.get():
                history_size = int(self.history_size_var.get())
                self.log(f"é‡å¤å¸§æ£€æµ‹: {', '.join(methods)}ï¼Œå†å²å¸§: {history_size}")
            else:
                self.log(f"é‡å¤å¸§æ£€æµ‹: {', '.join(methods)}ï¼Œä»…ä¸å‰å¸§æ¯”è¾ƒ")

        # ä»è¿›åº¦æ£€æµ‹ä¸­è·å–èµ·å§‹å¸§
        start_frame = self.current_frame_in_segment
        if start_frame > 0:
            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
            self.log(f"ä»ç¬¬ {start_frame + 1} å¸§æ¢å¤å¤„ç†")

        frame_idx = start_frame
        frame_files = []

        # æ³¨æ„ï¼šå·²åˆ é™¤é‡å¤å¸§è®°å½•æ–‡ä»¶çš„åˆ›å»º

        # åˆå§‹åŒ–å¸§è®¡æ•°å™¨
        frames_processed = 0
        segment_dup_count = 0  # å½“å‰ç‰‡æ®µçš„é‡å¤å¸§æ•°

        # ç»Ÿè®¡è®¡æ—¶
        total_frame_time = 0
        total_dup_detect_time = 0
        total_sr_time = 0
        total_io_time = 0

        while True:
            # æ£€æŸ¥æ˜¯å¦è¢«åœæ­¢
            if self.stopped:
                self.log(f"åœæ­¢å¤„ç†ï¼šç‰‡æ®µ {segment_index} çš„ç¬¬ {frame_idx + 1} å¸§")
                self.log(f"å·²å¤„ç†çš„å¸§å·²ä¿å­˜åœ¨: {after_dir}")
                break

            # æ£€æŸ¥æ˜¯å¦æš‚åœ - ä½¿ç”¨é«˜æ•ˆç­‰å¾…
            if self.paused:
                self.log(f"å¤„ç†æš‚åœäºç‰‡æ®µ {segment_index} çš„ç¬¬ {frame_idx + 1} å¸§")

                # é‡Šæ”¾GPUå†…å­˜ä»¥é™ä½å ç”¨
                if self.generator is not None:
                    try:
                        # å°†æ¨¡å‹ç§»åŠ¨åˆ°CPUå¹¶é‡Šæ”¾GPUå†…å­˜
                        self.generator = self.generator.cpu()
                        torch.cuda.empty_cache()
                        torch.cuda.synchronize()  # ç­‰å¾…CUDAæ“ä½œå®Œæˆ
                        self.log("æ¨¡å‹å·²ç§»åŠ¨åˆ°CPUï¼ŒGPUå†…å­˜å·²é‡Šæ”¾")
                    except Exception as e:
                        self.log(f"ç§»åŠ¨æ¨¡å‹åˆ°CPUæ—¶å‡ºé”™: {e}")

                # é«˜æ•ˆç­‰å¾…ï¼Œè€Œä¸æ˜¯å¿™ç­‰å¾…
                self.pause_btn.config(text="â–¶ ç»§ç»­")
                self.update_status("å·²æš‚åœ", "orange")

                while self.paused and not self.stopped:
                    time.sleep(0.5)  # ä½¿ç”¨è¾ƒçŸ­çš„ä¼‘çœ æ—¶é—´ä»¥ä¾¿å¿«é€Ÿå“åº”

                # æ¢å¤å¤„ç†
                if not self.stopped:
                    if self.generator is not None:
                        try:
                            # å°†æ¨¡å‹ç§»å›GPU
                            self.generator = self.generator.cuda()
                            self.log("æ¨¡å‹å·²ç§»å›GPU")
                        except Exception as e:
                            self.log(f"ç§»åŠ¨æ¨¡å‹å›GPUæ—¶å‡ºé”™: {e}")

                    self.pause_btn.config(text="â¸ æš‚åœ")
                    self.update_status("å¤„ç†ä¸­...", "blue")
                    self.log(f"å¤„ç†ç»§ç»­äºç‰‡æ®µ {segment_index} çš„ç¬¬ {frame_idx + 1} å¸§")

                if self.stopped:
                    break

            # æ¯å¤„ç†50å¸§æ¸…ç†ä¸€æ¬¡å†…å­˜
            if frame_idx % 50 == 0:
                self.cleanup_memory()
                self.log(f"å·²æ¸…ç†å†…å­˜ï¼ˆå¤„ç†åˆ°ç¬¬ {frame_idx} å¸§ï¼‰")

            # æ¯å¤„ç†100å¸§æ¸…ç†ä¸€æ¬¡å†å²ç¼“å­˜
            if frame_idx % 100 == 0 and self.enable_dup_detect_var.get():
                self.clear_history_cache()
                self.init_history_cache()  # é‡æ–°åˆå§‹åŒ–
                self.log(f"å·²æ¸…ç©ºå†å²ç¼“å­˜ï¼ˆå¤„ç†åˆ°ç¬¬ {frame_idx} å¸§ï¼‰")

            # è¯»å–å¸§
            read_start = time.time()
            ret, frame = cap.read()
            read_time = time.time() - read_start
            total_io_time += read_time

            if not ret:
                break

            # ä¿å­˜åŸå§‹å¸§åˆ°beforeç›®å½•
            save_start = time.time()
            before_path = os.path.join(before_dir, f"frame_{frame_idx:06d}.png")
            cv2.imwrite(before_path, frame)
            save_time = time.time() - save_start
            total_io_time += save_time

            # ä½¿ç”¨å¢å¼ºçš„é‡å¤å¸§æ£€æµ‹å¤„ç†å¸§
            process_start = time.time()
            sr_frame, current_hash, current_thumbnail, is_duplicate = \
                self.process_frame_with_enhanced_dup_detect(frame, frame_idx)
            frame_process_time = time.time() - process_start

            if is_duplicate:
                total_dup_detect_time += frame_process_time
                segment_dup_count += 1
            else:
                total_sr_time += frame_process_time

            total_frame_time += frame_process_time

            # ä¿å­˜å¤„ç†åçš„å¸§åˆ°afterç›®å½•
            save_sr_start = time.time()
            after_path = os.path.join(after_dir, f"frame_{frame_idx:06d}.png")
            sr_frame_bgr = cv2.cvtColor(sr_frame, cv2.COLOR_RGB2BGR)
            cv2.imwrite(after_path, sr_frame_bgr)
            save_sr_time = time.time() - save_sr_start
            total_io_time += save_sr_time

            # æ·»åŠ åˆ°å¸§æ–‡ä»¶åˆ—è¡¨
            frame_files.append(after_path)

            # æ³¨æ„ï¼šå·²åˆ é™¤é‡å¤å¸§è®°å½•æ–‡ä»¶çš„å†™å…¥

            # æ›´æ–°å½“å‰å¸§
            self.current_frame_in_segment = frame_idx + 1
            frames_processed += 1

            # æ›´æ–°è¯¦ç»†è¿›åº¦
            self.update_detailed_progress(self.current_frame_in_segment, total_frames)

            # æ¯å¤„ç†10å¸§æ›´æ–°ä¸€æ¬¡è¿›åº¦
            if frames_processed % 10 == 0:
                progress = (self.current_frame_in_segment / total_frames) * 100
                self.update_progress(progress)

            frame_idx += 1

        cap.release()

        # è®°å½•ç‰‡æ®µå¤„ç†ç»Ÿè®¡
        segment_elapsed = time.time() - segment_start_time
        avg_frame_time = total_frame_time / max(frames_processed, 1) if frames_processed > 0 else 0

        self.log("=" * 60)
        self.log(f"ç‰‡æ®µå¤„ç†å®Œæˆç»Ÿè®¡:")
        self.log(f"  ç‰‡æ®µåç§°: {segment_name}")
        self.log(f"  æ€»è€—æ—¶: {segment_elapsed:.2f}ç§’")
        self.log(f"  å¤„ç†å¸§æ•°: {frames_processed}")
        if frames_processed > 0:
            self.log(f"  å¹³å‡æ¯å¸§è€—æ—¶: {avg_frame_time:.3f}ç§’")
            self.log(
                f"  é‡å¤å¸§æ£€æµ‹è€—æ—¶: {total_dup_detect_time:.2f}ç§’ ({total_dup_detect_time / segment_elapsed * 100:.1f}%)")
            self.log(f"  è¶…åˆ†è¾¨ç‡å¤„ç†è€—æ—¶: {total_sr_time:.2f}ç§’ ({total_sr_time / segment_elapsed * 100:.1f}%)")
            self.log(f"  æ–‡ä»¶IOè€—æ—¶: {total_io_time:.2f}ç§’ ({total_io_time / segment_elapsed * 100:.1f}%)")

        if self.enable_dup_detect_var.get():
            dup_percentage = (segment_dup_count / frames_processed * 100) if frames_processed > 0 else 0
            self.log(f"  æ£€æµ‹åˆ°é‡å¤å¸§: {segment_dup_count}ä¸ª ({dup_percentage:.1f}%)")
            if segment_dup_count > 0:
                self.log(f"  é‡å¤å¸§èŠ‚çœæ—¶é—´ä¼°ç®—: {segment_dup_count * avg_frame_time:.2f}ç§’")

        # æ¸…ç©ºå†å²ç¼“å­˜ä»¥é‡Šæ”¾å†…å­˜
        self.clear_history_cache()

        # åªæœ‰åœ¨ç‰‡æ®µå®Œå…¨å¤„ç†å®Œä¸”æ²¡æœ‰åœæ­¢æ—¶æ‰ç”Ÿæˆè§†é¢‘
        if not self.stopped and frame_idx >= total_frames and frame_files:
            # ç”Ÿæˆå¤„ç†åçš„ç‰‡æ®µè§†é¢‘
            processed_segment_path = os.path.join(self.temp_base_dir, "04_processed_segments",
                                                  f"processed_{segment_name}")

            # å°†å¸§è½¬æ¢ä¸ºè§†é¢‘
            encode_start = time.time()
            success = self.frames_to_video(frame_files, processed_segment_path, fps, output_width, output_height,
                                           audio_path)
            encode_time = time.time() - encode_start

            if success:
                self.log(f"ç‰‡æ®µè§†é¢‘ç¼–ç è€—æ—¶: {encode_time:.2f}ç§’")
                self.log(f"ç‰‡æ®µè§†é¢‘ç”ŸæˆæˆåŠŸ: {processed_segment_path}")

                # æ¸…ç†å½“å‰ç‰‡æ®µçš„å¸§ç›®å½•
                self.cleanup_segment_frame_dirs(segment_path)
                self.log(f"å·²æ¸…ç†ç‰‡æ®µ {segment_name} çš„å¸§ä¸´æ—¶æ–‡ä»¶ (beforeå’Œafterç›®å½•)")

                # å¦‚æœæœ‰ç«‹å³åˆå¹¶åŠŸèƒ½ï¼Œè°ƒç”¨åˆå¹¶
                if self.immediate_merge_var.get() and not self.test_mode_var.get():
                    self.update_immediate_merge()

                return processed_segment_path, audio_path
            else:
                self.log("ç‰‡æ®µè§†é¢‘ç”Ÿæˆå¤±è´¥")
                return None, None
        else:
            if self.stopped:
                self.log("å¤„ç†è¢«åœæ­¢ï¼Œä¸ç”Ÿæˆè§†é¢‘ç‰‡æ®µï¼Œä¿ç•™ä¸´æ—¶æ–‡ä»¶ä»¥ä¾¿ä¸‹æ¬¡ç»§ç»­å¤„ç†")
            elif not frame_files:
                self.log("æ²¡æœ‰å¸§æ–‡ä»¶å¯å¤„ç†")
            return None, None

    def check_opencv_encoder_support(self):
        """æ£€æŸ¥OpenCVç¼–ç å™¨æ”¯æŒ"""
        test_size = (100, 100)
        test_encoders = ['mp4v', 'avc1', 'MJPG', 'XVID']

        for encoder in test_encoders:
            try:
                fourcc = cv2.VideoWriter_fourcc(*encoder)
                out = cv2.VideoWriter(tempfile.mktemp(suffix='.mp4'), fourcc, 1, test_size)
                if out.isOpened():
                    out.release()
                    return True
            except:
                pass
        return False

    def frames_to_video(self, frame_files, output_path, fps, width, height, audio_path=None):
        """å°†å¸§åºåˆ—è½¬æ¢ä¸ºè§†é¢‘"""
        encoder_mode = self.video_encoder_mode.get()

        if encoder_mode == "ffmpeg" or (encoder_mode == "auto" and not self.check_opencv_encoder_support()):
            return self.frames_to_video_alternative(frame_files, output_path, fps, width, height, audio_path)
        else:
            return self.frames_to_video_opencv(frame_files, output_path, fps, width, height, audio_path)

    def frames_to_video_opencv(self, frame_files, output_path, fps, width, height, audio_path=None):
        """å°†å¸§åºåˆ—è½¬æ¢ä¸ºè§†é¢‘ï¼ˆä½¿ç”¨OpenCVï¼‰"""
        self.log(f"æ­£åœ¨ç”Ÿæˆè§†é¢‘: {output_path}")
        start_time = time.time()

        if not frame_files:
            self.log("é”™è¯¯: æ²¡æœ‰å¯ç”¨çš„å¸§æ–‡ä»¶")
            return False

        # åˆ›å»ºä¸´æ—¶è§†é¢‘æ–‡ä»¶ï¼ˆæ— éŸ³é¢‘ï¼‰
        temp_video_path = output_path.replace('.mp4', '_temp.mp4')

        # å°è¯•å¤šç§ç¼–ç å™¨ï¼Œé¿å…OpenH264é—®é¢˜
        encoders_to_try = [
            ('mp4v', 'mp4'),  # MPEG-4 ç¼–ç 
            ('MJPG', 'avi'),  # Motion JPEG
            ('XVID', 'avi'),  # XVID ç¼–ç 
            ('I420', 'avi'),  # YUV ç¼–ç 
            ('IYUV', 'avi'),  # YUV ç¼–ç 
            ('DIVX', 'avi')  # DivX ç¼–ç 
        ]

        out = None
        selected_encoder = None
        selected_ext = None

        # å°è¯•ä¸åŒçš„ç¼–ç å™¨
        for codec, ext in encoders_to_try:
            try:
                if ext == 'avi':
                    temp_video_path = output_path.replace('.mp4', '_temp.avi')
                else:
                    temp_video_path = output_path.replace('.mp4', '_temp.mp4')

                fourcc = cv2.VideoWriter_fourcc(*codec)
                out = cv2.VideoWriter(temp_video_path, fourcc, fps, (width, height))

                if out.isOpened():
                    selected_encoder = codec
                    selected_ext = ext
                    self.log(f"ä½¿ç”¨ç¼–ç å™¨: {codec}ï¼Œæ–‡ä»¶æ ¼å¼: {ext}")
                    break
                else:
                    out.release()
            except Exception as e:
                if out:
                    out.release()
                continue

        if not out or not out.isOpened():
            self.log("é”™è¯¯: æ— æ³•åˆ›å»ºè§†é¢‘å†™å…¥å™¨ï¼Œå°è¯•ä½¿ç”¨ffmpegæ–¹å¼")
            return self.frames_to_video_alternative(frame_files, output_path, fps, width, height, audio_path)

        # æŒ‰é¡ºåºå†™å…¥æ‰€æœ‰å¸§
        write_start = time.time()
        frame_count = 0
        read_time = 0
        write_time = 0

        for frame_file in sorted(frame_files):
            if os.path.exists(frame_file):
                read_start = time.time()
                frame = cv2.imread(frame_file)
                read_time += time.time() - read_start

                if frame is not None:
                    # ç¡®ä¿å¸§çš„å¤§å°ä¸è§†é¢‘å†™å…¥å™¨åŒ¹é…
                    if frame.shape[1] != width or frame.shape[0] != height:
                        resize_start = time.time()
                        frame = cv2.resize(frame, (width, height), interpolation=cv2.INTER_LINEAR)
                        read_time += time.time() - resize_start

                    # ç¡®ä¿å¸§æ˜¯8ä½æ— ç¬¦å·æ•´æ•°
                    if frame.dtype != np.uint8:
                        frame = frame.astype(np.uint8)

                    write_frame_start = time.time()
                    out.write(frame)
                    write_time += time.time() - write_frame_start

                    frame_count += 1

                    # æ¯100å¸§è¾“å‡ºä¸€æ¬¡è¿›åº¦
                    if frame_count % 100 == 0:
                        current_time = time.time() - write_start
                        avg_time_per_frame = current_time / frame_count
                        self.log(f"å·²å†™å…¥ {frame_count} å¸§ï¼Œå¹³å‡æ¯å¸§: {avg_time_per_frame:.3f}ç§’")

        write_total_time = time.time() - write_start
        out.release()

        # ç¡®ä¿è§†é¢‘æ–‡ä»¶åˆ›å»ºæˆåŠŸ
        if not os.path.exists(temp_video_path) or os.path.getsize(temp_video_path) == 0:
            self.log(f"é”™è¯¯: è§†é¢‘æ–‡ä»¶åˆ›å»ºå¤±è´¥: {temp_video_path}")
            return self.frames_to_video_alternative(frame_files, output_path, fps, width, height, audio_path)

        file_size = os.path.getsize(temp_video_path) / (1024 * 1024)  # è½¬æ¢ä¸ºMB
        self.log(f"ä¸´æ—¶è§†é¢‘åˆ›å»ºæˆåŠŸï¼Œå¤§å°: {file_size:.2f} MBï¼Œå†™å…¥è€—æ—¶: {write_total_time:.2f}ç§’")
        self.log(f"  è¯»å–è€—æ—¶: {read_time:.2f}ç§’ï¼Œå†™å…¥è€—æ—¶: {write_time:.2f}ç§’")

        # å¦‚æœæœ‰éŸ³é¢‘ï¼Œåˆå¹¶éŸ³é¢‘å’Œè§†é¢‘
        if audio_path and os.path.exists(audio_path):
            self.log("åˆå¹¶éŸ³é¢‘å’Œè§†é¢‘...")
            merge_start = time.time()

            try:
                # å¦‚æœç”Ÿæˆçš„æ˜¯AVIæ–‡ä»¶ï¼Œéœ€è¦è½¬æ¢æ ¼å¼
                if selected_ext == 'avi':
                    # å…ˆè½¬æ¢ä¸ºmp4
                    mp4_temp = temp_video_path.replace('.avi', '_converted.mp4')
                    convert_cmd = [
                        'ffmpeg', '-y',
                        '-i', temp_video_path,
                        '-c:v', 'libx264',
                        '-preset', 'medium',
                        '-crf', '23',
                        '-loglevel', 'quiet',
                        mp4_temp
                    ]

                    subprocess.run(convert_cmd, check=True, capture_output=True, text=True)

                    if os.path.exists(mp4_temp):
                        # åˆ é™¤åŸå§‹AVIæ–‡ä»¶
                        os.remove(temp_video_path)
                        temp_video_path = mp4_temp

                # åˆå¹¶éŸ³é¢‘
                cmd = [
                    'ffmpeg', '-y',
                    '-i', temp_video_path,
                    '-i', audio_path,
                    '-c:v', 'copy',
                    '-c:a', 'aac',
                    '-b:a', '192k',
                    '-strict', 'experimental',
                    '-loglevel', 'quiet',
                    output_path
                ]

                result = subprocess.run(cmd, check=True, capture_output=True, text=True)

                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_video_path):
                    os.remove(temp_video_path)

                merge_time = time.time() - merge_start
                total_time = time.time() - start_time

                self.log(f"éŸ³é¢‘è§†é¢‘åˆå¹¶æˆåŠŸï¼Œè€—æ—¶: {total_time:.2f}ç§’")
                self.log(f"  è¯¦ç»†æ—¶é—´: å†™å…¥å¸§{write_total_time:.2f}s, åˆå¹¶{merge_time:.2f}s")
                self.log(f"ç”Ÿæˆè§†é¢‘: {output_path}ï¼Œåˆ†è¾¨ç‡: {width}x{height}ï¼Œå¸§ç‡: {fps}ï¼Œå¸§æ•°: {frame_count}")
                return True

            except subprocess.CalledProcessError as e:
                self.log(f"éŸ³é¢‘è§†é¢‘åˆå¹¶å¤±è´¥: {e.stderr}")

                # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œå°è¯•å¦ä¸€ç§æ–¹æ³•
                try:
                    self.log("å°è¯•ç¬¬äºŒç§æ–¹æ³•åˆå¹¶éŸ³é¢‘è§†é¢‘...")
                    cmd2 = [
                        'ffmpeg', '-y',
                        '-i', temp_video_path,
                        '-i', audio_path,
                        '-c:v', 'libx264',
                        '-preset', 'medium',
                        '-crf', '23',
                        '-c:a', 'aac',
                        '-b:a', '192k',
                        '-strict', 'experimental',
                        '-loglevel', 'quiet',
                        output_path
                    ]

                    subprocess.run(cmd2, check=True, capture_output=True, text=True)

                    if os.path.exists(temp_video_path):
                        os.remove(temp_video_path)

                    self.log("ç¬¬äºŒç§æ–¹æ³•åˆå¹¶æˆåŠŸ")
                    return True
                except Exception as e2:
                    self.log(f"ç¬¬äºŒç§æ–¹æ³•ä¹Ÿå¤±è´¥: {e2}")
                    # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œä½¿ç”¨ä¸´æ—¶è§†é¢‘æ–‡ä»¶ä½œä¸ºè¾“å‡º
                    if os.path.exists(temp_video_path):
                        shutil.move(temp_video_path, output_path)
                        self.log("ä½¿ç”¨æ— éŸ³é¢‘è§†é¢‘ä½œä¸ºè¾“å‡º")
                    return True

        else:
            # å¦‚æœæ²¡æœ‰éŸ³é¢‘ï¼Œç›´æ¥ä½¿ç”¨ä¸´æ—¶è§†é¢‘æ–‡ä»¶
            if os.path.exists(temp_video_path):
                # å¦‚æœæ˜¯AVIæ ¼å¼ï¼Œè½¬æ¢ä¸ºMP4
                if selected_ext == 'avi':
                    self.log("å°†AVIè½¬æ¢ä¸ºMP4...")
                    convert_cmd = [
                        'ffmpeg', '-y',
                        '-i', temp_video_path,
                        '-c:v', 'libx264',
                        '-preset', 'medium',
                        '-crf', '23',
                        '-loglevel', 'quiet',
                        output_path
                    ]

                    try:
                        subprocess.run(convert_cmd, check=True, capture_output=True, text=True)
                        os.remove(temp_video_path)
                    except Exception as e:
                        self.log(f"è½¬æ¢å¤±è´¥: {e}")
                        shutil.move(temp_video_path, output_path)
                else:
                    shutil.move(temp_video_path, output_path)

                total_time = time.time() - start_time
                self.log(f"è§†é¢‘ç”ŸæˆæˆåŠŸï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")
                self.log(f"ç”Ÿæˆè§†é¢‘: {output_path}ï¼Œåˆ†è¾¨ç‡: {width}x{height}ï¼Œå¸§ç‡: {fps}ï¼Œå¸§æ•°: {frame_count}")
                return True
            else:
                self.log(f"é”™è¯¯: è§†é¢‘æ–‡ä»¶æœªåˆ›å»º: {temp_video_path}")

        return False

    def frames_to_video_alternative(self, frame_files, output_path, fps, width, height, audio_path=None):
        """æ›¿ä»£æ–¹æ³•ï¼šä½¿ç”¨ffmpegç›´æ¥ç”Ÿæˆè§†é¢‘ï¼ˆé¿å…OpenCVç¼–ç å™¨é—®é¢˜ï¼‰"""
        self.log("ä½¿ç”¨ffmpegç›´æ¥ç”Ÿæˆè§†é¢‘...")
        start_time = time.time()

        if not frame_files:
            self.log("é”™è¯¯: æ²¡æœ‰å¯ç”¨çš„å¸§æ–‡ä»¶")
            return False

        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶åˆ—è¡¨
        list_file = tempfile.mktemp(suffix=".txt")
        frame_files_sorted = sorted(frame_files)

        with open(list_file, 'w', encoding='utf-8') as f:
            for frame_file in frame_files_sorted:
                f.write(f"file '{os.path.abspath(frame_file)}'\n")

        # ä½¿ç”¨ffmpegä»å›¾åƒåºåˆ—ç”Ÿæˆè§†é¢‘
        temp_video_path = output_path.replace('.mp4', '_temp.mp4')

        cmd = [
            'ffmpeg', '-y',
            '-f', 'concat',
            '-safe', '0',
            '-r', str(fps),
            '-i', list_file,
            '-c:v', 'libx264',
            '-preset', 'medium',
            '-crf', '23',
            '-pix_fmt', 'yuv420p',
            '-loglevel', 'quiet',
            temp_video_path
        ]

        try:
            convert_start = time.time()
            subprocess.run(cmd, check=True, capture_output=True, text=True)
            convert_time = time.time() - convert_start

            if not os.path.exists(temp_video_path):
                self.log("é”™è¯¯: ffmpegæœªèƒ½ç”Ÿæˆè§†é¢‘")
                os.remove(list_file)
                return False

            # å¦‚æœæœ‰éŸ³é¢‘ï¼Œåˆå¹¶éŸ³é¢‘
            if audio_path and os.path.exists(audio_path):
                merge_cmd = [
                    'ffmpeg', '-y',
                    '-i', temp_video_path,
                    '-i', audio_path,
                    '-c:v', 'copy',
                    '-c:a', 'aac',
                    '-b:a', '192k',
                    '-loglevel', 'quiet',
                    output_path
                ]

                merge_start = time.time()
                subprocess.run(merge_cmd, check=True, capture_output=True, text=True)
                merge_time = time.time() - merge_start

                os.remove(temp_video_path)
                total_time = time.time() - start_time
                self.log(
                    f"è§†é¢‘ç”ŸæˆæˆåŠŸï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’ (è½¬æ¢: {convert_time:.2f}s, åˆå¹¶: {merge_time:.2f}s)")
            else:
                shutil.move(temp_video_path, output_path)
                total_time = time.time() - start_time
                self.log(f"è§†é¢‘ç”ŸæˆæˆåŠŸï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’ (è½¬æ¢: {convert_time:.2f}s)")

            os.remove(list_file)
            return True

        except subprocess.CalledProcessError as e:
            self.log(f"ffmpegç”Ÿæˆè§†é¢‘å¤±è´¥: {e.stderr}")
            if os.path.exists(list_file):
                os.remove(list_file)
            return False

    def process_segment_directly(self, segment_path, segment_index):
        """ç›´æ¥å¤„ç†è§†é¢‘ç‰‡æ®µï¼ˆä¸è¿›è¡Œé‡å¤å¸§æ£€æµ‹ï¼‰"""
        segment_name = os.path.basename(segment_path)
        self.log(f"ç›´æ¥å¤„ç†ç‰‡æ®µ {segment_index}: {segment_name}")
        segment_start_time = time.time()

        if self.test_mode_var.get():
            self.log("æµ‹è¯•æ¨¡å¼ï¼šä¸è¿›è¡Œè¶…åˆ†è¾¨ç‡å¤„ç†")
            return None, None

        # è¯»å–è§†é¢‘
        try:
            video = VideoFileClip(segment_path)
        except Exception as e:
            self.log(f"è¯»å–è§†é¢‘å¤±è´¥: {e}")
            return None, None

        # è·å–è§†é¢‘ä¿¡æ¯
        fps = video.fps
        width, height = video.size
        total_frames = int(video.duration * fps)
        has_audio = video.audio is not None

        # æå–éŸ³é¢‘ï¼ˆå¦‚æœæœ‰ï¼‰
        audio_path = None
        if has_audio:
            audio_name = segment_name.replace('.mp4', '.aac')
            audio_path = os.path.join(self.temp_base_dir, "02_audio", audio_name)
            try:
                video.audio.write_audiofile(audio_path, verbose=False)
                self.log("éŸ³é¢‘æå–æˆåŠŸ")
            except Exception as e:
                self.log(f"éŸ³é¢‘æå–å¤±è´¥: {e}")
                audio_path = None
                has_audio = False

        # è®¡ç®—è¾“å‡ºå°ºå¯¸
        scale = int(self.scale_var.get())
        downsample_threshold = int(self.downsample_threshold.get())

        short_side = min(height, width)
        if downsample_threshold != -1 and short_side > downsample_threshold:
            rescale_factor = short_side / downsample_threshold
        else:
            rescale_factor = 1

        # è¾“å‡ºå°ºå¯¸
        output_width = int(width * scale / rescale_factor)
        output_height = int(height * scale / rescale_factor)

        self.log(f"è¾“å…¥å°ºå¯¸: {width}x{height}, è¾“å‡ºå°ºå¯¸: {output_width}x{output_height}")
        self.log(f"ç›´æ¥å¤„ç†æ¨¡å¼ï¼šä½¿ç”¨moviepyå¤„ç†ï¼Œä¸è¿›è¡Œé‡å¤å¸§æ£€æµ‹")

        # åˆ›å»ºè¾“å‡ºè·¯å¾„
        processed_segment_path = os.path.join(self.temp_base_dir, "04_processed_segments", f"processed_{segment_name}")

        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
        try:
            if has_audio and audio_path:
                writer = FFMPEG_VideoWriter(processed_segment_path, (output_width, output_height), fps,
                                            audiofile=audio_path)
                self.log("ä½¿ç”¨å¸¦éŸ³é¢‘çš„è§†é¢‘å†™å…¥å™¨")
            else:
                writer = FFMPEG_VideoWriter(processed_segment_path, (output_width, output_height), fps)
                self.log("ä½¿ç”¨æ— éŸ³é¢‘çš„è§†é¢‘å†™å…¥å™¨")
        except Exception as e:
            self.log(f"åˆ›å»ºè§†é¢‘å†™å…¥å™¨å¤±è´¥: {e}")
            video.close()
            return None, None

        frame_idx = 0
        frames_processed = 0
        total_frame_time = 0

        # å¤„ç†æ¯ä¸€å¸§
        for frame_idx, img_lr in enumerate(video.iter_frames(fps=fps, dtype='uint8')):
            # æ£€æŸ¥æ˜¯å¦è¢«åœæ­¢
            if self.stopped:
                self.log(f"åœæ­¢å¤„ç†ï¼šç‰‡æ®µ {segment_index} çš„ç¬¬ {frame_idx + 1} å¸§")
                break

            # ç›´æ¥å¤„ç†æ¨¡å¼ä¸æ”¯æŒæš‚åœï¼Œæ‰€ä»¥ä¸éœ€è¦æ£€æŸ¥æš‚åœçŠ¶æ€

            # æ³¨æ„ï¼šmoviepyè¿”å›çš„æ˜¯RGBæ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸ºBGRè¿›è¡Œè¶…åˆ†å¤„ç†
            # è½¬æ¢ä¸ºBGRæ ¼å¼
            img_lr_bgr = cv2.cvtColor(img_lr, cv2.COLOR_RGB2BGR)

            # ä¸‹é‡‡æ ·ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if rescale_factor != 1:
                img_lr_bgr = cv2.resize(img_lr_bgr, (int(width / rescale_factor), int(height / rescale_factor)),
                                        interpolation=cv2.INTER_LINEAR)

            # è£å‰ªï¼ˆå¦‚æœéœ€è¦ï¼‰
            if self.crop_for_4x_var.get() and scale == 4:
                h, w, _ = img_lr_bgr.shape
                if h % 4 != 0:
                    img_lr_bgr = img_lr_bgr[:4 * (h // 4), :, :]
                if w % 4 != 0:
                    img_lr_bgr = img_lr_bgr[:, :4 * (w // 4), :]

            # å¤„ç†å¸§
            process_start = time.time()
            sr_frame = self.process_single_frame(img_lr_bgr)
            frame_process_time = time.time() - process_start
            total_frame_time += frame_process_time

            # å†™å…¥å¸§ï¼ˆæ³¨æ„ï¼šmoviepyéœ€è¦RGBæ ¼å¼ï¼‰
            sr_frame_rgb = cv2.cvtColor(sr_frame, cv2.COLOR_BGR2RGB)
            writer.write_frame(sr_frame_rgb)

            # æ›´æ–°è¿›åº¦
            frames_processed += 1

            # æ›´æ–°è¯¦ç»†è¿›åº¦
            if total_frames > 0:
                self.update_detailed_progress(frame_idx + 1, total_frames)

            # æ›´æ–°è¿›åº¦æ¡
            if total_frames > 0:
                progress = ((frame_idx + 1) / total_frames) * 100
                self.update_progress(progress)

            # æ¯å¤„ç†10å¸§æ›´æ–°ä¸€æ¬¡æ—¥å¿—
            if (frame_idx + 1) % 10 == 0:
                avg_frame_time = total_frame_time / (frame_idx + 1)
                self.log(f"å·²å¤„ç† {frame_idx + 1}/{total_frames} å¸§ï¼Œå¹³å‡æ¯å¸§è€—æ—¶: {avg_frame_time:.3f}ç§’")

            # æ¯å¤„ç†50å¸§æ¸…ç†ä¸€æ¬¡å†…å­˜
            if frame_idx % 50 == 0:
                self.cleanup_memory()

        # å…³é—­å†™å…¥å™¨å’Œè§†é¢‘
        writer.close()
        video.close()

        # è®°å½•ç‰‡æ®µå¤„ç†ç»Ÿè®¡
        segment_elapsed = time.time() - segment_start_time
        avg_frame_time = total_frame_time / max(frames_processed, 1)

        self.log(f"ç›´æ¥å¤„ç†å®Œæˆ: {segment_name}ï¼Œæ€»è€—æ—¶: {segment_elapsed:.2f}ç§’")
        self.log(f"  å¤„ç†å¸§æ•°: {frames_processed}ï¼Œå¹³å‡æ¯å¸§è€—æ—¶: {avg_frame_time:.3f}ç§’")

        # å¦‚æœæœ‰ç«‹å³åˆå¹¶åŠŸèƒ½ï¼Œè°ƒç”¨åˆå¹¶
        if self.immediate_merge_var.get() and not self.test_mode_var.get():
            self.update_immediate_merge()

        return processed_segment_path, audio_path if has_audio else None

    def update_immediate_merge(self):
        """æ›´æ–°ç«‹å³åˆå¹¶è§†é¢‘ - æ£€æŸ¥04_processed_segmentsæ–‡ä»¶å¤¹å¹¶åˆå¹¶åˆ°05_immediate_merge"""
        if not self.immediate_merge_var.get() or self.test_mode_var.get():
            return None

        start_time = time.time()

        # è·å–è·¯å¾„
        processed_segments_dir = os.path.join(self.temp_base_dir, "04_processed_segments")
        merge_dir = os.path.join(self.temp_base_dir, "05_immediate_merge")
        log_file_path = os.path.join(processed_segments_dir, "merge_log.txt")

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(merge_dir, exist_ok=True)

        # è¯»å–æ—¥å¿—æ–‡ä»¶ï¼Œè·å–å·²åˆå¹¶çš„ç‰‡æ®µ
        merged_segments = set()
        if os.path.exists(log_file_path):
            try:
                with open(log_file_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        segment_name = line.strip()
                        if segment_name:
                            merged_segments.add(segment_name)
                self.log(f"ä»æ—¥å¿—æ–‡ä»¶ä¸­è¯»å–åˆ° {len(merged_segments)} ä¸ªå·²åˆå¹¶çš„ç‰‡æ®µ")
            except Exception as e:
                self.log(f"è¯»å–åˆå¹¶æ—¥å¿—å¤±è´¥: {e}")
                merged_segments = set()

        # è·å–04_processed_segmentsç›®å½•ä¸‹æ‰€æœ‰çš„processed_segment_*.mp4æ–‡ä»¶
        all_processed_segments = []
        if os.path.exists(processed_segments_dir):
            for f in sorted(os.listdir(processed_segments_dir)):
                if f.startswith("processed_segment_") and f.endswith(".mp4"):
                    all_processed_segments.append(f)

        if not all_processed_segments:
            self.log("æ²¡æœ‰æ‰¾åˆ°å·²å¤„ç†çš„ç‰‡æ®µ")
            return None

        # æ‰¾å‡ºæœªåˆå¹¶çš„ç‰‡æ®µ
        unmerged_segments = []
        for segment in all_processed_segments:
            if segment not in merged_segments:
                unmerged_segments.append(segment)

        if not unmerged_segments:
            self.log("æ‰€æœ‰ç‰‡æ®µéƒ½å·²åˆå¹¶ï¼Œæ— éœ€æ“ä½œ")
            return None

        self.log(f"æ‰¾åˆ° {len(unmerged_segments)} ä¸ªæœªåˆå¹¶çš„ç‰‡æ®µ")

        # è·å–å½“å‰çš„åˆå¹¶è§†é¢‘ï¼ˆå¦‚æœæœ‰ï¼‰
        merged_videos = []
        if os.path.exists(merge_dir):
            for f in os.listdir(merge_dir):
                if f.startswith("merged_video") and f.endswith(".mp4"):
                    merged_videos.append(os.path.join(merge_dir, f))

        merged_video_path = None
        if merged_videos:
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„
            merged_videos.sort(key=lambda x: os.path.getmtime(x))
            merged_video_path = merged_videos[-1]
            self.log(f"æ‰¾åˆ°ç°æœ‰çš„åˆå¹¶è§†é¢‘: {os.path.basename(merged_video_path)}")
        else:
            self.log("æ²¡æœ‰æ‰¾åˆ°ç°æœ‰çš„åˆå¹¶è§†é¢‘ï¼Œå°†åˆ›å»ºæ–°çš„")

        # æ„å»ºè¦åˆå¹¶çš„è§†é¢‘æ–‡ä»¶åˆ—è¡¨
        video_files_to_merge = []

        # å¦‚æœæœ‰ç°æœ‰çš„åˆå¹¶è§†é¢‘ï¼Œå…ˆåŠ å…¥
        if merged_video_path and os.path.exists(merged_video_path):
            video_files_to_merge.append(merged_video_path)

        # åŠ å…¥æ–°çš„æœªåˆå¹¶ç‰‡æ®µ
        for segment in unmerged_segments:
            segment_path = os.path.join(processed_segments_dir, segment)
            if os.path.exists(segment_path):
                video_files_to_merge.append(segment_path)
            else:
                self.log(f"è­¦å‘Šï¼šç‰‡æ®µæ–‡ä»¶ä¸å­˜åœ¨: {segment}")

        if len(video_files_to_merge) == 0:
            self.log("æ²¡æœ‰è§†é¢‘æ–‡ä»¶å¯åˆå¹¶")
            return None

        # å¦‚æœåªæœ‰ä¸€ä¸ªæ–‡ä»¶ä¸”æ˜¯æ–°çš„åˆå¹¶è§†é¢‘ï¼Œç›´æ¥å¤åˆ¶
        if len(video_files_to_merge) == 1 and video_files_to_merge[0] == merged_video_path:
            self.log("åªæœ‰ç°æœ‰çš„åˆå¹¶è§†é¢‘ï¼Œæ— éœ€æ“ä½œ")
            return merged_video_path

        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶åˆ—è¡¨
        list_file = tempfile.mktemp(suffix=".txt")

        try:
            with open(list_file, 'w', encoding='utf-8') as f:
                for video_file in video_files_to_merge:
                    f.write(f"file '{os.path.abspath(video_file)}'\n")

            # ç”Ÿæˆæ–°çš„åˆå¹¶è§†é¢‘æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            new_merged_video_path = os.path.join(merge_dir, f"merged_video_{timestamp}.mp4")

            # ä½¿ç”¨ffmpegåˆå¹¶
            cmd = [
                'ffmpeg', '-y',
                '-f', 'concat',
                '-safe', '0',
                '-i', list_file,
                '-c', 'copy',
                new_merged_video_path
            ]

            merge_start = time.time()
            subprocess.run(cmd, check=True, capture_output=True, text=True)
            merge_time = time.time() - merge_start

            # æ›´æ–°æ—¥å¿—æ–‡ä»¶ï¼Œè®°å½•æ–°åˆå¹¶çš„ç‰‡æ®µ
            try:
                with open(log_file_path, 'a', encoding='utf-8') as f:
                    for segment in unmerged_segments:
                        f.write(f"{segment}\n")
                self.log(f"å·²å°† {len(unmerged_segments)} ä¸ªç‰‡æ®µè®°å½•åˆ°åˆå¹¶æ—¥å¿—")
            except Exception as e:
                self.log(f"å†™å…¥åˆå¹¶æ—¥å¿—å¤±è´¥: {e}")

            # åˆ é™¤æ—§çš„åˆå¹¶è§†é¢‘ï¼ˆå¦‚æœæœ‰ï¼‰
            if merged_video_path and merged_video_path != new_merged_video_path:
                try:
                    os.remove(merged_video_path)
                    self.log(f"å·²åˆ é™¤æ—§çš„åˆå¹¶è§†é¢‘: {os.path.basename(merged_video_path)}")
                except Exception as e:
                    self.log(f"åˆ é™¤æ—§çš„åˆå¹¶è§†é¢‘å¤±è´¥: {e}")

            elapsed = time.time() - start_time
            self.log(f"ç«‹å³åˆæˆæˆåŠŸ: åˆå¹¶äº† {len(unmerged_segments)} ä¸ªæ–°ç‰‡æ®µï¼Œè€—æ—¶: {elapsed:.2f}ç§’ (åˆå¹¶: {merge_time:.2f}s)")
            self.log(f"æ–°çš„åˆå¹¶è§†é¢‘: {os.path.basename(new_merged_video_path)}")

            return new_merged_video_path

        except Exception as e:
            self.log(f"ç«‹å³åˆæˆå¤±è´¥: {e}")
            return None
        finally:
            if os.path.exists(list_file):
                os.remove(list_file)

    def process_single_video(self, video_path):
        """å¤„ç†å•ä¸ªè§†é¢‘"""
        try:
            self.log(
                f"å¼€å§‹å¤„ç†è§†é¢‘ {self.current_video_index + 1}/{len(self.input_paths)}: {os.path.basename(video_path)}")
            video_start_time = time.time()

            # è®¾ç½®è§†é¢‘åŸºç¡€åç§°
            self.video_base_name = Path(video_path).stem

            # è®¾ç½®ä¸´æ—¶ç›®å½•ï¼ˆåŸºäºè§†é¢‘æ–‡ä»¶åå’Œæµ‹è¯•æ¨¡å¼ï¼‰
            temp_dirs = self.setup_temp_dirs(video_path)
            if not temp_dirs:
                raise ValueError("æ— æ³•åˆ›å»ºä¸´æ—¶ç›®å½•")

            self.log(f"ä¸´æ—¶æ–‡ä»¶ç›®å½•: {temp_dirs['base']}")
            if self.is_test_mode_folder:
                self.log("æ³¨æ„ï¼šå½“å‰ä¸ºæµ‹è¯•æ¨¡å¼æ–‡ä»¶å¤¹")

            # æ£€æµ‹è¿›åº¦
            if self.enable_dup_detect_var.get():
                # å¯ç”¨é‡å¤å¸§æ£€æµ‹æ¨¡å¼ï¼šä»03å’Œ04æ–‡ä»¶å¤¹æ£€æµ‹è¿›åº¦
                next_segment, current_frame, processed_segments = self.detect_progress_from_folders()
                self.current_segment_index = next_segment - 1 if next_segment > 0 else 0
                self.current_frame_in_segment = current_frame
                self.processed_segments = [f"segment_{i:03d}.mp4" for i in processed_segments]
                self.log(f"ä»æ–‡ä»¶å¤¹æ£€æµ‹åˆ°è¿›åº¦: ä¸‹ä¸€ä¸ªç‰‡æ®µ={next_segment}, å½“å‰å¸§={current_frame}")
            else:
                # ç›´æ¥å¤„ç†æ¨¡å¼ï¼šåªä»04æ–‡ä»¶å¤¹æ£€æµ‹è¿›åº¦
                processed_dir = os.path.join(self.temp_base_dir, "04_processed_segments")
                if os.path.exists(processed_dir):
                    processed_files = [f for f in os.listdir(processed_dir)
                                       if f.startswith("processed_") and f.endswith(".mp4")]
                    if processed_files:
                        # æå–æœ€åä¸€ä¸ªå¤„ç†æ–‡ä»¶çš„ç‰‡æ®µç¼–å·
                        last_processed = sorted(processed_files)[-1]
                        try:
                            # æ ¼å¼å¦‚ï¼šprocessed_segment_001.mp4
                            segment_num = int(last_processed.split('_')[2].split('.')[0])
                            self.current_segment_index = segment_num  # ä¸‹ä¸€ä¸ªè¦å¤„ç†çš„ç‰‡æ®µ
                            self.processed_segments = [f"segment_{i:03d}.mp4" for i in range(1, segment_num)]
                            self.log(f"ä»04æ–‡ä»¶å¤¹æ£€æµ‹åˆ°è¿›åº¦: å·²å¤„ç†{segment_num}ä¸ªç‰‡æ®µï¼Œä¸‹ä¸€ä¸ªç‰‡æ®µ={segment_num + 1}")
                        except:
                            self.current_segment_index = 0
                            self.processed_segments = []
                            self.log("æ— æ³•è§£æå¤„ç†æ–‡ä»¶åï¼Œä»å¤´å¼€å§‹å¤„ç†")
                    else:
                        self.current_segment_index = 0
                        self.processed_segments = []
                        self.log("æœªæ‰¾åˆ°å·²å¤„ç†çš„ç‰‡æ®µï¼Œä»å¤´å¼€å§‹å¤„ç†")
                else:
                    self.current_segment_index = 0
                    self.processed_segments = []
                    self.log("æœªæ‰¾åˆ°04æ–‡ä»¶å¤¹ï¼Œä»å¤´å¼€å§‹å¤„ç†")

            # é‡ç½®é‡å¤å¸§è®¡æ•°ï¼ˆæ¯ä¸ªè§†é¢‘å¼€å§‹æ—¶é‡ç½®ï¼‰
            self.dup_frame_count = 0
            self.update_dup_info(self.dup_frame_count)

            # æ­¥éª¤1: åŠ è½½æ¨¡å‹
            if not self.test_mode_var.get():
                self.log("=" * 60)
                self.log("æ­¥éª¤1: åŠ è½½æ¨¡å‹...")
                self.update_progress(0)
                model_load_start = time.time()
                self.generator = self.load_model()
                model_load_time = time.time() - model_load_start
                self.log(f"æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {model_load_time:.2f}ç§’")
                self.update_progress(5)
            else:
                self.log("æµ‹è¯•æ¨¡å¼ï¼šè·³è¿‡æ¨¡å‹åŠ è½½")
                self.update_progress(5)

            # æ­¥éª¤2: åˆ†å‰²è§†é¢‘ï¼ˆå¦‚æœéœ€è¦ï¼‰
            segments_dir = os.path.join(self.temp_base_dir, "01_original_segments")
            if os.path.exists(segments_dir):
                # è¯»å–å·²æœ‰çš„ç‰‡æ®µ
                segment_files = []
                for f in sorted(os.listdir(segments_dir)):
                    if f.startswith("segment_") and f.endswith(".mp4"):
                        segment_files.append(os.path.join(segments_dir, f))

                if segment_files:
                    self.segments = segment_files
                    self.total_segments = len(self.segments)
                    self.log(f"æ‰¾åˆ° {len(self.segments)} ä¸ªå·²æœ‰ç‰‡æ®µ")
                    self.update_progress(10)
                else:
                    # æ²¡æœ‰ç‰‡æ®µï¼Œéœ€è¦åˆ†å‰²
                    self.log("=" * 60)
                    self.log("æ­¥éª¤2: åˆ†å‰²è§†é¢‘...")
                    segment_duration = float(self.segment_duration.get())
                    split_start = time.time()
                    self.segments = self.split_video_by_keyframes(video_path, segment_duration, temp_dirs['base'])
                    split_time = time.time() - split_start

                    self.total_segments = len(self.segments)
                    self.log(f"è§†é¢‘åˆ†å‰²å®Œæˆï¼Œå…±{len(self.segments)}æ®µï¼Œè€—æ—¶: {split_time:.2f}ç§’")
                    self.update_progress(10)

                    if not self.segments:
                        raise ValueError("è§†é¢‘åˆ†å‰²å¤±è´¥")

                    # é‡ç½®è¿›åº¦
                    self.current_segment_index = 0
                    self.current_frame_in_segment = 0
                    self.processed_segments = []
            else:
                # éœ€è¦åˆ†å‰²è§†é¢‘
                self.log("=" * 60)
                self.log("æ­¥éª¤2: åˆ†å‰²è§†é¢‘...")
                segment_duration = float(self.segment_duration.get())
                split_start = time.time()
                self.segments = self.split_video_by_keyframes(video_path, segment_duration, temp_dirs['base'])
                split_time = time.time() - split_start

                self.total_segments = len(self.segments)
                self.log(f"è§†é¢‘åˆ†å‰²å®Œæˆï¼Œå…±{len(self.segments)}æ®µï¼Œè€—æ—¶: {split_time:.2f}ç§’")
                self.update_progress(10)

                if not self.segments:
                    raise ValueError("è§†é¢‘åˆ†å‰²å¤±è´¥")

                # é‡ç½®è¿›åº¦
                self.current_segment_index = 0
                self.current_frame_in_segment = 0
                self.processed_segments = []

            # æ­¥éª¤3: å¤„ç†è§†é¢‘ç‰‡æ®µ
            self.log("=" * 60)
            self.log("æ­¥éª¤3: å¤„ç†è§†é¢‘ç‰‡æ®µ...")

            all_processed_segments = []
            total_segment_time = 0
            total_frames_processed = 0
            total_dup_count = 0

            for i in range(self.current_segment_index, len(self.segments)):
                # æ£€æŸ¥æ˜¯å¦è¢«åœæ­¢
                if self.stopped:
                    self.log(f"å¤„ç†è¢«ç”¨æˆ·åœæ­¢äºç‰‡æ®µ {i + 1}")
                    break

                segment = self.segments[i]
                segment_name = os.path.basename(segment)

                # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡ï¼ˆé€šè¿‡04æ–‡ä»¶å¤¹åˆ¤æ–­ï¼‰
                processed_segment_path = os.path.join(temp_dirs['processed_segments'], f"processed_{segment_name}")
                if os.path.exists(processed_segment_path):
                    self.log(f"è·³è¿‡å·²å¤„ç†çš„ç‰‡æ®µ {i + 1}/{len(self.segments)}: {segment_name}")
                    self.current_segment_index = i + 1
                    self.current_frame_in_segment = 0
                    all_processed_segments.append(processed_segment_path)
                    continue

                self.log(f"å¤„ç†ç‰‡æ®µ {i + 1}/{len(self.segments)}: {segment_name}")
                segment_start = time.time()

                if not self.enable_dup_detect_var.get() and not self.test_mode_var.get():
                    # ç›´æ¥å¤„ç†æ¨¡å¼ï¼ˆä¸è¿›è¡Œé‡å¤å¸§æ£€æµ‹ï¼‰
                    processed_segment_path, audio_path = self.process_segment_directly(segment, i + 1)
                else:
                    # é€å¸§å¤„ç†æ¨¡å¼ï¼ˆå¸¦é‡å¤å¸§æ£€æµ‹æˆ–æµ‹è¯•æ¨¡å¼ï¼‰
                    processed_segment_path, audio_path = self.process_segment_frames(segment, i + 1)

                segment_time = time.time() - segment_start
                total_segment_time += segment_time

                # æ£€æŸ¥æ˜¯å¦è¢«åœæ­¢
                if self.stopped:
                    break

                if processed_segment_path:
                    # æ‰€æœ‰éæµ‹è¯•æ¨¡å¼éƒ½ä¼šç”Ÿæˆè§†é¢‘ç‰‡æ®µ
                    all_processed_segments.append(processed_segment_path)
                elif self.test_mode_var.get():
                    self.log(f"æµ‹è¯•æ¨¡å¼ï¼šç‰‡æ®µ {i + 1} å¤„ç†å®Œæˆï¼Œå¸§æ–‡ä»¶å·²ä¿å­˜")

                # æ›´æ–°è¿›åº¦
                self.current_segment_index = i + 1
                self.current_frame_in_segment = 0

                # æ›´æ–°æ€»ä½“è¿›åº¦
                overall_progress = 10 + (i + 1) / len(self.segments) * 60
                self.update_progress(overall_progress)

                # å¤„ç†å®Œä¸€ä¸ªç‰‡æ®µåæ¸…ç†å†…å­˜
                self.cleanup_memory()

            if self.stopped:
                self.log(f"å¤„ç†å·²åœæ­¢")
                return False

            # æ­¥éª¤4: å¦‚æœå¤„ç†äº†å¤šä¸ªç‰‡æ®µä¸”ä¸æ˜¯æµ‹è¯•æ¨¡å¼ï¼Œæ‹¼æ¥è§†é¢‘
            if not self.test_mode_var.get():
                # æ£€æŸ¥æ˜¯å¦æœ‰ç«‹å³åˆæˆçš„æœ€ç»ˆè§†é¢‘
                merge_dir = os.path.join(self.temp_base_dir, "05_immediate_merge")
                if self.immediate_merge_var.get() and os.path.exists(merge_dir):
                    # æŸ¥æ‰¾æœ€æ–°çš„åˆå¹¶è§†é¢‘
                    merged_files = []
                    for f in os.listdir(merge_dir):
                        if f.startswith("merged_video_") and f.endswith(".mp4"):
                            merged_files.append(os.path.join(merge_dir, f))

                    if merged_files:
                        # æŒ‰æ–‡ä»¶åæ’åºï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
                        merged_files.sort(key=lambda x: os.path.basename(x))
                        latest_merged = merged_files[-1]

                        # å°†æœ€ç»ˆåˆå¹¶è§†é¢‘ç§»åŠ¨åˆ°è¾“å‡ºç›®å½•
                        output_filename = f"{self.video_base_name}_super_resolved.mp4"
                        final_output = os.path.join(self.output_dir.get(), output_filename)

                        merge_start = time.time()
                        shutil.copy2(latest_merged, final_output)
                        merge_time = time.time() - merge_start

                        self.update_progress(95)
                        self.log(f"ä½¿ç”¨ç«‹å³åˆæˆçš„è§†é¢‘ä½œä¸ºæœ€ç»ˆè¾“å‡º: {final_output}ï¼Œå¤åˆ¶è€—æ—¶: {merge_time:.2f}ç§’")

                        # æ¸…ç†ç«‹å³åˆæˆç›®å½•
                        shutil.rmtree(merge_dir)
                        self.log("å·²æ¸…ç†ç«‹å³åˆæˆç›®å½•")
                    else:
                        # å¦‚æœæ²¡æœ‰ç«‹å³åˆæˆè§†é¢‘ï¼Œåˆ™ä½¿ç”¨ä¼ ç»Ÿæ‹¼æ¥æ–¹å¼
                        self.log("=" * 60)
                        self.log("æ­¥éª¤4: æ‹¼æ¥å¤„ç†åçš„è§†é¢‘ç‰‡æ®µ...")

                        if all_processed_segments:
                            output_filename = f"{self.video_base_name}_super_resolved.mp4"
                            final_output = os.path.join(self.output_dir.get(), output_filename)

                            if len(all_processed_segments) > 1:
                                self.concatenate_videos(all_processed_segments, final_output)
                            else:
                                # å¦‚æœåªæœ‰ä¸€ä¸ªç‰‡æ®µï¼Œç›´æ¥å¤åˆ¶
                                copy_start = time.time()
                                shutil.copy2(all_processed_segments[0], final_output)
                                copy_time = time.time() - copy_start
                                self.log(f"å¤åˆ¶å•ä¸ªç‰‡æ®µï¼Œè€—æ—¶: {copy_time:.2f}ç§’")

                            self.update_progress(95)
                            self.log(f"æœ€ç»ˆè¾“å‡ºæ–‡ä»¶: {final_output}")
                        else:
                            self.log("æ²¡æœ‰å¯æ‹¼æ¥çš„ç‰‡æ®µ")
                else:
                    # ä¼ ç»Ÿæ‹¼æ¥æ–¹å¼
                    self.log("=" * 60)
                    self.log("æ­¥éª¤4: æ‹¼æ¥å¤„ç†åçš„è§†é¢‘ç‰‡æ®µ...")

                    if all_processed_segments:
                        output_filename = f"{self.video_base_name}_super_resolved.mp4"
                        final_output = os.path.join(self.output_dir.get(), output_filename)

                        if len(all_processed_segments) > 1:
                            self.concatenate_videos(all_processed_segments, final_output)
                        else:
                            # å¦‚æœåªæœ‰ä¸€ä¸ªç‰‡æ®µï¼Œç›´æ¥å¤åˆ¶
                            copy_start = time.time()
                            shutil.copy2(all_processed_segments[0], final_output)
                            copy_time = time.time() - copy_start
                            self.log(f"å¤åˆ¶å•ä¸ªç‰‡æ®µï¼Œè€—æ—¶: {copy_time:.2f}ç§’")

                        self.update_progress(95)
                        self.log(f"æœ€ç»ˆè¾“å‡ºæ–‡ä»¶: {final_output}")
                    else:
                        self.log("æ²¡æœ‰å¯æ‹¼æ¥çš„ç‰‡æ®µ")
            else:
                # æµ‹è¯•æ¨¡å¼ï¼šä¸ç”Ÿæˆè§†é¢‘
                self.log("æµ‹è¯•æ¨¡å¼ï¼šè·³è¿‡è§†é¢‘åˆæˆæ­¥éª¤")
                self.update_progress(95)

            # æ­¥éª¤5: è‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self.log("=" * 60)
            self.log("æ­¥éª¤5: è‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
            self.update_progress(100)

            # åœ¨è§†é¢‘å¤„ç†å®Œæˆåï¼Œè‡ªåŠ¨æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶ï¼Œåªä¿ç•™å¤„ç†å¥½çš„è§†é¢‘
            if not self.test_mode_var.get():
                # æ£€æŸ¥æ˜¯å¦æˆåŠŸç”Ÿæˆäº†æœ€ç»ˆè§†é¢‘
                output_filename = f"{self.video_base_name}_super_resolved.mp4"
                final_output = os.path.join(self.output_dir.get(), output_filename)

                if os.path.exists(final_output):
                    # æ¸…ç†é™¤04_processed_segmentså’Œæœ€ç»ˆè¾“å‡ºå¤–çš„æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶
                    self.cleanup_temp_after_success(temp_dirs)
                else:
                    self.log("æœ€ç»ˆè§†é¢‘æœªç”Ÿæˆï¼Œä¿ç•™ä¸´æ—¶æ–‡ä»¶")
            else:
                self.log("æµ‹è¯•æ¨¡å¼ï¼šä¿ç•™ä¸´æ—¶æ–‡ä»¶ä¾›æ£€æŸ¥")

            # è§†é¢‘å¤„ç†å®Œæˆç»Ÿè®¡
            total_video_time = time.time() - video_start_time

            # è®¡ç®—è¯¦ç»†æ—¶é—´ç»Ÿè®¡
            if self.enable_dup_detect_var.get() and not self.test_mode_var.get():
                total_dup_time = 0  # è¿™é‡Œéœ€è¦ä»ç‰‡æ®µå¤„ç†ä¸­ç´¯è®¡
                total_sr_time = total_segment_time - total_dup_time  # ä¼°ç®—
            else:
                total_dup_time = 0
                total_sr_time = total_segment_time

            avg_frame_time = total_segment_time / max(total_frames_processed, 1) if total_frames_processed > 0 else 0

            self.log("=" * 60)
            self.log("è§†é¢‘å¤„ç†å®Œæˆè¯¦ç»†ç»Ÿè®¡:")
            self.log(f"  è§†é¢‘åç§°: {os.path.basename(video_path)}")
            self.log(f"  æ€»å¤„ç†æ—¶é—´: {total_video_time:.2f}ç§’")

            if not self.test_mode_var.get():
                self.log(f"  æ¨¡å‹åŠ è½½æ—¶é—´: {model_load_time if 'model_load_time' in locals() else 0:.2f}ç§’")
                self.log(f"  è§†é¢‘åˆ†å‰²æ—¶é—´: {split_time if 'split_time' in locals() else 0:.2f}ç§’")
                self.log(f"  ç‰‡æ®µå¤„ç†æ€»æ—¶é—´: {total_segment_time:.2f}ç§’")

                if self.enable_dup_detect_var.get():
                    self.log(f"    é‡å¤å¸§æ£€æµ‹æ—¶é—´: {total_dup_time:.2f}ç§’")
                    self.log(f"    è¶…åˆ†è¾¨ç‡å¤„ç†æ—¶é—´: {total_sr_time:.2f}ç§’")
                    self.log(f"  æ€»è®¡é‡å¤å¸§: {self.dup_frame_count}ä¸ª")

                if total_frames_processed > 0:
                    self.log(f"  å¤„ç†æ€»å¸§æ•°: {total_frames_processed}")
                    self.log(f"  å¹³å‡æ¯å¸§å¤„ç†æ—¶é—´: {avg_frame_time:.3f}ç§’")

                    # è®¡ç®—å¤„ç†é€Ÿåº¦
                    processing_speed = total_frames_processed / total_segment_time if total_segment_time > 0 else 0
                    self.log(f"  å¤„ç†é€Ÿåº¦: {processing_speed:.1f} å¸§/ç§’")
            else:
                self.log("æµ‹è¯•æ¨¡å¼ç»Ÿè®¡:")
                self.log(f"  æ€»æ£€æµ‹æ—¶é—´: {total_video_time:.2f}ç§’")
                self.log(f"  æ€»è®¡æ£€æµ‹åˆ°é‡å¤å¸§: {self.dup_frame_count}ä¸ª")
                self.log(f"  æ£€æµ‹æ€»å¸§æ•°: {total_frames_processed}")
                if total_frames_processed > 0:
                    avg_detection_time = total_segment_time / total_frames_processed
                    self.log(f"  å¹³å‡æ¯å¸§æ£€æµ‹æ—¶é—´: {avg_detection_time:.3f}ç§’")

            self.log("=" * 60)

            if self.test_mode_var.get():
                self.log(f"æµ‹è¯•æ¨¡å¼å®Œæˆï¼æµ‹è¯•ç»“æœä¿å­˜åœ¨: {temp_dirs['base']}")
            else:
                self.log(f"å¤„ç†å®Œæˆï¼è¾“å‡ºæ–‡ä»¶: {self.video_base_name}_super_resolved.mp4")

            # é‡ç½®çŠ¶æ€
            self.current_segment_index = 0
            self.current_frame_in_segment = 0
            self.total_segments = 0
            self.segments = []
            self.processed_segments = []
            self.dup_frame_count = 0
            self.update_dup_info(0)

            # æ¸…ç©ºå†å²ç¼“å­˜
            self.clear_history_cache()

            return True

        except Exception as e:
            self.log(f"å¤„ç†è§†é¢‘å¤±è´¥: {str(e)}")
            import traceback
            self.log(f"é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
            return False

    def cleanup_temp_after_success(self, temp_dirs):
        """æˆåŠŸå¤„ç†åè‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            # åªä¿ç•™04_processed_segmentsç›®å½•ï¼Œæ¸…ç†å…¶ä»–ä¸´æ—¶ç›®å½•
            dirs_to_clean = [
                temp_dirs['original_segments'],
                temp_dirs['audio'],
                temp_dirs['segment_frames'],
                os.path.join(temp_dirs['base'], "05_immediate_merge")
            ]

            cleaned_count = 0
            for dir_path in dirs_to_clean:
                if os.path.exists(dir_path):
                    try:
                        shutil.rmtree(dir_path)
                        cleaned_count += 1
                        self.log(f"å·²æ¸…ç†ä¸´æ—¶ç›®å½•: {os.path.basename(dir_path)}")
                    except Exception as e:
                        self.log(f"æ¸…ç†ä¸´æ—¶ç›®å½•æ—¶å‡ºé”™({os.path.basename(dir_path)}): {e}")

            self.log(f"è‡ªåŠ¨æ¸…ç†å®Œæˆï¼Œå…±æ¸…ç† {cleaned_count} ä¸ªä¸´æ—¶ç›®å½•")
        except Exception as e:
            self.log(f"è‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    def concatenate_videos(self, video_list, output_path):
        """æ‹¼æ¥è§†é¢‘ç‰‡æ®µ"""
        self.log("å¼€å§‹æ‹¼æ¥è§†é¢‘ç‰‡æ®µ...")
        start_time = time.time()

        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶åˆ—è¡¨
        list_file = tempfile.mktemp(suffix=".txt")

        with open(list_file, 'w', encoding='utf-8') as f:
            for video in video_list:
                f.write(f"file '{os.path.abspath(video)}'\n")

        # ä½¿ç”¨ffmpegæ‹¼æ¥
        cmd = [
            'ffmpeg', '-y',
            '-f', 'concat',
            '-safe', '0',
            '-i', list_file,
            '-c', 'copy',
            output_path
        ]

        try:
            concat_start = time.time()
            subprocess.run(cmd, check=True, capture_output=True, text=True)
            concat_time = time.time() - concat_start

            total_time = time.time() - start_time
            self.log(f"è§†é¢‘æ‹¼æ¥å®Œæˆ: {output_path}")
            self.log(f"  æ€»è€—æ—¶: {total_time:.2f}ç§’ (æ‹¼æ¥: {concat_time:.2f}s)")
            return True
        except subprocess.CalledProcessError as e:
            self.log(f"è§†é¢‘æ‹¼æ¥å¤±è´¥: {e.stderr}")
            raise
        finally:
            if os.path.exists(list_file):
                os.remove(list_file)

    def process_videos(self):
        """ä¸»å¤„ç†å‡½æ•° - å¤„ç†å¤šä¸ªè§†é¢‘"""
        try:
            # æ£€æŸ¥è¾“å…¥
            if not self.input_paths:
                messagebox.showerror("é”™è¯¯", "è¯·é€‰æ‹©æœ‰æ•ˆçš„è¾“å…¥è§†é¢‘æ–‡ä»¶")
                return

            output_dir = self.output_dir.get()
            if not output_dir:
                messagebox.showerror("é”™è¯¯", "è¯·é€‰æ‹©è¾“å‡ºç›®å½•")
                return

            # éªŒè¯å‚æ•°ï¼ˆæ·»åŠ ç©ºå€¼æ£€æŸ¥ï¼‰
            try:
                hash_threshold_str = self.hash_threshold_var.get()
                ssim_threshold_str = self.ssim_threshold_var.get()
                history_size_str = self.history_size_var.get()

                # å¤„ç†ç©ºå€¼
                hash_threshold = int(hash_threshold_str) if hash_threshold_str else 3
                ssim_threshold = float(ssim_threshold_str) if ssim_threshold_str else 0.98
                history_size = int(history_size_str) if history_size_str else 20

                if hash_threshold < 0 or hash_threshold > 10:
                    messagebox.showwarning("è­¦å‘Š", "å“ˆå¸Œç›¸ä¼¼åº¦é˜ˆå€¼å¿…é¡»åœ¨0-10ä¹‹é—´")
                    self.hash_threshold_var.set("3")
                    return

                if ssim_threshold < 0.9 or ssim_threshold > 1.0:
                    messagebox.showwarning("è­¦å‘Š", "SSIMé˜ˆå€¼å¿…é¡»åœ¨0.9-1.0ä¹‹é—´")
                    self.ssim_threshold_var.set("0.98")
                    return

                if history_size < 1 or history_size > 200:
                    messagebox.showwarning("è­¦å‘Š", "å†å²å¸§æ•°é‡å¿…é¡»åœ¨1-200ä¹‹é—´")
                    self.history_size_var.set("20")
                    return
            except ValueError:
                messagebox.showerror("é”™è¯¯", "å‚æ•°æ ¼å¼é”™è¯¯")
                return

            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)

            # æ›´æ–°çŠ¶æ€
            self.processing = True
            self.paused = False
            self.stopped = False
            self.process_btn.config(state='disabled')

            # æ ¹æ®å¤„ç†æ¨¡å¼è®¾ç½®æš‚åœæŒ‰é’®çŠ¶æ€
            if not self.enable_dup_detect_var.get():
                self.pause_btn.config(state='disabled')  # ç›´æ¥å¤„ç†æ¨¡å¼ç¦ç”¨æš‚åœ
                self.log("ç›´æ¥å¤„ç†æ¨¡å¼ï¼šæš‚åœåŠŸèƒ½å·²ç¦ç”¨")
            else:
                self.pause_btn.config(state='normal')  # é€å¸§å¤„ç†æ¨¡å¼å¯ç”¨æš‚åœ

            self.stop_btn.config(state='normal')
            self.update_status("æ‰¹é‡å¤„ç†ä¸­...", "blue")

            # å¯åŠ¨å†…å­˜ç›‘æ§
            self.start_memory_monitor()

            # å¤„ç†æ¯ä¸ªè§†é¢‘
            total_videos = len(self.input_paths)
            total_start_time = time.time()

            self.log("=" * 60)
            self.log(f"å¼€å§‹æ‰¹é‡å¤„ç† {total_videos} ä¸ªè§†é¢‘")
            self.log("=" * 60)

            for i in range(self.current_video_index, total_videos):
                if self.stopped:
                    break

                self.current_video_index = i
                video_path = self.input_paths[i]

                # æ›´æ–°è¿›åº¦ä¿¡æ¯
                self.progress_info.config(text=f"æ­£åœ¨å¤„ç†è§†é¢‘ {i + 1}/{total_videos}: {os.path.basename(video_path)}")
                self.root.update_idletasks()

                # å¤„ç†å•ä¸ªè§†é¢‘
                success = self.process_single_video(video_path)

                if not success and not self.stopped:
                    # å•ä¸ªè§†é¢‘å¤„ç†å¤±è´¥ï¼Œä½†ç”¨æˆ·æ²¡æœ‰åœæ­¢ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª
                    self.log(f"è§†é¢‘å¤„ç†å¤±è´¥ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªè§†é¢‘")
                    continue

                if self.stopped:
                    break

            if self.stopped:
                self.log(f"æ‰¹é‡å¤„ç†å·²åœæ­¢")
                self.update_status("å·²åœæ­¢", "orange")
                return

            # æ‰€æœ‰è§†é¢‘å¤„ç†å®Œæˆ
            total_elapsed = time.time() - total_start_time

            self.log("=" * 60)
            self.log("æ‰¹é‡å¤„ç†å®Œæˆç»Ÿè®¡:")
            self.log(f"  å¤„ç†è§†é¢‘æ€»æ•°: {total_videos}")
            self.log(f"  æ€»å¤„ç†æ—¶é—´: {total_elapsed:.2f}ç§’")
            self.log(f"  å¹³å‡æ¯ä¸ªè§†é¢‘å¤„ç†æ—¶é—´: {total_elapsed / total_videos:.2f}ç§’")
            self.log("=" * 60)

            if self.test_mode_var.get():
                self.update_status("æµ‹è¯•å®Œæˆï¼", "green")
                messagebox.showinfo("æµ‹è¯•å®Œæˆ",
                                    f"æ‰¹é‡æµ‹è¯•å®Œæˆï¼\n\n"
                                    f"å…±å¤„ç† {total_videos} ä¸ªè§†é¢‘\n"
                                    f"æ€»è€—æ—¶: {total_elapsed:.2f}ç§’\n"
                                    f"æµ‹è¯•ç»“æœä¿å­˜åœ¨å„è§†é¢‘çš„ä¸´æ—¶ç›®å½•ä¸­")
            else:
                self.update_status("æ‰¹é‡å¤„ç†å®Œæˆï¼", "green")
                messagebox.showinfo("å®Œæˆ",
                                    f"æ‰¹é‡å¤„ç†å®Œæˆï¼\n\n"
                                    f"å…±å¤„ç† {total_videos} ä¸ªè§†é¢‘\n"
                                    f"æ€»è€—æ—¶: {total_elapsed:.2f}ç§’\n"
                                    f"è¾“å‡ºç›®å½•: {output_dir}")

            # é‡ç½®çŠ¶æ€
            self.current_video_index = 0

        except Exception as e:
            self.log(f"æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}")
            self.update_status(f"å¤„ç†å¤±è´¥: {str(e)}", "red")
            messagebox.showerror("é”™è¯¯", f"å¤„ç†å¤±è´¥: {str(e)}")
        finally:
            self.processing = False
            self.paused = False
            self.stopped = False
            self.process_btn.config(state='normal')
            self.pause_btn.config(state='disabled', text="â¸ æš‚åœ")
            self.stop_btn.config(state='disabled')

            # æ¸…ç†GPUå†…å­˜
            if self.generator and not self.test_mode_var.get():
                try:
                    # ç¡®ä¿æ¨¡å‹ä»GPUç§»é™¤
                    self.generator = self.generator.cpu()
                    del self.generator
                    self.generator = None
                    torch.cuda.empty_cache()
                    torch.cuda.synchronize()  # ç­‰å¾…CUDAæ“ä½œå®Œæˆ
                    self.log("GPUå†…å­˜å·²å®Œå…¨é‡Šæ”¾")
                except Exception as e:
                    self.log(f"æ¸…ç†GPUå†…å­˜æ—¶å‡ºé”™: {e}")

    def start_processing(self):
        """å¼€å§‹å¤„ç†"""
        if self.processing:
            return

        # éªŒè¯å‚æ•°
        try:
            scale = int(self.scale_var.get())
            model = self.model_var.get()
            history_size = int(self.history_size_var.get())

            if model in ["GRL", "DAT"] and scale != 4:
                messagebox.showwarning("è­¦å‘Š", f"{model}æ¨¡å‹åªæ”¯æŒ4å€ç¼©æ”¾")
                self.scale_var.set("4")
                return

            if scale not in [2, 4]:
                messagebox.showwarning("è­¦å‘Š", "ç¼©æ”¾å› å­å¿…é¡»æ˜¯2æˆ–4")
                return

            if history_size < 1 or history_size > 200:
                messagebox.showwarning("è­¦å‘Š", "å†å²å¸§æ•°é‡å¿…é¡»åœ¨1-200ä¹‹é—´")
                self.history_size_var.set("20")
                return
        except ValueError:
            messagebox.showerror("é”™è¯¯", "å‚æ•°æ ¼å¼é”™è¯¯")
            return

        # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œå¤„ç†
        self.processing_thread = threading.Thread(target=self.process_videos)
        self.processing_thread.daemon = True
        self.processing_thread.start()

    def toggle_pause(self):
        """åˆ‡æ¢æš‚åœ/ç»§ç»­çŠ¶æ€"""
        if not self.processing:
            return

        # ç›´æ¥å¤„ç†æ¨¡å¼ä¸æ”¯æŒæš‚åœ
        if not self.enable_dup_detect_var.get():
            messagebox.showinfo("æç¤º", "ç›´æ¥å¤„ç†æ¨¡å¼ä¸æ”¯æŒæš‚åœåŠŸèƒ½")
            return

        if self.paused:
            # ç»§ç»­å¤„ç†
            self.paused = False
            self.pause_btn.config(text="â¸ æš‚åœ")
            self.update_status("å¤„ç†ä¸­...", "blue")
            self.log("å¤„ç†ç»§ç»­")

            # é€šçŸ¥æš‚åœçš„çº¿ç¨‹ç»§ç»­
            with self.pause_cv:
                self.pause_cv.notify_all()
        else:
            # æš‚åœå¤„ç†
            self.paused = True
            self.pause_btn.config(text="â–¶ ç»§ç»­")
            self.update_status("å·²æš‚åœ", "orange")
            self.log("å¤„ç†æš‚åœ")

    def stop_processing(self):
        """åœæ­¢å¤„ç†"""
        if not self.processing:
            return

        response = messagebox.askyesno("åœæ­¢å¤„ç†",
                                       "æ˜¯å¦ç¡®è®¤åœæ­¢å¤„ç†ï¼Ÿ")

        if not response:
            return

        self.log("æ­£åœ¨åœæ­¢å¤„ç†...")
        self.update_status("æ­£åœ¨åœæ­¢...", "orange")
        self.stopped = True
        self.paused = False  # ç¡®ä¿æš‚åœçŠ¶æ€è¢«æ¸…é™¤

        # é€šçŸ¥æš‚åœçš„çº¿ç¨‹ç»§ç»­ï¼ˆå¦‚æœæ˜¯æš‚åœçŠ¶æ€ï¼‰
        with self.pause_cv:
            self.pause_cv.notify_all()

        # ç­‰å¾…å¤„ç†çº¿ç¨‹å“åº”
        time.sleep(0.5)

        self.log("å¤„ç†å·²åœæ­¢")
        self.update_status("å·²åœæ­¢", "orange")

        # é‡ç½®æŒ‰é’®çŠ¶æ€
        self.process_btn.config(state='normal')
        self.pause_btn.config(state='disabled', text="â¸ æš‚åœ")
        self.stop_btn.config(state='disabled')
        self.paused = False
        self.processing = False

    def run(self):
        """è¿è¡ŒGUI"""
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)

        # å±…ä¸­æ˜¾ç¤ºçª—å£
        self.root.update_idletasks()
        width = self.root.winfo_width()
        height = self.root.winfo_height()
        x = (self.root.winfo_screenwidth() // 2) - (width // 2)
        y = (self.root.winfo_screenheight() // 2) - (height // 2)
        self.root.geometry(f'{width}x{height}+{x}+{y}')

        self.root.mainloop()

    def on_closing(self):
        """å…³é—­çª—å£æ—¶çš„æ¸…ç†"""
        # ä¿å­˜é…ç½®
        self.save_config()

        if self.processing:
            response = messagebox.askyesno("é€€å‡º",
                                           "å¤„ç†ä»åœ¨è¿›è¡Œä¸­ï¼Œæ˜¯å¦ç¡®è®¤é€€å‡ºï¼Ÿ\n\n"
                                           "é€€å‡ºåè¿›åº¦å°†ä¸ä¼šä¿å­˜ï¼Œä¸‹æ¬¡éœ€è¦é‡æ–°å¼€å§‹å¤„ç†ã€‚")

            if not response:
                return

            self.log("æ­£åœ¨åœæ­¢å¤„ç†å¹¶é€€å‡º...")
            self.processing = False
            self.stopped = True
            self.paused = False

            # é€šçŸ¥æš‚åœçš„çº¿ç¨‹ç»§ç»­ï¼ˆå¦‚æœæ˜¯æš‚åœçŠ¶æ€ï¼‰
            with self.pause_cv:
                self.pause_cv.notify_all()

            time.sleep(1.0)  # ç»™çº¿ç¨‹æ›´å¤šæ—¶é—´å“åº”

        self.root.destroy()


def main():
    """ä¸»å‡½æ•°"""
    app = APISRVideoProcessor()
    app.run()


if __name__ == "__main__":
    main()