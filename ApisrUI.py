import os
import pickle
import shutil
import subprocess
import sys
import tempfile
import threading
import time
import tkinter as tk
import warnings
import collections
import json
from datetime import datetime
from pathlib import Path
from tkinter import ttk, filedialog, messagebox
from tkinter.scrolledtext import ScrolledText

import cv2
import numpy as np
import torch
from PIL import Image
import imagehash
from skimage.metrics import structural_similarity as ssim

warnings.filterwarnings('ignore')

# æ·»åŠ APISRé¡¹ç›®è·¯å¾„
sys.path.append('.')

# ç›´æ¥ä»architectureå¯¼å…¥æ¨¡å‹
try:
    from architecture.rrdb import RRDBNet
    from architecture.grl import GRL
    from architecture.dat import DAT
    from architecture.cunet import UNet_Full
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å‹æ¶æ„æ—¶å‡ºé”™: {e}")
    print("è¯·ç¡®ä¿architectureæ¨¡å—åœ¨Pythonè·¯å¾„ä¸­")
    sys.exit(1)


class ModernButton(ttk.Button):
    """ç°ä»£åŒ–æŒ‰é’®æ ·å¼"""

    def __init__(self, master=None, **kwargs):
        super().__init__(master, **kwargs)
        self.configure(style='Accent.TButton')


class APISRVideoProcessor:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("APISR è§†é¢‘è¶…åˆ†è¾¨ç‡å¤„ç†å·¥å…·")
        self.root.geometry("1200x800")

        # è®¾ç½®çª—å£å›¾æ ‡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        try:
            self.root.iconbitmap('icon.ico')
        except:
            pass

        # è®¾ç½®ä¸»é¢˜é¢œè‰²
        self.bg_color = "#f5f5f7"
        self.sidebar_color = "#2c3e50"
        self.accent_color = "#3498db"
        self.success_color = "#27ae60"
        self.warning_color = "#f39c12"
        self.danger_color = "#e74c3c"

        # é…ç½®æ–‡ä»¶è·¯å¾„
        self.config_file = "apisr_config.json"

        # åˆå§‹åŒ–å˜é‡
        self.input_paths = []  # æ”¹ä¸ºå­˜å‚¨å¤šä¸ªè§†é¢‘è·¯å¾„çš„åˆ—è¡¨
        self.output_dir = tk.StringVar()
        self.model_var = tk.StringVar(value="GRL")
        self.scale_var = tk.StringVar(value="4")
        self.segment_duration = tk.StringVar(value="20")
        self.downsample_threshold = tk.StringVar(value="720")
        self.float16_var = tk.BooleanVar(value=False)
        self.crop_for_4x_var = tk.BooleanVar(value=True)
        self.batch_size_var = tk.StringVar(value="1")
        self.tile_size_var = tk.StringVar(value="128")
        self.hash_threshold_var = tk.StringVar(value="3")
        self.ssim_threshold_var = tk.StringVar(value="0.98")
        self.enable_dup_detect_var = tk.BooleanVar(value=True)
        self.use_ssim_var = tk.BooleanVar(value=True)
        self.use_hash_var = tk.BooleanVar(value=True)
        self.test_mode_var = tk.BooleanVar(value=False)
        self.enable_history_var = tk.BooleanVar(value=True)
        self.history_size_var = tk.StringVar(value="20")
        self.immediate_merge_var = tk.BooleanVar(value=False)  # æ–°å¢ï¼šç«‹å³åˆæˆè§†é¢‘é€‰é¡¹
        self.last_test_mode_state = False  # è®°å½•ä¸Šä¸€æ¬¡çš„æµ‹è¯•æ¨¡å¼çŠ¶æ€

        # è®¾ç½®æ ·å¼
        self.setup_styles()

        # æ¨¡å‹ä¿¡æ¯
        self.models = {
            "GRL": {"scale": [4], "weight": "pretrained/4x_APISR_GRL_GAN_generator.pth"},
            "DAT": {"scale": [4], "weight": "pretrained/4x_APISR_DAT_GAN_generator.pth"},
            "RRDB": {"scale": [2, 4], "weight": {
                "2": "pretrained/2x_APISR_RRDB_GAN_generator.pth",
                "4": "pretrained/4x_APISR_RRDB_GAN_generator.pth"
            }},
            "CUNET": {"scale": [4], "weight": "pretrained/4x_APISR_CUNET_GAN_generator.pth"}
        }

        # å¤„ç†å™¨çŠ¶æ€
        self.processing = False
        self.paused = False
        self.stopped = False
        self.generator = None
        self.weight_dtype = torch.float32

        # è¿›åº¦æ¢å¤ç›¸å…³
        self.current_video_index = 0  # æ–°å¢ï¼šå½“å‰å¤„ç†è§†é¢‘ç´¢å¼•
        self.current_segment_index = 0
        self.current_frame_in_segment = 0
        self.total_segments = 0
        self.segments = []
        self.processed_segments = []
        self.progress_data_file = None

        # é‡å¤å¸§æ£€æµ‹ç›¸å…³
        self.dup_frame_count = 0

        # æ–°å¢ï¼šå†å²å¸§ç¼“å­˜ç³»ç»Ÿ
        self.init_history_cache()

        # ä¸´æ—¶æ–‡ä»¶è·¯å¾„
        self.temp_base_dir = None
        self.current_segment_frames_dir = None
        self.video_base_name = None
        self.is_test_mode_folder = False  # æ–°å¢ï¼šæ ‡è®°æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼æ–‡ä»¶å¤¹

        # çº¿ç¨‹æ§åˆ¶
        self.processing_thread = None
        self.pause_event = threading.Event()
        self.stop_event = threading.Event()
        self.processing_lock = threading.Lock()
        self.last_save_time = 0
        self.save_interval = 10

        # æ–°å¢ï¼šæš‚åœæ—¶çš„å†…å­˜ä¼˜åŒ–
        self.pause_lock = threading.Lock()
        self.pause_cv = threading.Condition(self.pause_lock)
        self.should_sleep = False

        # è®¾ç½®å†å²å¸§æ•°é‡éªŒè¯
        self.setup_history_size_validation()

        self.setup_ui()

        # è®¾ç½®åˆå§‹æ¨¡å‹
        self.on_model_change()

        # åŠ è½½é…ç½®æ–‡ä»¶
        self.load_config()

        # ç»‘å®šé…ç½®ä¿å­˜äº‹ä»¶
        self.setup_config_save_bindings()

        # è·Ÿè¸ªæµ‹è¯•æ¨¡å¼å˜åŒ–
        self.test_mode_var.trace('w', self.on_test_mode_changed)

    def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if os.path.exists(self.config_file):
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)

                # è®¾ç½®å˜é‡
                if 'model' in config:
                    self.model_var.set(config['model'])
                if 'scale' in config:
                    self.scale_var.set(str(config['scale']))
                if 'segment_duration' in config:
                    self.segment_duration.set(str(config['segment_duration']))
                if 'downsample_threshold' in config:
                    self.downsample_threshold.set(str(config['downsample_threshold']))
                if 'float16' in config:
                    self.float16_var.set(config['float16'])
                if 'crop_for_4x' in config:
                    self.crop_for_4x_var.set(config['crop_for_4x'])
                if 'batch_size' in config:
                    self.batch_size_var.set(str(config['batch_size']))
                if 'tile_size' in config:
                    self.tile_size_var.set(str(config['tile_size']))
                if 'hash_threshold' in config:
                    self.hash_threshold_var.set(str(config['hash_threshold']))
                if 'ssim_threshold' in config:
                    self.ssim_threshold_var.set(str(config['ssim_threshold']))
                if 'enable_dup_detect' in config:
                    self.enable_dup_detect_var.set(config['enable_dup_detect'])
                if 'use_ssim' in config:
                    self.use_ssim_var.set(config['use_ssim'])
                if 'use_hash' in config:
                    self.use_hash_var.set(config['use_hash'])
                if 'test_mode' in config:
                    self.test_mode_var.set(config['test_mode'])
                    self.last_test_mode_state = config['test_mode']  # è®°å½•åˆå§‹çŠ¶æ€
                if 'enable_history' in config:
                    self.enable_history_var.set(config['enable_history'])
                if 'history_size' in config:
                    self.history_size_var.set(str(config['history_size']))
                if 'immediate_merge' in config:
                    self.immediate_merge_var.set(config['immediate_merge'])

                self.log(f"å·²ä» {self.config_file} åŠ è½½é…ç½®")

                # æ›´æ–°UIçŠ¶æ€
                self.on_model_change()
                self.toggle_history_settings()
            except Exception as e:
                self.log(f"åŠ è½½é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        else:
            self.log("æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")

    def save_config(self):
        """ä¿å­˜é…ç½®æ–‡ä»¶"""
        try:
            config = {
                'model': self.model_var.get(),
                'scale': int(self.scale_var.get()),
                'segment_duration': int(self.segment_duration.get()),
                'downsample_threshold': int(self.downsample_threshold.get()),
                'float16': self.float16_var.get(),
                'crop_for_4x': self.crop_for_4x_var.get(),
                'batch_size': int(self.batch_size_var.get()),
                'tile_size': int(self.tile_size_var.get()),
                'hash_threshold': int(self.hash_threshold_var.get()),
                'ssim_threshold': float(self.ssim_threshold_var.get()),
                'enable_dup_detect': self.enable_dup_detect_var.get(),
                'use_ssim': self.use_ssim_var.get(),
                'use_hash': self.use_hash_var.get(),
                'test_mode': self.test_mode_var.get(),
                'enable_history': self.enable_history_var.get(),
                'history_size': int(self.history_size_var.get()),
                'immediate_merge': self.immediate_merge_var.get(),  # ä¿å­˜ç«‹å³åˆæˆé€‰é¡¹
                'last_saved': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }

            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=4, ensure_ascii=False)

            self.log(f"é…ç½®å·²ä¿å­˜åˆ° {self.config_file}")
        except Exception as e:
            self.log(f"ä¿å­˜é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    def on_test_mode_changed(self, *args):
        """æµ‹è¯•æ¨¡å¼å˜åŒ–æ—¶çš„å¤„ç†"""
        current_state = self.test_mode_var.get()

        # å¦‚æœä»éæµ‹è¯•æ¨¡å¼åˆ‡æ¢åˆ°æµ‹è¯•æ¨¡å¼
        if current_state and not self.last_test_mode_state:
            # å¼¹å‡ºç¡®è®¤çª—å£
            response = messagebox.askyesno("ç¡®è®¤æµ‹è¯•æ¨¡å¼",
                                           "æµ‹è¯•æ¨¡å¼ä»…è¿›è¡Œé‡å¤å¸§æ£€æµ‹ï¼Œä¸è¿›è¡Œè¶…åˆ†è¾¨ç‡å¤„ç†ï¼Œä¸”ä¼šåˆ›å»ºå•ç‹¬çš„æµ‹è¯•æ–‡ä»¶å¤¹ã€‚\n\n"
                                           "æ˜¯å¦ç¡®è®¤å¯ç”¨æµ‹è¯•æ¨¡å¼ï¼Ÿ")

            if not response:
                # ç”¨æˆ·å–æ¶ˆï¼Œæ¢å¤åŸæ¥çš„çŠ¶æ€
                self.test_mode_var.set(False)
                return
            else:
                self.log("æµ‹è¯•æ¨¡å¼å·²å¯ç”¨ - ä»…è¿›è¡Œé‡å¤å¸§æ£€æµ‹ï¼Œä¸è¿›è¡Œè¶…åˆ†è¾¨ç‡å¤„ç†")

        # å¦‚æœä»æµ‹è¯•æ¨¡å¼åˆ‡æ¢åˆ°éæµ‹è¯•æ¨¡å¼
        elif not current_state and self.last_test_mode_state:
            response = messagebox.askyesno("é€€å‡ºæµ‹è¯•æ¨¡å¼",
                                           "é€€å‡ºæµ‹è¯•æ¨¡å¼å°†åˆ é™¤æµ‹è¯•æ¨¡å¼äº§ç”Ÿçš„ä¸´æ—¶æ–‡ä»¶ã€‚\n\n"
                                           "æ˜¯å¦ç¡®è®¤é€€å‡ºæµ‹è¯•æ¨¡å¼ï¼Ÿ")

            if response:
                # æ¸…ç†æµ‹è¯•æ¨¡å¼çš„ä¸´æ—¶æ–‡ä»¶
                self.cleanup_test_mode_files()
                self.log("å·²é€€å‡ºæµ‹è¯•æ¨¡å¼ï¼Œæµ‹è¯•æ–‡ä»¶å·²æ¸…ç†")
            else:
                # ç”¨æˆ·å–æ¶ˆï¼Œæ¢å¤æµ‹è¯•æ¨¡å¼
                self.test_mode_var.set(True)
                return

        # æ›´æ–°çŠ¶æ€è®°å½•
        self.last_test_mode_state = current_state

    def cleanup_test_mode_files(self):
        """æ¸…ç†æµ‹è¯•æ¨¡å¼äº§ç”Ÿçš„ä¸´æ—¶æ–‡ä»¶"""
        output_dir = self.output_dir.get()
        if not output_dir or not os.path.exists(output_dir):
            return

        # æŸ¥æ‰¾æ‰€æœ‰æµ‹è¯•æ¨¡å¼çš„ä¸´æ—¶ç›®å½•
        test_temp_dirs = []
        for item in os.listdir(output_dir):
            item_path = os.path.join(output_dir, item)
            if os.path.isdir(item_path) and item.endswith("_test_temp"):
                test_temp_dirs.append(item_path)

        if test_temp_dirs:
            self.log(f"æ‰¾åˆ° {len(test_temp_dirs)} ä¸ªæµ‹è¯•æ¨¡å¼ä¸´æ—¶ç›®å½•")
            for temp_dir in test_temp_dirs:
                try:
                    shutil.rmtree(temp_dir)
                    self.log(f"å·²æ¸…ç†æµ‹è¯•ä¸´æ—¶ç›®å½•: {os.path.basename(temp_dir)}")
                except Exception as e:
                    self.log(f"æ¸…ç†æµ‹è¯•ä¸´æ—¶ç›®å½•æ—¶å‡ºé”™: {e}")

    def setup_history_size_validation(self):
        """è®¾ç½®å†å²å¸§æ•°é‡è¾“å…¥çš„éªŒè¯"""

        def validate_history_size(*args):
            # è·å–å½“å‰å€¼
            current_value = self.history_size_var.get()

            # å¦‚æœä¸æ˜¯æ•°å­—ï¼Œæ¢å¤ä¸ºé»˜è®¤å€¼20
            if not current_value.isdigit():
                self.history_size_var.set("20")
                return

            # è½¬æ¢ä¸ºæ•´æ•°
            try:
                history_size = int(current_value)

                # é™åˆ¶èŒƒå›´åœ¨1-100ä¹‹é—´
                if history_size < 1:
                    self.history_size_var.set("1")
                elif history_size > 100:
                    self.history_size_var.set("100")
            except ValueError:
                # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œæ¢å¤ä¸ºé»˜è®¤å€¼20
                self.history_size_var.set("20")

        # æ·»åŠ traceç›‘å¬å˜é‡å˜åŒ–
        self.history_size_var.trace('w', lambda *args: validate_history_size())

    def setup_styles(self):
        """è®¾ç½®UIæ ·å¼"""
        style = ttk.Style()
        style.theme_use('clam')
        style.configure('TFrame', background=self.bg_color)
        style.configure('TLabel', background=self.bg_color, font=('Segoe UI', 9))
        style.configure('TButton', font=('Segoe UI', 9), padding=5)
        style.configure('Accent.TButton', background=self.accent_color,
                        foreground='white', font=('Segoe UI', 9, 'bold'))
        style.configure('TProgressbar', thickness=15, background=self.accent_color)
        style.configure('TLabelframe', background=self.bg_color, borderwidth=2)
        style.configure('TLabelframe.Label', background=self.bg_color,
                        font=('Segoe UI', 10, 'bold'))

    def init_history_cache(self):
        """åˆå§‹åŒ–å†å²å¸§ç¼“å­˜"""
        # æ£€æŸ¥å†å²å¸§å¼€å…³
        if not self.enable_history_var.get():
            # å¦‚æœå†å²å¸§åŠŸèƒ½å…³é—­ï¼Œä½¿ç”¨é»˜è®¤å€¼1ï¼ˆåªä¸å‰ä¸€å¸§æ¯”è¾ƒï¼‰
            history_size = 1
        else:
            try:
                history_size = int(self.history_size_var.get())
                # ç¡®ä¿å†å²å¸§æ•°é‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
                if history_size < 1:
                    history_size = 1
                    self.history_size_var.set("1")
                elif history_size > 100:
                    history_size = 100
                    self.history_size_var.set("100")
            except:
                history_size = 20  # é»˜è®¤å€¼
                self.history_size_var.set("20")

        self.frame_history = collections.deque(maxlen=history_size)
        self.frame_hash_history = collections.deque(maxlen=history_size)

        if self.use_ssim_var.get():
            self.frame_thumbnail_history = collections.deque(maxlen=history_size)
        else:
            self.frame_thumbnail_history = None

        self.frame_sr_history = collections.deque(maxlen=history_size)
        self.frame_idx_history = collections.deque(maxlen=history_size)

    def setup_ui(self):
        """è®¾ç½®UIå¸ƒå±€"""
        # ä¸»å®¹å™¨
        main_container = ttk.Frame(self.root)
        main_container.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

        # æ ‡é¢˜
        title_frame = ttk.Frame(main_container)
        title_frame.pack(fill=tk.X, pady=(0, 10))

        title_label = tk.Label(title_frame, text="APISR è§†é¢‘è¶…åˆ†è¾¨ç‡å¤„ç†å·¥å…·",
                               font=('Segoe UI', 18, 'bold'),
                               foreground=self.sidebar_color,
                               background=self.bg_color)
        title_label.pack(side=tk.LEFT)

        version_label = tk.Label(title_frame, text="v2.0",  # ç‰ˆæœ¬æ›´æ–°åˆ°2.0
                                 font=('Segoe UI', 9),
                                 foreground='#7f8c8d',
                                 background=self.bg_color)
        version_label.pack(side=tk.RIGHT)

        # ä¸»å†…å®¹åŒºåŸŸ - ä½¿ç”¨PanedWindowå®ç°å¯è°ƒæ•´å¤§å°çš„åˆ†å‰²
        paned_window = tk.PanedWindow(main_container, orient=tk.HORIZONTAL, sashwidth=8, sashrelief=tk.RAISED)
        paned_window.pack(fill=tk.BOTH, expand=True, pady=(0, 10))

        # å·¦ä¾§å‚æ•°é¢æ¿
        left_frame = ttk.Frame(paned_window)
        paned_window.add(left_frame, width=500, minsize=400)

        # å³ä¾§æ—¥å¿—é¢æ¿
        right_frame = ttk.Frame(paned_window)
        paned_window.add(right_frame, width=600, minsize=400)

        # è®¾ç½®é¢æ¿
        self.setup_left_panel(left_frame)
        self.setup_right_panel(right_frame)

        # è¿›åº¦æ¡åŒºåŸŸ
        progress_frame = ttk.Frame(main_container)
        progress_frame.pack(fill=tk.X, pady=(0, 5))

        # è¿›åº¦ä¿¡æ¯
        progress_info_frame = ttk.Frame(progress_frame)
        progress_info_frame.pack(fill=tk.X, pady=(0, 3))

        self.progress_info = ttk.Label(progress_info_frame, text="å‡†å¤‡å¼€å§‹å¤„ç†",
                                       font=('Segoe UI', 10, 'bold'),
                                       foreground=self.sidebar_color)
        self.progress_info.pack(side=tk.LEFT, anchor=tk.W)

        self.detailed_progress_info = ttk.Label(progress_info_frame, text="",
                                                font=('Segoe UI', 9),
                                                foreground='#7f8c8d')
        self.detailed_progress_info.pack(side=tk.RIGHT, anchor=tk.E)

        # è¿›åº¦æ¡
        self.progress_var = tk.DoubleVar()
        self.progress_bar = ttk.Progressbar(progress_frame, variable=self.progress_var,
                                            maximum=100, length=600,
                                            style='TProgressbar')
        self.progress_bar.pack(fill=tk.X, pady=(0, 5))

        # æ§åˆ¶æŒ‰é’®åŒºåŸŸ
        control_frame = ttk.Frame(main_container)
        control_frame.pack(fill=tk.X, pady=(5, 5))

        # å·¦ä¾§æŒ‰é’®ç»„
        left_btn_frame = ttk.Frame(control_frame)
        left_btn_frame.pack(side=tk.LEFT)

        self.process_btn = ModernButton(left_btn_frame, text="â–¶ å¼€å§‹å¤„ç†",
                                        command=self.start_processing, width=12)
        self.process_btn.pack(side=tk.LEFT, padx=2)

        self.pause_btn = ttk.Button(left_btn_frame, text="â¸ æš‚åœ",
                                    command=self.toggle_pause, width=12, state='disabled')
        self.pause_btn.pack(side=tk.LEFT, padx=2)

        self.stop_btn = ttk.Button(left_btn_frame, text="â¹ åœæ­¢",
                                   command=self.stop_processing, width=12, state='disabled')
        self.stop_btn.pack(side=tk.LEFT, padx=2)

        # ä¸­é—´ç»Ÿè®¡ä¿¡æ¯
        center_btn_frame = ttk.Frame(control_frame)
        center_btn_frame.pack(side=tk.LEFT, padx=20)

        self.dup_info = tk.Label(center_btn_frame, text="é‡å¤å¸§: 0",
                                 font=('Segoe UI', 9),
                                 foreground=self.warning_color,
                                 background=self.bg_color)
        self.dup_info.pack()

        # å³ä¾§æŒ‰é’®ç»„
        right_btn_frame = ttk.Frame(control_frame)
        right_btn_frame.pack(side=tk.RIGHT)

        ttk.Button(right_btn_frame, text="ğŸ“‚ æ‰“å¼€ç›®å½•",
                   command=self.open_output_dir, width=12).pack(side=tk.RIGHT, padx=2)

        ttk.Button(right_btn_frame, text="æ¸…ç†ä¸´æ—¶æ–‡ä»¶",
                   command=self.cleanup_temp_files, width=12).pack(side=tk.RIGHT, padx=2)

        ttk.Button(right_btn_frame, text="æ¸…ç©ºæ—¥å¿—",
                   command=self.clear_log, width=12).pack(side=tk.RIGHT, padx=2)

        # æ–°å¢ï¼šä¿å­˜é…ç½®æŒ‰é’®
        ttk.Button(right_btn_frame, text="ä¿å­˜é…ç½®",
                   command=self.save_config, width=12).pack(side=tk.RIGHT, padx=2)

        # åº•éƒ¨çŠ¶æ€æ 
        status_bar = ttk.Frame(main_container, height=20)
        status_bar.pack(fill=tk.X, pady=(5, 0))

        self.status_label = tk.Label(status_bar, text="å‡†å¤‡å°±ç»ª",
                                     font=('Segoe UI', 9),
                                     foreground=self.success_color,
                                     background=self.bg_color)
        self.status_label.pack(side=tk.LEFT, padx=10)

        gpu_info = self.get_gpu_info()
        self.gpu_label = tk.Label(status_bar, text=gpu_info,
                                  font=('Segoe UI', 9),
                                  foreground='#7f8c8d',
                                  background=self.bg_color)
        self.gpu_label.pack(side=tk.RIGHT, padx=10)

    def setup_config_save_bindings(self):
        """è®¾ç½®é…ç½®ä¿å­˜çš„äº‹ä»¶ç»‘å®š"""
        # ä¸ºæ‰€æœ‰é‡è¦å˜é‡æ·»åŠ traceï¼Œå½“å€¼æ”¹å˜æ—¶è‡ªåŠ¨ä¿å­˜é…ç½®
        variables_to_trace = [
            (self.model_var, 'w'),
            (self.scale_var, 'w'),
            (self.segment_duration, 'w'),
            (self.downsample_threshold, 'w'),
            (self.batch_size_var, 'w'),
            (self.tile_size_var, 'w'),
            (self.hash_threshold_var, 'w'),
            (self.ssim_threshold_var, 'w'),
            (self.history_size_var, 'w'),
        ]

        for var, mode in variables_to_trace:
            var.trace(mode, lambda *args: self.save_config())

        # ä¸ºBooleanVaræ·»åŠ å›è°ƒ
        boolean_vars = [
            self.float16_var,
            self.crop_for_4x_var,
            self.enable_dup_detect_var,
            self.use_ssim_var,
            self.use_hash_var,
            self.immediate_merge_var,  # æ–°å¢
        ]

        for var in boolean_vars:
            var.trace('w', lambda *args: self.save_config())

        # æµ‹è¯•æ¨¡å¼å•ç‹¬å¤„ç†ï¼Œå› ä¸ºæœ‰å¼¹çª—ç¡®è®¤
        # æ³¨æ„ï¼šæµ‹è¯•æ¨¡å¼çš„traceå·²ç»åœ¨__init__ä¸­å•ç‹¬è®¾ç½®

    def setup_left_panel(self, parent):
        """è®¾ç½®å·¦ä¾§å‚æ•°é¢æ¿"""
        # åˆ›å»ºä¸»æ¡†æ¶
        main_frame = ttk.Frame(parent)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)

        # ä½¿ç”¨gridå¸ƒå±€ï¼Œ4è¡Œ2åˆ—
        for i in range(4):
            main_frame.grid_rowconfigure(i, weight=1, pad=2)
        for i in range(2):
            main_frame.grid_columnconfigure(i, weight=1, pad=5)

        row = 0

        # 1. æ–‡ä»¶è®¾ç½®éƒ¨åˆ† - å ç”¨ä¸€è¡Œä¸¤åˆ—
        file_frame = ttk.LabelFrame(main_frame, text="æ–‡ä»¶è®¾ç½®", padding=8)
        file_frame.grid(row=row, column=0, columnspan=2, sticky="nsew", padx=2, pady=2)
        file_frame.grid_columnconfigure(1, weight=1)

        # è¾“å…¥æ–‡ä»¶ - ç´§å‡‘å¸ƒå±€
        ttk.Label(file_frame, text="è¾“å…¥è§†é¢‘:", font=('Segoe UI', 9)).grid(row=0, column=0, sticky=tk.W, pady=(0, 2))

        input_btn_frame = ttk.Frame(file_frame)
        input_btn_frame.grid(row=0, column=1, sticky=tk.W, pady=(0, 2))

        ttk.Button(input_btn_frame, text="é€‰æ‹©è§†é¢‘æ–‡ä»¶",
                   command=self.select_input_files, width=18).pack(side=tk.LEFT)

        # åˆ›å»ºæ ‡ç­¾æ˜¾ç¤ºé€‰æ‹©çš„è§†é¢‘æ•°é‡
        self.input_info_label = tk.Label(input_btn_frame, text="æœªé€‰æ‹©è§†é¢‘",
                                         font=('Segoe UI', 8),
                                         foreground='#7f8c8d',
                                         background=self.bg_color)
        self.input_info_label.pack(side=tk.LEFT, padx=(10, 0))

        # è¾“å‡ºç›®å½• - ç´§å‡‘å¸ƒå±€
        ttk.Label(file_frame, text="è¾“å‡ºç›®å½•:", font=('Segoe UI', 9)).grid(row=1, column=0, sticky=tk.W, pady=(2, 0))

        output_entry_frame = ttk.Frame(file_frame)
        output_entry_frame.grid(row=1, column=1, sticky=tk.EW, pady=(2, 0))
        output_entry_frame.grid_columnconfigure(0, weight=1)

        output_entry = ttk.Entry(output_entry_frame, textvariable=self.output_dir, font=('Segoe UI', 9))
        output_entry.grid(row=0, column=0, sticky=tk.EW, padx=(0, 5))
        ttk.Button(output_entry_frame, text="æµè§ˆ", command=self.select_output_dir, width=8).grid(row=0, column=1)

        row += 1

        # 2. æ¨¡å‹å‚æ•°éƒ¨åˆ†
        model_frame = ttk.LabelFrame(main_frame, text="æ¨¡å‹å‚æ•°", padding=8)
        model_frame.grid(row=row, column=0, sticky="nsew", padx=2, pady=2)

        # ä½¿ç”¨gridå¸ƒå±€å†…éƒ¨æ§ä»¶
        ttk.Label(model_frame, text="é€‰æ‹©æ¨¡å‹:").grid(row=0, column=0, sticky=tk.W, pady=2, padx=(0, 5))
        model_combo = ttk.Combobox(model_frame, textvariable=self.model_var,
                                   values=list(self.models.keys()),
                                   state="readonly", width=12, font=('Segoe UI', 9))
        model_combo.grid(row=0, column=1, sticky=tk.W, pady=2)
        model_combo.bind('<<ComboboxSelected>>', self.on_model_change)

        ttk.Label(model_frame, text="ç¼©æ”¾å› å­:").grid(row=1, column=0, sticky=tk.W, pady=2, padx=(0, 5))
        self.scale_combo = ttk.Combobox(model_frame, textvariable=self.scale_var,
                                        state="readonly", width=12, font=('Segoe UI', 9))
        self.scale_combo.grid(row=1, column=1, sticky=tk.W, pady=2)

        ttk.Label(model_frame, text="åˆ†æ®µæ—¶é•¿(ç§’):").grid(row=2, column=0, sticky=tk.W, pady=2, padx=(0, 5))
        ttk.Entry(model_frame, textvariable=self.segment_duration,
                  width=12, font=('Segoe UI', 9)).grid(row=2, column=1, sticky=tk.W, pady=2)

        ttk.Label(model_frame, text="ä¸‹é‡‡æ ·é˜ˆå€¼:").grid(row=3, column=0, sticky=tk.W, pady=2, padx=(0, 5))
        ttk.Entry(model_frame, textvariable=self.downsample_threshold,
                  width=12, font=('Segoe UI', 9)).grid(row=3, column=1, sticky=tk.W, pady=2)

        # 3. æ€§èƒ½è®¾ç½®éƒ¨åˆ†
        perf_frame = ttk.LabelFrame(main_frame, text="æ€§èƒ½è®¾ç½®", padding=8)
        perf_frame.grid(row=row, column=1, sticky="nsew", padx=2, pady=2)

        ttk.Label(perf_frame, text="æ‰¹å¤„ç†å¤§å°:").grid(row=0, column=0, sticky=tk.W, pady=2, padx=(0, 5))
        ttk.Entry(perf_frame, textvariable=self.batch_size_var,
                  width=10, font=('Segoe UI', 9)).grid(row=0, column=1, sticky=tk.W, pady=2)

        ttk.Label(perf_frame, text="ç“¦ç‰‡å¤§å°:").grid(row=1, column=0, sticky=tk.W, pady=2, padx=(0, 5))
        ttk.Entry(perf_frame, textvariable=self.tile_size_var,
                  width=10, font=('Segoe UI', 9)).grid(row=1, column=1, sticky=tk.W, pady=2)

        ttk.Label(perf_frame, text="æ•°æ®ç±»å‹:").grid(row=2, column=0, sticky=tk.W, pady=2, padx=(0, 5))
        ttk.Checkbutton(perf_frame, text="FP16åŠ é€Ÿ",
                        variable=self.float16_var).grid(row=2, column=1, sticky=tk.W, pady=2)

        ttk.Label(perf_frame, text="è¾¹ç¼˜å¤„ç†:").grid(row=3, column=0, sticky=tk.W, pady=2, padx=(0, 5))
        ttk.Checkbutton(perf_frame, text="4å€ç¼©æ”¾æ—¶è£å‰ª",
                        variable=self.crop_for_4x_var).grid(row=3, column=1, sticky=tk.W, pady=2)

        row += 1

        # 4. é‡å¤å¸§æ£€æµ‹éƒ¨åˆ† - å ç”¨ä¸€è¡Œä¸¤åˆ—
        dup_frame = ttk.LabelFrame(main_frame, text="é‡å¤å¸§æ£€æµ‹è®¾ç½®", padding=8)
        dup_frame.grid(row=row, column=0, columnspan=2, sticky="nsew", padx=2, pady=2)

        # å¯ç”¨æ£€æµ‹
        ttk.Checkbutton(dup_frame, text="å¯ç”¨é‡å¤å¸§æ£€æµ‹",
                        variable=self.enable_dup_detect_var).grid(row=0, column=0, sticky=tk.W, pady=2, columnspan=2)

        # æ£€æµ‹æ–¹æ³•
        method_frame = ttk.Frame(dup_frame)
        method_frame.grid(row=1, column=0, columnspan=2, sticky=tk.W, pady=2)
        ttk.Checkbutton(method_frame, text="å“ˆå¸Œæ£€æµ‹",
                        variable=self.use_hash_var, width=10).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Checkbutton(method_frame, text="SSIMæ£€æµ‹",
                        variable=self.use_ssim_var, width=10).pack(side=tk.LEFT)

        # å“ˆå¸Œé˜ˆå€¼
        ttk.Label(dup_frame, text="å“ˆå¸Œé˜ˆå€¼:").grid(row=2, column=0, sticky=tk.W, pady=2)
        hash_frame = ttk.Frame(dup_frame)
        hash_frame.grid(row=2, column=1, sticky=tk.W, pady=2)
        ttk.Entry(hash_frame, textvariable=self.hash_threshold_var,
                  width=8, font=('Segoe UI', 9)).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Label(hash_frame, text="(0-10)", foreground='#7f8c8d', font=('Segoe UI', 8)).pack(side=tk.LEFT)

        # SSIMé˜ˆå€¼
        ttk.Label(dup_frame, text="SSIMé˜ˆå€¼:").grid(row=3, column=0, sticky=tk.W, pady=2)
        ssim_frame = ttk.Frame(dup_frame)
        ssim_frame.grid(row=3, column=1, sticky=tk.W, pady=2)
        ttk.Entry(ssim_frame, textvariable=self.ssim_threshold_var,
                  width=8, font=('Segoe UI', 9)).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Label(ssim_frame, text="(0.9-1.0)", foreground='#7f8c8d', font=('Segoe UI', 8)).pack(side=tk.LEFT)

        # å†å²å¸§è®¾ç½®
        ttk.Label(dup_frame, text="å†å²å¸§è®¾ç½®:").grid(row=4, column=0, sticky=tk.W, pady=2)
        history_setting_frame = ttk.Frame(dup_frame)
        history_setting_frame.grid(row=4, column=1, sticky=tk.W, pady=2)

        # å†å²å¸§å¼€å…³
        self.history_check = ttk.Checkbutton(history_setting_frame, text="å¯ç”¨",
                                             variable=self.enable_history_var,
                                             command=self.toggle_history_settings)
        self.history_check.pack(side=tk.LEFT, padx=(0, 10))

        # å†å²å¸§æ•°é‡è¾“å…¥æ¡†
        history_size_frame = ttk.Frame(history_setting_frame)
        history_size_frame.pack(side=tk.LEFT)

        ttk.Label(history_size_frame, text="æ•°é‡:").pack(side=tk.LEFT, padx=(0, 5))

        # åˆ›å»ºéªŒè¯å‡½æ•°ï¼Œç¡®ä¿åªèƒ½è¾“å…¥æ•´æ•°
        def validate_integer_input(action, value_if_allowed):
            if action == '1':  # æ’å…¥æ“ä½œ
                if value_if_allowed == '':
                    return True
                try:
                    int(value_if_allowed)
                    return True
                except ValueError:
                    return False
            return True

        # åˆ›å»ºå†å²å¸§æ•°é‡è¾“å…¥æ¡†
        vcmd = (self.root.register(validate_integer_input), '%d', '%P')
        self.history_entry = ttk.Entry(history_size_frame, textvariable=self.history_size_var,
                                       width=6, font=('Segoe UI', 9),
                                       validate='key', validatecommand=vcmd,
                                       state='normal' if self.enable_history_var.get() else 'disabled')
        self.history_entry.pack(side=tk.LEFT, padx=(0, 5))

        ttk.Label(history_size_frame, text="(1-100)", foreground='#7f8c8d', font=('Segoe UI', 8)).pack(side=tk.LEFT)

        row += 1

        # 5. å…¶ä»–é€‰é¡¹å’Œè¯´æ˜ä¿¡æ¯éƒ¨åˆ†
        bottom_frame = ttk.Frame(main_frame)
        bottom_frame.grid(row=row, column=0, columnspan=2, sticky="nsew", pady=(2, 0))
        bottom_frame.grid_columnconfigure(0, weight=1)
        bottom_frame.grid_columnconfigure(1, weight=1)

        # å¤„ç†é€‰é¡¹éƒ¨åˆ†
        options_frame = ttk.LabelFrame(bottom_frame, text="å¤„ç†é€‰é¡¹", padding=8)
        options_frame.grid(row=0, column=0, sticky="nsew", padx=(0, 5), pady=0)

        ttk.Checkbutton(options_frame, text="æµ‹è¯•æ¨¡å¼(ä»…é‡å¤å¸§æ£€æµ‹)",
                        variable=self.test_mode_var).pack(anchor=tk.W, pady=2)

        # æ–°å¢ï¼šç«‹å³åˆæˆè§†é¢‘é€‰é¡¹
        ttk.Checkbutton(options_frame, text="ç«‹å³åˆæˆè§†é¢‘",
                        variable=self.immediate_merge_var).pack(anchor=tk.W, pady=2)

        ttk.Checkbutton(options_frame, text="å¯ç”¨é…ç½®è‡ªåŠ¨ä¿å­˜",
                        command=self.save_config).pack(anchor=tk.W, pady=2)

        # è¯´æ˜ä¿¡æ¯éƒ¨åˆ†
        info_frame = ttk.LabelFrame(bottom_frame, text="è¯´æ˜", padding=8)
        info_frame.grid(row=0, column=1, sticky="nsew", padx=(5, 0), pady=0)

        info_text = """1. æ”¯æŒæ‰¹é‡å¤„ç†å¤šä¸ªè§†é¢‘
2. æš‚åœæ—¶å¯ä¿å­˜è¿›åº¦
3. é‡å¤å¸§æ£€æµ‹å¯åŠ é€Ÿå¤„ç†
4. å†å²å¸§æ•°é‡å¯é…ç½®
5. é…ç½®è‡ªåŠ¨ä¿å­˜
6. æµ‹è¯•æ¨¡å¼æœ‰ç¡®è®¤çª—å£
7. å¯ç«‹å³åˆæˆè§†é¢‘
8. æ–°å¢æ€§èƒ½è®¡æ—¶åŠŸèƒ½"""

        info_label = tk.Label(info_frame, text=info_text,
                              font=('Segoe UI', 8),
                              foreground='#7f8c8d',
                              background=self.bg_color,
                              justify=tk.LEFT)
        info_label.pack(anchor=tk.W)

    def setup_right_panel(self, parent):
        """è®¾ç½®å³ä¾§æ—¥å¿—é¢æ¿"""
        log_frame = ttk.LabelFrame(parent, text="å¤„ç†æ—¥å¿—", padding=8)
        log_frame.pack(fill=tk.BOTH, expand=True)

        self.log_text = ScrolledText(log_frame, height=28, width=60,
                                     font=('Consolas', 9),
                                     bg='#2c3e50', fg='white',
                                     insertbackground='white')
        self.log_text.pack(fill=tk.BOTH, expand=True)

    def toggle_history_settings(self):
        """åˆ‡æ¢å†å²å¸§è®¾ç½®çš„çŠ¶æ€"""
        if self.enable_history_var.get():
            self.history_entry.config(state='normal')
            self.log("å†å²å¸§åŠŸèƒ½å·²å¯ç”¨")
        else:
            self.history_entry.config(state='disabled')

    def get_gpu_info(self):
        """è·å–GPUä¿¡æ¯"""
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024 ** 3
            return f"GPU: {gpu_name} ({gpu_memory:.1f}GB)"
        return "æ— å¯ç”¨GPU"

    def on_model_change(self, event=None):
        """å½“æ¨¡å‹æ”¹å˜æ—¶æ›´æ–°å¯ç”¨ç¼©æ”¾å› å­"""
        model = self.model_var.get()
        if model in self.models:
            scales = self.models[model]["scale"]
            self.scale_combo['values'] = scales
            if str(scales[0]) in self.scale_var.get():
                self.scale_var.set(str(scales[0]))
            else:
                self.scale_var.set(str(scales[0]))

    def select_input_files(self):
        """é€‰æ‹©å¤šä¸ªè¾“å…¥è§†é¢‘æ–‡ä»¶"""
        filenames = filedialog.askopenfilenames(
            title="é€‰æ‹©è§†é¢‘æ–‡ä»¶",
            filetypes=[
                ("è§†é¢‘æ–‡ä»¶", "*.mp4 *.avi *.mov *.mkv *.flv *.wmv"),
                ("æ‰€æœ‰æ–‡ä»¶", "*.*")
            ]
        )

        if filenames:
            # æŒ‰æ–‡ä»¶åæ’åº
            self.input_paths = sorted(list(filenames))

            # æ›´æ–°æ˜¾ç¤ºä¿¡æ¯
            if len(self.input_paths) == 1:
                file_name = os.path.basename(self.input_paths[0])
                if len(file_name) > 20:
                    file_name = file_name[:17] + "..."
                self.input_info_label.config(text=f"å·²é€‰æ‹©: {file_name}")
            else:
                self.input_info_label.config(text=f"å·²é€‰æ‹© {len(self.input_paths)} ä¸ªè§†é¢‘")
                self.log(f"å·²é€‰æ‹© {len(self.input_paths)} ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œå°†æŒ‰ä»¥ä¸‹é¡ºåºå¤„ç†:")
                for i, path in enumerate(self.input_paths):
                    self.log(f"  {i + 1}. {os.path.basename(path)}")

            # è‡ªåŠ¨è®¾ç½®è¾“å‡ºç›®å½•ï¼ˆä»¥ç¬¬ä¸€ä¸ªè§†é¢‘çš„ç›®å½•ä¸ºå‡†ï¼‰
            if not self.output_dir.get():
                output_path = Path(self.input_paths[0]).parent / "APISR_Output"
                self.output_dir.set(str(output_path))

    def select_output_dir(self):
        """é€‰æ‹©è¾“å‡ºç›®å½•"""
        directory = filedialog.askdirectory(title="é€‰æ‹©è¾“å‡ºç›®å½•")
        if directory:
            self.output_dir.set(directory)

    def open_output_dir(self):
        """æ‰“å¼€è¾“å‡ºç›®å½•"""
        output_dir = self.output_dir.get()
        if output_dir and os.path.exists(output_dir):
            try:
                if sys.platform == "win32":
                    os.startfile(output_dir)
                elif sys.platform == "darwin":
                    subprocess.Popen(["open", output_dir])
                else:
                    subprocess.Popen(["xdg-open", output_dir])
            except Exception as e:
                self.log(f"æ‰“å¼€ç›®å½•å¤±è´¥: {e}")

    def setup_temp_dirs(self, video_path):
        """è®¾ç½®ä¸´æ—¶ç›®å½•ç»“æ„ - åŸºäºè§†é¢‘æ–‡ä»¶åå’Œæµ‹è¯•æ¨¡å¼"""
        output_dir = self.output_dir.get()
        if not output_dir:
            return None

        # è·å–è§†é¢‘åŸºç¡€åç§°
        video_name = Path(video_path).stem

        # æ ¹æ®æµ‹è¯•æ¨¡å¼æ·»åŠ åç¼€
        if self.test_mode_var.get():
            temp_dir_suffix = "_test_temp"
            self.is_test_mode_folder = True
        else:
            temp_dir_suffix = "_temp"
            self.is_test_mode_folder = False

        # åŸºäºè§†é¢‘æ–‡ä»¶ååˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir_name = f"{video_name}{temp_dir_suffix}"
        self.temp_base_dir = os.path.join(output_dir, temp_dir_name)

        # åˆ›å»ºæ ‡å‡†åŒ–çš„ç›®å½•ç»“æ„
        dirs = {
            'base': self.temp_base_dir,
            'original_segments': os.path.join(self.temp_base_dir, "01_original_segments"),
            'audio': os.path.join(self.temp_base_dir, "02_audio"),
            'segment_frames': os.path.join(self.temp_base_dir, "03_segment_frames"),  # ç›´æ¥æ”¾ç½®before/afteræ–‡ä»¶å¤¹
            'processed_segments': os.path.join(self.temp_base_dir, "04_processed_segments"),
            'logs': os.path.join(self.temp_base_dir, "05_logs"),
            'immediate_merge': os.path.join(self.temp_base_dir, "06_immediate_merge")  # æ–°å¢ï¼šç«‹å³åˆæˆç›®å½•
        }

        # åˆ›å»ºç›®å½•
        for path in dirs.values():
            os.makedirs(path, exist_ok=True)

        return dirs

    def setup_segment_frame_dirs(self, segment_index):
        """ä¸ºå½“å‰ç‰‡æ®µè®¾ç½®å¸§ç›®å½• - ç›´æ¥åœ¨03_segment_framesä¸‹åˆ›å»ºæ–‡ä»¶å¤¹"""
        if not self.temp_base_dir:
            return None, None

        # ç›´æ¥åœ¨03_segment_framesä¸‹åˆ›å»ºå¸¦å‰åç¼€çš„æ–‡ä»¶å¤¹
        before_dir = os.path.join(self.temp_base_dir, "03_segment_frames", f"segment_{segment_index:03d}_before")
        after_dir = os.path.join(self.temp_base_dir, "03_segment_frames", f"segment_{segment_index:03d}_after")

        os.makedirs(before_dir, exist_ok=True)
        os.makedirs(after_dir, exist_ok=True)

        return before_dir, after_dir

    def cleanup_segment_frame_dirs(self, segment_index):
        """æ¸…ç†å½“å‰ç‰‡æ®µçš„å¸§ç›®å½•"""
        if not self.temp_base_dir:
            return

        # æ¸…ç†beforeå’Œafteræ–‡ä»¶å¤¹
        before_dir = os.path.join(self.temp_base_dir, "03_segment_frames", f"segment_{segment_index:03d}_before")
        after_dir = os.path.join(self.temp_base_dir, "03_segment_frames", f"segment_{segment_index:03d}_after")

        for dir_path in [before_dir, after_dir]:
            if os.path.exists(dir_path):
                try:
                    shutil.rmtree(dir_path)
                except Exception as e:
                    pass

    def cleanup_temp_files(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        output_dir = self.output_dir.get()
        if output_dir:
            # æŸ¥æ‰¾æ‰€æœ‰åŸºäºè§†é¢‘æ–‡ä»¶åçš„ä¸´æ—¶ç›®å½•
            temp_dirs = []
            for item in os.listdir(output_dir):
                item_path = os.path.join(output_dir, item)
                if os.path.isdir(item_path) and (item.endswith("_temp") or item.endswith("_test_temp")):
                    temp_dirs.append(item_path)

            if temp_dirs:
                response = messagebox.askyesno("æ¸…ç†ä¸´æ—¶æ–‡ä»¶",
                                               f"æ‰¾åˆ° {len(temp_dirs)} ä¸ªä¸´æ—¶ç›®å½•ã€‚æ˜¯å¦æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶ï¼Ÿ\n"
                                               f"ï¼ˆåŒ…æ‹¬æ™®é€šæ¨¡å¼å’Œæµ‹è¯•æ¨¡å¼çš„ä¸´æ—¶æ–‡ä»¶ï¼‰")
                if response:
                    for temp_dir in temp_dirs:
                        try:
                            shutil.rmtree(temp_dir)
                            self.log(f"å·²æ¸…ç†ä¸´æ—¶ç›®å½•: {os.path.basename(temp_dir)}")
                        except Exception as e:
                            self.log(f"æ¸…ç†ä¸´æ—¶ç›®å½•æ—¶å‡ºé”™: {e}")
                    messagebox.showinfo("æ¸…ç†å®Œæˆ", "ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ")
            else:
                messagebox.showinfo("æ¸…ç†ä¸´æ—¶æ–‡ä»¶", "æ²¡æœ‰æ‰¾åˆ°ä¸´æ—¶æ–‡ä»¶")

    def log(self, message):
        """æ·»åŠ æ—¥å¿—"""
        if not hasattr(self, 'log_text'):
            # å¦‚æœlog_textè¿˜ä¸å­˜åœ¨ï¼Œå…ˆæ‰“å°åˆ°æ§åˆ¶å°
            print(f"[åˆå§‹åŒ–] {message}")
            return

        timestamp = datetime.now().strftime("%H:%M:%S")
        self.log_text.insert(tk.END, f"[{timestamp}] {message}\n")
        self.log_text.see(tk.END)
        self.root.update_idletasks()

    def clear_log(self):
        """æ¸…ç©ºæ—¥å¿—"""
        self.log_text.delete(1.0, tk.END)

    def update_status(self, message, color="black"):
        """æ›´æ–°çŠ¶æ€"""
        colors = {
            "black": "#2c3e50",
            "green": self.success_color,
            "blue": self.accent_color,
            "orange": self.warning_color,
            "red": self.danger_color
        }
        self.status_label.config(text=message, foreground=colors.get(color, color))
        self.root.update_idletasks()

    def update_progress_info(self):
        """æ›´æ–°è¿›åº¦ä¿¡æ¯"""
        if self.total_segments > 0:
            info = f"è§†é¢‘ {self.current_video_index + 1}/{len(self.input_paths)} - ç‰‡æ®µ {self.current_segment_index + 1}/{self.total_segments}"
            self.progress_info.config(text=info)
            self.root.update_idletasks()

    def update_detailed_progress(self, current_frame, total_frames):
        """æ›´æ–°è¯¦ç»†è¿›åº¦ä¿¡æ¯"""
        if total_frames > 0:
            percentage = current_frame / total_frames * 100
            info = f"å½“å‰ç‰‡æ®µ: ç¬¬ {current_frame}/{total_frames} å¸§ ({percentage:.1f}%)"
            self.detailed_progress_info.config(text=info)
            self.root.update_idletasks()

    def update_dup_info(self, dup_count):
        """æ›´æ–°é‡å¤å¸§ä¿¡æ¯"""
        self.dup_info.config(text=f"é‡å¤å¸§: {dup_count}")
        self.root.update_idletasks()

    def update_progress(self, value):
        """æ›´æ–°è¿›åº¦æ¡"""
        self.progress_var.set(value)
        self.root.update_idletasks()

    def save_progress(self, force=False):
        """ä¿å­˜è¿›åº¦ - ä¼˜åŒ–ä¿å­˜é¢‘ç‡"""
        if not self.output_dir.get() or not self.temp_base_dir:
            return

        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜
        current_time = time.time()
        if not force and current_time - self.last_save_time < self.save_interval:
            return

        # ä¿å­˜å½“å‰è§†é¢‘çš„è¿›åº¦
        current_video_path = self.input_paths[self.current_video_index] if self.current_video_index < len(
            self.input_paths) else ""

        progress_data = {
            'current_video_index': self.current_video_index,
            'current_video_path': current_video_path,
            'model': self.model_var.get(),
            'scale': int(self.scale_var.get()),
            'downsample_threshold': int(self.downsample_threshold.get()),
            'float16': self.float16_var.get(),
            'crop_for_4x': self.crop_for_4x_var.get(),
            'batch_size': int(self.batch_size_var.get()),
            'hash_threshold': int(self.hash_threshold_var.get()),
            'ssim_threshold': float(self.ssim_threshold_var.get()),
            'use_hash': self.use_hash_var.get(),
            'use_ssim': self.use_ssim_var.get(),
            'test_mode': self.test_mode_var.get(),
            'enable_history': self.enable_history_var.get(),
            'history_size': int(self.history_size_var.get()),
            'immediate_merge': self.immediate_merge_var.get(),  # æ–°å¢
            'current_segment_index': self.current_segment_index,
            'current_frame_in_segment': self.current_frame_in_segment,
            'total_segments': self.total_segments,
            'segments': self.segments,
            'processed_segments': self.processed_segments,
            'temp_base_dir': self.temp_base_dir,
            'is_test_mode_folder': self.is_test_mode_folder,  # æ–°å¢
            'dup_frame_count': self.dup_frame_count,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

        progress_file = os.path.join(self.temp_base_dir, "progress_data.pkl")
        try:
            with open(progress_file, 'wb') as f:
                pickle.dump(progress_data, f)

            self.last_save_time = current_time
            if force:
                self.log(
                    f"è¿›åº¦å·²ä¿å­˜: è§†é¢‘ {self.current_video_index + 1} - ç‰‡æ®µ {self.current_segment_index + 1} çš„ç¬¬ {self.current_frame_in_segment + 1} å¸§")
        except Exception as e:
            self.log(f"ä¿å­˜è¿›åº¦æ—¶å‡ºé”™: {e}")

    # ============================================================
    # æ¨¡å‹åŠ è½½å‡½æ•°ï¼ˆä»test_utils.pyæ•´åˆï¼‰
    # ============================================================

    def load_rrdb(self, generator_weight_PATH, scale, print_options=False):
        '''åŠ è½½RRDBæ¨¡å‹'''
        start_time = time.time()

        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint_g = torch.load(generator_weight_PATH)

        # æŸ¥æ‰¾ç”Ÿæˆå™¨æƒé‡
        if 'params_ema' in checkpoint_g:
            # å¯¹äºå®˜æ–¹çš„ESRNET/ESRGANæƒé‡
            weight = checkpoint_g['params_ema']
            generator = RRDBNet(3, 3, scale=scale)  # é»˜è®¤å—æ•°ä¸º6

        elif 'params' in checkpoint_g:
            # å¯¹äºå®˜æ–¹çš„ESRNET/ESRGANæƒé‡
            weight = checkpoint_g['params']
            generator = RRDBNet(3, 3, scale=scale)

        elif 'model_state_dict' in checkpoint_g:
            # å¯¹äºä¸ªäººè®­ç»ƒçš„æƒé‡
            weight = checkpoint_g['model_state_dict']
            generator = RRDBNet(3, 3, scale=scale)

        else:
            raise ValueError("This weight is not supported")

        # å¤„ç†torch.compileæƒé‡é”®é‡å‘½å
        old_keys = [key for key in weight]
        for old_key in old_keys:
            if old_key[:10] == "_orig_mod.":
                new_key = old_key[10:]
                weight[new_key] = weight[old_key]
                del weight[old_key]

        generator.load_state_dict(weight)
        generator = generator.eval().cuda()

        # æ‰“å°é€‰é¡¹ä»¥æ˜¾ç¤ºä½¿ç”¨äº†å“ªäº›è®¾ç½®
        if print_options:
            if 'opt' in checkpoint_g:
                for key in checkpoint_g['opt']:
                    value = checkpoint_g['opt'][key]
                    print(f'{key} : {value}')

        elapsed = time.time() - start_time
        self.log(f"RRDBæ¨¡å‹åŠ è½½è€—æ—¶: {elapsed:.2f}ç§’")

        return generator

    def load_cunet(self, generator_weight_PATH, scale, print_options=False):
        '''åŠ è½½CUNETæ¨¡å‹'''
        start_time = time.time()

        if scale != 2:
            raise NotImplementedError("We only support 2x in CUNET")

        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint_g = torch.load(generator_weight_PATH)

        # æŸ¥æ‰¾ç”Ÿæˆå™¨æƒé‡
        if 'model_state_dict' in checkpoint_g:
            # å¯¹äºä¸ªäººè®­ç»ƒçš„æƒé‡
            weight = checkpoint_g['model_state_dict']
            loss = checkpoint_g["lowest_generator_weight"]
            if "iteration" in checkpoint_g:
                iteration = checkpoint_g["iteration"]
            else:
                iteration = "NAN"
            generator = UNet_Full()
            # generator = torch.compile(generator)  # torch.compile
            self.log(f"the generator weight is {loss} at iteration {iteration}")

        else:
            raise ValueError("This weight is not supported")

        # å¤„ç†torch.compileæƒé‡é”®é‡å‘½å
        old_keys = [key for key in weight]
        for old_key in old_keys:
            if old_key[:10] == "_orig_mod.":
                new_key = old_key[10:]
                weight[new_key] = weight[old_key]
                del weight[old_key]

        generator.load_state_dict(weight)
        generator = generator.eval().cuda()

        # æ‰“å°é€‰é¡¹ä»¥æ˜¾ç¤ºä½¿ç”¨äº†å“ªäº›è®¾ç½®
        if print_options:
            if 'opt' in checkpoint_g:
                for key in checkpoint_g['opt']:
                    value = checkpoint_g['opt'][key]
                    print(f'{key} : {value}')

        elapsed = time.time() - start_time
        self.log(f"CUNETæ¨¡å‹åŠ è½½è€—æ—¶: {elapsed:.2f}ç§’")

        return generator

    def load_grl(self, generator_weight_PATH, scale=4):
        '''åŠ è½½GRLæ¨¡å‹'''
        start_time = time.time()

        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint_g = torch.load(generator_weight_PATH)

        # æŸ¥æ‰¾ç”Ÿæˆå™¨æƒé‡
        if 'model_state_dict' in checkpoint_g:
            weight = checkpoint_g['model_state_dict']

            # GRL tinyæ¨¡å‹ï¼ˆæ³¨æ„ï¼štiny2ç‰ˆæœ¬ï¼‰
            generator = GRL(
                upscale=scale,
                img_size=64,
                window_size=8,
                depths=[4, 4, 4, 4],
                embed_dim=64,
                num_heads_window=[2, 2, 2, 2],
                num_heads_stripe=[2, 2, 2, 2],
                mlp_ratio=2,
                qkv_proj_type="linear",
                anchor_proj_type="avgpool",
                anchor_window_down_factor=2,
                out_proj_type="linear",
                conv_type="1conv",
                upsampler="nearest+conv",  # æ›´æ”¹
            ).cuda()

        else:
            raise ValueError("This weight is not supported")

        generator.load_state_dict(weight)
        generator = generator.eval().cuda()

        # è®¡ç®—å‚æ•°æ•°é‡
        num_params = 0
        for p in generator.parameters():
            if p.requires_grad:
                num_params += p.numel()

        elapsed = time.time() - start_time
        self.log(f"GRLæ¨¡å‹åŠ è½½è€—æ—¶: {elapsed:.2f}ç§’")
        self.log(f"GRLæ¨¡å‹å‚æ•°æ•°é‡: {num_params / 10 ** 6: 0.2f}M")

        return generator

    def load_dat(self, generator_weight_PATH, scale=4):
        '''åŠ è½½DATæ¨¡å‹'''
        start_time = time.time()

        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint_g = torch.load(generator_weight_PATH)

        # æŸ¥æ‰¾ç”Ÿæˆå™¨æƒé‡
        if 'model_state_dict' in checkpoint_g:
            weight = checkpoint_g['model_state_dict']

            # é»˜è®¤çš„DATå°æ¨¡å‹
            generator = DAT(upscale=4,
                            in_chans=3,
                            img_size=64,
                            img_range=1.,
                            depth=[6, 6, 6, 6, 6, 6],
                            embed_dim=180,
                            num_heads=[6, 6, 6, 6, 6, 6],
                            expansion_factor=2,
                            resi_connection='1conv',
                            split_size=[8, 16],
                            upsampler='pixelshuffledirect',
                            ).cuda()

        else:
            raise ValueError("This weight is not supported")

        generator.load_state_dict(weight)
        generator = generator.eval().cuda()

        # è®¡ç®—å‚æ•°æ•°é‡
        num_params = 0
        for p in generator.parameters():
            if p.requires_grad:
                num_params += p.numel()

        elapsed = time.time() - start_time
        self.log(f"DATæ¨¡å‹åŠ è½½è€—æ—¶: {elapsed:.2f}ç§’")
        self.log(f"DATæ¨¡å‹å‚æ•°æ•°é‡: {num_params / 10 ** 6: 0.2f}M")

        return generator

    # ============================================================
    # é‡å¤å¸§æ£€æµ‹å‡½æ•°
    # ============================================================

    def calculate_frame_hash(self, frame):
        """è®¡ç®—å¸§çš„æ„ŸçŸ¥å“ˆå¸Œå€¼ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        start_time = time.time()

        # å…ˆç¼©å°å›¾åƒä»¥å‡å°‘è®¡ç®—é‡
        h, w = frame.shape[:2]
        if h > 360 or w > 480:
            new_h = 360
            new_w = int(w * (360 / h))
            frame_resized = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        else:
            frame_resized = frame

        frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
        pil_img = Image.fromarray(frame_rgb)

        # ä½¿ç”¨æ›´é«˜æ•ˆçš„å“ˆå¸Œæ–¹æ³•
        frame_hash = imagehash.phash(pil_img, hash_size=8)  # å‡å°å“ˆå¸Œå¤§å°ä»¥æé«˜è®¡ç®—é€Ÿåº¦

        elapsed = time.time() - start_time
        if elapsed > 0.01:  # åªè®°å½•è€—æ—¶è¾ƒé•¿çš„å“ˆå¸Œè®¡ç®—
            self.log(f"å“ˆå¸Œè®¡ç®—è€—æ—¶: {elapsed:.3f}ç§’")

        return frame_hash

    def calculate_ssim_fast(self, frame1, frame2):
        """å¿«é€Ÿè®¡ç®—SSIMï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        start_time = time.time()

        # å°†å›¾åƒç¼©å°ä»¥åŠ é€Ÿè®¡ç®—
        h1, w1 = frame1.shape[:2]
        h2, w2 = frame2.shape[:2]

        # ä½¿ç”¨è¾ƒå°çš„å›ºå®šå°ºå¯¸
        target_size = (180, 320)  # 16:9çš„æ¯”ä¾‹

        # å¦‚æœå›¾åƒæ¯”ç›®æ ‡å°ºå¯¸å¤§ï¼Œåˆ™ç¼©å°
        if h1 > target_size[0] or w1 > target_size[1]:
            scale_factor = min(target_size[0] / h1, target_size[1] / w1)
            new_h = int(h1 * scale_factor)
            new_w = int(w1 * scale_factor)
            gray1 = cv2.resize(cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY), (new_w, new_h))
        else:
            gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)

        if h2 > target_size[0] or w2 > target_size[1]:
            scale_factor = min(target_size[0] / h2, target_size[1] / w2)
            new_h = int(h2 * scale_factor)
            new_w = int(w2 * scale_factor)
            gray2 = cv2.resize(cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY), (new_w, new_h))
        else:
            gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)

        try:
            ssim_value, _ = ssim(gray1, gray2, full=True, data_range=255)

            elapsed = time.time() - start_time
            if elapsed > 0.01:  # åªè®°å½•è€—æ—¶è¾ƒé•¿çš„SSIMè®¡ç®—
                self.log(f"SSIMè®¡ç®—è€—æ—¶: {elapsed:.3f}ç§’ï¼Œç»“æœ: {ssim_value:.4f}")

            return ssim_value
        except:
            elapsed = time.time() - start_time
            self.log(f"SSIMè®¡ç®—å¤±è´¥ï¼Œè€—æ—¶: {elapsed:.3f}ç§’")
            return 0.0

    def check_frame_duplicate_enhanced(self, frame, frame_idx):
        """å¢å¼ºç‰ˆé‡å¤å¸§æ£€æµ‹ï¼Œæ£€æŸ¥æœ€è¿‘Nå¸§"""
        if not self.enable_dup_detect_var.get() or not self.frame_history:
            return False, None, None, None

        start_time = time.time()
        history_size = len(self.frame_history)

        current_hash = None
        current_thumbnail = None

        # è®¡ç®—å½“å‰å¸§çš„ä¿¡æ¯ï¼ˆæŒ‰éœ€è®¡ç®—ï¼‰
        hash_time = 0
        if self.use_hash_var.get():
            hash_start = time.time()
            current_hash = self.calculate_frame_hash(frame)
            hash_time = time.time() - hash_start

        ssim_thumbnail_time = 0
        if self.use_ssim_var.get():
            # ä¿å­˜ç¼©ç•¥å›¾ç”¨äºSSIMè®¡ç®—
            thumb_start = time.time()
            h, w = frame.shape[:2]
            if h > 180 or w > 320:
                new_h = 180
                new_w = int(w * (180 / h))
                current_thumbnail = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
            else:
                current_thumbnail = frame.copy()
            ssim_thumbnail_time = time.time() - thumb_start

        # è·å–é˜ˆå€¼
        hash_threshold = int(self.hash_threshold_var.get())
        ssim_threshold = float(self.ssim_threshold_var.get())

        # ä»æœ€è¿‘å¸§å¼€å§‹æ£€æŸ¥ï¼ˆæ—¶é—´ä¸Šè¶Šæ¥è¿‘è¶Šå¯èƒ½é‡å¤ï¼‰
        best_match_idx = -1
        best_match_reason = ""
        best_hash_diff = None
        best_ssim_value = None

        # éå†å†å²å¸§ï¼ˆä»æœ€è¿‘çš„å¼€å§‹ï¼‰
        compare_start = time.time()
        ssim_compare_time = 0
        hash_compare_time = 0

        for i, (hist_frame, hist_hash, hist_thumbnail, hist_sr_result, hist_frame_idx) in enumerate(
                zip(self.frame_history, self.frame_hash_history,
                    self.frame_thumbnail_history if self.use_ssim_var.get() else [None] * len(self.frame_history),
                    self.frame_sr_history,
                    self.frame_idx_history)):

            # è·³è¿‡æ— æ•ˆè®°å½•
            if hist_frame is None or hist_sr_result is None:
                continue

            # å¦‚æœä½¿ç”¨å“ˆå¸Œæ£€æµ‹
            if self.use_hash_var.get() and current_hash is not None and hist_hash is not None:
                hash_compare_start = time.time()
                hash_diff = current_hash - hist_hash
                hash_compare_time += time.time() - hash_compare_start

                if hash_diff <= hash_threshold:
                    # å¦‚æœåŒæ—¶å¯ç”¨äº†SSIMæ£€æµ‹ï¼Œéœ€è¦éªŒè¯SSIM
                    if self.use_ssim_var.get():
                        ssim_compare_start = time.time()
                        ssim_value = self.calculate_ssim_fast(frame, hist_frame)
                        ssim_compare_time += time.time() - ssim_compare_start

                        if ssim_value >= ssim_threshold:
                            best_match_idx = i
                            best_match_reason = f"å“ˆå¸Œ({hash_diff})å’ŒSSIM({ssim_value:.3f})åŒ¹é…"
                            best_hash_diff = hash_diff
                            best_ssim_value = ssim_value
                            break
                    else:
                        # åªä½¿ç”¨å“ˆå¸Œæ£€æµ‹
                        best_match_idx = i
                        best_match_reason = f"å“ˆå¸ŒåŒ¹é…(å·®å¼‚:{hash_diff})"
                        best_hash_diff = hash_diff
                        break
            # å¦‚æœåªä½¿ç”¨SSIMæ£€æµ‹
            elif self.use_ssim_var.get() and current_thumbnail is not None and hist_thumbnail is not None:
                ssim_compare_start = time.time()
                ssim_value = self.calculate_ssim_fast(frame, hist_frame)
                ssim_compare_time += time.time() - ssim_compare_start

                if ssim_value >= ssim_threshold:
                    best_match_idx = i
                    best_match_reason = f"SSIMåŒ¹é…({ssim_value:.3f})"
                    best_ssim_value = ssim_value
                    break

        compare_time = time.time() - compare_start

        if best_match_idx >= 0:
            # æ‰¾åˆ°åŒ¹é…çš„å¸§
            matched_sr_result = self.frame_sr_history[best_match_idx]
            matched_frame_idx = self.frame_idx_history[best_match_idx]

            # è¯¦ç»†è®¡æ—¶ä¿¡æ¯
            total_elapsed = time.time() - start_time
            timing_info = []
            if hash_time > 0:
                timing_info.append(f"å“ˆå¸Œè®¡ç®—: {hash_time:.3f}s")
            if ssim_thumbnail_time > 0:
                timing_info.append(f"ç¼©ç•¥å›¾: {ssim_thumbnail_time:.3f}s")
            if hash_compare_time > 0:
                timing_info.append(f"å“ˆå¸Œæ¯”è¾ƒ: {hash_compare_time:.3f}s")
            if ssim_compare_time > 0:
                timing_info.append(f"SSIMæ¯”è¾ƒ: {ssim_compare_time:.3f}s")

            timing_str = f" è®¡æ—¶: {total_elapsed:.3f}s ({', '.join(timing_info)})"

            # ç®€åŒ–æ—¥å¿—è¾“å‡º
            log_message = f"å¸§ {frame_idx:04d}: ä¸å¸§ {matched_frame_idx:04d} é‡å¤"
            if self.enable_history_var.get():
                log_message += f" (å†å²å¸§: {history_size})"
            log_message += timing_str

            self.log(log_message)

            self.dup_frame_count += 1
            self.update_dup_info(self.dup_frame_count)

            # æ›´æ–°å†å²å¸§ä¿¡æ¯ï¼ˆå°†åŒ¹é…å¸§ç§»åˆ°æœ€è¿‘ä½ç½®ï¼‰
            if best_match_idx > 0:  # å¦‚æœä¸æ˜¯å·²ç»åœ¨æœ€å‰é¢
                # é‡æ–°æ’åˆ—å†å²è®°å½•ï¼Œå°†åŒ¹é…å¸§ç§»åˆ°æœ€è¿‘ä½ç½®
                items_to_move = [
                    self.frame_history[best_match_idx],
                    self.frame_hash_history[best_match_idx],
                    self.frame_thumbnail_history[best_match_idx] if self.use_ssim_var.get() else None,
                    self.frame_sr_history[best_match_idx],
                    self.frame_idx_history[best_match_idx]
                ]

                # ç§»é™¤åŒ¹é…å¸§
                del self.frame_history[best_match_idx]
                del self.frame_hash_history[best_match_idx]
                if self.use_ssim_var.get():
                    del self.frame_thumbnail_history[best_match_idx]
                del self.frame_sr_history[best_match_idx]
                del self.frame_idx_history[best_match_idx]

                # æ’å…¥åˆ°æœ€å‰é¢ï¼ˆæœ€è¿‘ä½ç½®ï¼‰
                self.frame_history.appendleft(items_to_move[0])
                self.frame_hash_history.appendleft(items_to_move[1])
                if self.use_ssim_var.get():
                    self.frame_thumbnail_history.appendleft(items_to_move[2])
                self.frame_sr_history.appendleft(items_to_move[3])
                self.frame_idx_history.appendleft(items_to_move[4])

            return True, matched_sr_result.copy(), current_hash, current_thumbnail

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…å¸§ï¼Œä¹Ÿè¾“å‡ºæ—¥å¿—ï¼ˆä»…å½“å¯ç”¨è¯¦ç»†æ—¥å¿—æ—¶ï¼‰
        else:
            total_elapsed = time.time() - start_time
            if total_elapsed > 0.05:  # åªè®°å½•è€—æ—¶è¾ƒé•¿çš„æ£€æµ‹
                timing_info = []
                if hash_time > 0:
                    timing_info.append(f"å“ˆå¸Œè®¡ç®—: {hash_time:.3f}s")
                if ssim_thumbnail_time > 0:
                    timing_info.append(f"ç¼©ç•¥å›¾: {ssim_thumbnail_time:.3f}s")
                if compare_time > 0:
                    timing_info.append(f"æ¯”è¾ƒ: {compare_time:.3f}s")

                timing_str = f" è®¡æ—¶: {total_elapsed:.3f}s ({', '.join(timing_info)})"

                log_message = f"å¸§ {frame_idx:04d}: æœªé‡å¤"
                if self.enable_history_var.get():
                    log_message += f" (å†å²å¸§: {history_size})"
                log_message += timing_str

                self.log(log_message)

        return False, None, current_hash, current_thumbnail

    def add_frame_to_history(self, frame, frame_hash, frame_thumbnail, sr_result, frame_idx):
        """æ·»åŠ å¸§åˆ°å†å²è®°å½•"""
        start_time = time.time()

        # æ·»åŠ å¸§æ•°æ®
        self.frame_history.append(frame.copy())
        self.frame_hash_history.append(frame_hash)
        if self.use_ssim_var.get():
            self.frame_thumbnail_history.append(frame_thumbnail)

        self.frame_sr_history.append(sr_result.copy() if sr_result is not None else None)
        self.frame_idx_history.append(frame_idx)

        elapsed = time.time() - start_time
        if elapsed > 0.01:  # åªè®°å½•è€—æ—¶è¾ƒé•¿çš„æ·»åŠ æ“ä½œ
            self.log(f"æ·»åŠ åˆ°å†å²ç¼“å­˜è€—æ—¶: {elapsed:.3f}ç§’")

    # ============================================================
    # è§†é¢‘å¤„ç†å‡½æ•°
    # ============================================================

    def extract_audio(self, video_path, audio_path):
        """æå–éŸ³é¢‘"""
        start_time = time.time()

        cmd = [
            'ffmpeg', '-y',
            '-i', video_path,
            '-vn',
            '-acodec', 'copy',
            '-loglevel', 'quiet',
            audio_path
        ]

        try:
            subprocess.run(cmd, check=True, capture_output=True, text=True)

            elapsed = time.time() - start_time
            self.log(f"éŸ³é¢‘æå–è€—æ—¶: {elapsed:.2f}ç§’")
            return True
        except subprocess.CalledProcessError as e:
            self.log(f"æå–éŸ³é¢‘å¤±è´¥: {e.stderr}")
            return False

    def split_video_by_keyframes(self, video_path, segment_duration, output_dir):
        """æŒ‰å…³é”®å¸§åˆ†å‰²è§†é¢‘"""
        self.log(f"å¼€å§‹åˆ†å‰²è§†é¢‘: {os.path.basename(video_path)}")
        start_time = time.time()

        segments = []

        # åˆ›å»ºåˆ†æ®µç›®å½•
        segment_dir = os.path.join(output_dir, "01_original_segments")
        os.makedirs(segment_dir, exist_ok=True)

        # ä½¿ç”¨ffmpegåˆ†å‰²è§†é¢‘
        segment_pattern = os.path.join(segment_dir, "segment_%03d.mp4")

        cmd = [
            'ffmpeg', '-y',
            '-i', video_path,
            '-c', 'copy',
            '-map', '0',
            '-segment_time', str(segment_duration),
            '-f', 'segment',
            '-reset_timestamps', '1',
            '-segment_format', 'mp4',
            '-segment_list', os.path.join(segment_dir, "segments_list.txt"),
            segment_pattern
        ]

        try:
            subprocess.run(cmd, check=True, capture_output=True, text=True)

            # è·å–ç”Ÿæˆçš„åˆ†æ®µæ–‡ä»¶
            for f in sorted(os.listdir(segment_dir)):
                if f.startswith("segment_") and f.endswith(".mp4"):
                    segment_file = os.path.join(segment_dir, f)
                    segments.append(segment_file)

            elapsed = time.time() - start_time
            self.log(f"è§†é¢‘åˆ†å‰²å®Œæˆï¼Œå…±{len(segments)}æ®µï¼Œè€—æ—¶: {elapsed:.2f}ç§’")

        except subprocess.CalledProcessError as e:
            self.log(f"è§†é¢‘åˆ†å‰²å¤±è´¥: {e.stderr}")
            return []

        return segments

    def load_model(self):
        """åŠ è½½æ¨¡å‹ï¼ˆæµ‹è¯•æ¨¡å¼ä¸‹ä¸åŠ è½½ï¼‰"""
        if self.test_mode_var.get():
            self.log("æµ‹è¯•æ¨¡å¼ï¼šè·³è¿‡æ¨¡å‹åŠ è½½")
            return None

        model_name = self.model_var.get()
        scale = int(self.scale_var.get())

        # ç¡®å®šæƒé‡è·¯å¾„
        if model_name == "RRDB":
            weight_path = self.models[model_name]["weight"][str(scale)]
        else:
            weight_path = self.models[model_name]["weight"]

        # æ£€æŸ¥æƒé‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(weight_path):
            raise FileNotFoundError(f"æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {weight_path}")

        self.log(f"åŠ è½½æ¨¡å‹: {model_name}, ç¼©æ”¾: {scale}x")
        self.log(f"æƒé‡æ–‡ä»¶: {weight_path}")

        # è®¾ç½®æ•°æ®ç±»å‹
        if self.float16_var.get():
            torch.backends.cudnn.benchmark = True
            self.weight_dtype = torch.float16
            self.log("ä½¿ç”¨FP16æ¨ç†æ¨¡å¼ï¼ˆåŠ é€Ÿï¼‰")
        else:
            self.weight_dtype = torch.float32
            self.log("ä½¿ç”¨FP32æ¨ç†æ¨¡å¼ï¼ˆè´¨é‡ä¼˜å…ˆï¼‰")

        # åŠ è½½æ¨¡å‹
        if model_name == "GRL":
            generator = self.load_grl(weight_path, scale=scale)
        elif model_name == "DAT":
            generator = self.load_dat(weight_path, scale=scale)
        elif model_name == "RRDB":
            generator = self.load_rrdb(weight_path, scale=scale)
        elif model_name == "CUNET":
            generator = self.load_cunet(weight_path, scale=scale)
        else:
            raise ValueError(f"æœªçŸ¥æ¨¡å‹: {model_name}")

        generator = generator.to(dtype=self.weight_dtype)
        generator.eval()

        # ç§»åŠ¨åˆ°GPU
        if torch.cuda.is_available():
            generator = generator.cuda()

        return generator

    def process_single_frame(self, frame):
        """å¤„ç†å•å¸§å›¾åƒ"""
        start_time = time.time()

        if self.test_mode_var.get():
            # æµ‹è¯•æ¨¡å¼ä¸å¤„ç†ï¼Œç›´æ¥è¿”å›RGBæ ¼å¼
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            elapsed = time.time() - start_time
            if elapsed > 0.05:
                self.log(f"æµ‹è¯•æ¨¡å¼å¸§å¤„ç†è€—æ—¶: {elapsed:.3f}ç§’")
            return frame_rgb

        from torchvision.transforms import ToTensor

        preprocess_start = time.time()

        # é¢„å¤„ç†
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # ä¸‹é‡‡æ ·ï¼ˆå¦‚æœéœ€è¦ï¼‰
        scale = int(self.scale_var.get())
        downsample_threshold = int(self.downsample_threshold.get())

        h, w, _ = frame_rgb.shape
        short_side = min(h, w)

        original_h, original_w = h, w

        if downsample_threshold != -1 and short_side > downsample_threshold:
            rescale_factor = short_side / downsample_threshold
            new_w = int(w / rescale_factor)
            new_h = int(h / rescale_factor)
            frame_rgb = cv2.resize(frame_rgb, (new_w, new_h), interpolation=cv2.INTER_LINEAR)

        # è£å‰ªï¼ˆå¦‚æœéœ€è¦ï¼‰
        if self.crop_for_4x_var.get() and scale == 4:
            h, w, _ = frame_rgb.shape
            if h % 4 != 0:
                frame_rgb = frame_rgb[:4 * (h // 4), :, :]
            if w % 4 != 0:
                frame_rgb = frame_rgb[:, :4 * (w // 4), :]

        preprocess_time = time.time() - preprocess_start

        # è½¬æ¢ä¸ºtensorå¹¶è¿›è¡Œæ¨ç†
        tensor_start = time.time()
        img_tensor = ToTensor()(frame_rgb).unsqueeze(0)

        if torch.cuda.is_available():
            img_tensor = img_tensor.cuda()

        img_tensor = img_tensor.to(dtype=self.weight_dtype)
        tensor_time = time.time() - tensor_start

        # æ¨ç†
        inference_start = time.time()
        with torch.no_grad():
            result = self.generator(img_tensor)
        inference_time = time.time() - inference_start

        # åå¤„ç†
        postprocess_start = time.time()
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        result_np = result[0].cpu().detach().numpy()
        result_np = np.transpose(result_np, (1, 2, 0))
        result_np = np.clip(result_np * 255.0, 0, 255).astype(np.uint8)

        # å¦‚æœéœ€è¦ï¼Œç¼©æ”¾å›åŸå§‹å¤§å°
        if downsample_threshold != -1 and short_side > downsample_threshold:
            output_h = int(original_h * scale)
            output_w = int(original_w * scale)
            result_np = cv2.resize(result_np, (output_w, output_h), interpolation=cv2.INTER_LINEAR)

        postprocess_time = time.time() - postprocess_start

        total_elapsed = time.time() - start_time

        # è®°å½•è€—æ—¶ä¿¡æ¯ï¼ˆåªè®°å½•è€—æ—¶è¾ƒé•¿çš„å¸§ï¼‰
        if total_elapsed > 0.2:  # åªè®°å½•è¶…è¿‡200msçš„å¸§å¤„ç†
            self.log(f"å¸§å¤„ç†è€—æ—¶: {total_elapsed:.3f}ç§’ (é¢„å¤„ç†: {preprocess_time:.3f}s, "
                     f"å¼ é‡åŒ–: {tensor_time:.3f}s, æ¨ç†: {inference_time:.3f}s, "
                     f"åå¤„ç†: {postprocess_time:.3f}s)")

        return result_np

    def process_frame_with_enhanced_dup_detect(self, frame, frame_idx):
        """å¤„ç†å•å¸§ï¼ŒåŒ…å«å¢å¼ºçš„é‡å¤å¸§æ£€æµ‹"""
        start_time = time.time()
        is_duplicate = False

        # æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤å¸§
        dup_detect_start = time.time()
        is_duplicate, matched_sr_result, current_hash, current_thumbnail = \
            self.check_frame_duplicate_enhanced(frame, frame_idx)
        dup_detect_time = time.time() - dup_detect_start

        if is_duplicate and matched_sr_result is not None:
            # æ‰¾åˆ°é‡å¤å¸§ï¼Œç›´æ¥ä½¿ç”¨å†å²è¶…åˆ†è¾¨ç‡ç»“æœ
            result_np = matched_sr_result

            # æ›´æ–°å†å²è®°å½•ï¼ˆä½¿ç”¨åŒ¹é…çš„å¸§ä¿¡æ¯ï¼‰
            if current_hash is None and self.use_hash_var.get():
                current_hash = self.calculate_frame_hash(frame)
            if current_thumbnail is None and self.use_ssim_var.get():
                h, w = frame.shape[:2]
                if h > 180 or w > 320:
                    new_h = 180
                    new_w = int(w * (180 / h))
                    current_thumbnail = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
                else:
                    current_thumbnail = frame.copy()

            self.add_frame_to_history(frame, current_hash, current_thumbnail, result_np, frame_idx)

            total_elapsed = time.time() - start_time
            # è®°å½•é‡å¤å¸§çš„å¤„ç†æ€»è€—æ—¶
            if total_elapsed > 0.1:
                self.log(f"é‡å¤å¸§å¤„ç†æ€»è€—æ—¶: {total_elapsed:.3f}ç§’ (æ£€æµ‹: {dup_detect_time:.3f}s)")

            return result_np, current_hash, current_thumbnail, is_duplicate

        # éé‡å¤å¸§ï¼Œè¿›è¡Œè¶…åˆ†è¾¨ç‡å¤„ç†
        sr_start = time.time()
        result_np = self.process_single_frame(frame)
        sr_time = time.time() - sr_start

        # è®¡ç®—å½“å‰å¸§çš„ä¿¡æ¯
        info_start = time.time()
        if self.use_hash_var.get() and current_hash is None:
            current_hash = self.calculate_frame_hash(frame)
        if self.use_ssim_var.get() and current_thumbnail is None:
            h, w = frame.shape[:2]
            if h > 180 or w > 320:
                new_h = 180
                new_w = int(w * (180 / h))
                current_thumbnail = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
            else:
                current_thumbnail = frame.copy()
        info_time = time.time() - info_start

        # æ›´æ–°å†å²è®°å½•
        history_start = time.time()
        self.add_frame_to_history(frame, current_hash, current_thumbnail, result_np, frame_idx)
        history_time = time.time() - history_start

        total_elapsed = time.time() - start_time

        # è®°å½•éé‡å¤å¸§çš„å¤„ç†æ€»è€—æ—¶ï¼ˆåªè®°å½•è€—æ—¶è¾ƒé•¿çš„å¸§ï¼‰
        if total_elapsed > 0.3:  # åªè®°å½•è¶…è¿‡300msçš„å¸§å¤„ç†
            self.log(f"æ–°å¸§å¤„ç†æ€»è€—æ—¶: {total_elapsed:.3f}ç§’ (æ£€æµ‹: {dup_detect_time:.3f}s, "
                     f"è¶…åˆ†: {sr_time:.3f}s, ä¿¡æ¯è®¡ç®—: {info_time:.3f}s, "
                     f"å†å²æ›´æ–°: {history_time:.3f}s)")

        return result_np, current_hash, current_thumbnail, is_duplicate

    def apply_new_settings(self):
        """åº”ç”¨æ–°çš„è®¾ç½®åˆ°å½“å‰å¤„ç†ä¸­"""
        self.log("æ­£åœ¨åº”ç”¨æ–°çš„è®¾ç½®...")

        # é‡æ–°åˆå§‹åŒ–å†å²å¸§ç¼“å­˜
        self.init_history_cache()

        # è®°å½•å½“å‰è®¾ç½®
        if self.enable_dup_detect_var.get():
            methods = []
            if self.use_hash_var.get():
                methods.append(f"å“ˆå¸Œ(é˜ˆå€¼:{self.hash_threshold_var.get()})")
            if self.use_ssim_var.get():
                methods.append(f"SSIM(é˜ˆå€¼:{self.ssim_threshold_var.get()})")

            if self.enable_history_var.get():
                history_size = int(self.history_size_var.get())
                self.log(f"é‡å¤å¸§æ£€æµ‹: {', '.join(methods)}ï¼Œå†å²å¸§: {history_size}")
            else:
                self.log(f"é‡å¤å¸§æ£€æµ‹: {', '.join(methods)}ï¼Œä»…ä¸å‰å¸§æ¯”è¾ƒ")
        else:
            self.log("é‡å¤å¸§æ£€æµ‹å·²ç¦ç”¨")

        # è®°å½•ç«‹å³åˆæˆè®¾ç½®
        if self.immediate_merge_var.get():
            self.log("ç«‹å³åˆæˆè§†é¢‘åŠŸèƒ½å·²å¯ç”¨")
        else:
            self.log("ç«‹å³åˆæˆè§†é¢‘åŠŸèƒ½å·²ç¦ç”¨")

        return True

    def process_segment_frames(self, segment_path, segment_index):
        """å¤„ç†è§†é¢‘ç‰‡æ®µçš„æ‰€æœ‰å¸§ï¼ˆé€å¸§å¤„ç†ï¼‰"""
        segment_name = os.path.basename(segment_path)
        self.log(f"å¤„ç†ç‰‡æ®µ {segment_index}: {segment_name}")
        segment_start_time = time.time()

        if self.test_mode_var.get():
            self.log("æµ‹è¯•æ¨¡å¼ï¼šä»…è¿›è¡Œé‡å¤å¸§æ£€æµ‹ï¼Œä¸è¿›è¡Œè¶…åˆ†è¾¨ç‡å¤„ç†")

        # åˆå§‹åŒ–å†å²å¸§ç¼“å­˜
        self.init_history_cache()

        # æ›´æ–°é‡å¤å¸§è®¡æ•°ï¼ˆå·²é‡ç½®ä¸º0ï¼‰
        self.update_dup_info(self.dup_frame_count)

        # ä¸ºå½“å‰ç‰‡æ®µåˆ›å»ºå¸§ç›®å½•ï¼ˆç›´æ¥åˆ›å»ºåœ¨03_segment_framesä¸‹ï¼‰
        before_dir, after_dir = self.setup_segment_frame_dirs(segment_index)

        if not before_dir or not after_dir:
            self.log("é”™è¯¯ï¼šæ— æ³•åˆ›å»ºå¸§ç›®å½•")
            return None, None

        # æå–éŸ³é¢‘
        audio_name = segment_name.replace('.mp4', '.aac')
        audio_path = os.path.join(self.temp_base_dir, "02_audio", audio_name)
        has_audio = self.extract_audio(segment_path, audio_path)

        if has_audio:
            self.log("éŸ³é¢‘æå–æˆåŠŸ")
        else:
            self.log("è§†é¢‘æ— éŸ³é¢‘æˆ–éŸ³é¢‘æå–å¤±è´¥")

        # è¯»å–è§†é¢‘
        cap = cv2.VideoCapture(segment_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        if total_frames == 0:
            self.log(f"è­¦å‘Š: æ— æ³•è·å–ç‰‡æ®µ {segment_path} çš„å¸§æ•°")
            cap.release()
            return None, None

        # è®¡ç®—è¾“å‡ºå°ºå¯¸
        scale = int(self.scale_var.get())
        downsample_threshold = int(self.downsample_threshold.get())

        short_side = min(height, width)
        if downsample_threshold != -1 and short_side > downsample_threshold:
            rescale_factor = short_side / downsample_threshold
        else:
            rescale_factor = 1

        # è¾“å‡ºå°ºå¯¸
        output_width = int(width * scale / rescale_factor)
        output_height = int(height * scale / rescale_factor)

        self.log(f"è¾“å…¥å°ºå¯¸: {width}x{height}, è¾“å‡ºå°ºå¯¸: {output_width}x{output_height}")

        # æ˜¾ç¤ºæ£€æµ‹å‚æ•°
        if self.enable_dup_detect_var.get():
            methods = []
            if self.use_hash_var.get():
                methods.append(f"å“ˆå¸Œ(é˜ˆå€¼:{self.hash_threshold_var.get()})")
            if self.use_ssim_var.get():
                methods.append(f"SSIM(é˜ˆå€¼:{self.ssim_threshold_var.get()})")

            if self.enable_history_var.get():
                history_size = int(self.history_size_var.get())
                self.log(f"é‡å¤å¸§æ£€æµ‹: {', '.join(methods)}ï¼Œå†å²å¸§: {history_size}")
            else:
                self.log(f"é‡å¤å¸§æ£€æµ‹: {', '.join(methods)}ï¼Œä»…ä¸å‰å¸§æ¯”è¾ƒ")

        # å¦‚æœä»è¿›åº¦æ¢å¤ï¼Œè·³è¿‡å·²å¤„ç†çš„å¸§
        start_frame = self.current_frame_in_segment
        if start_frame > 0:
            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
            self.log(f"ä»ç¬¬ {start_frame + 1} å¸§æ¢å¤å¤„ç†")

        frame_idx = start_frame
        frame_files = []

        # åˆ›å»ºé‡å¤å¸§è®°å½•æ–‡ä»¶
        dup_record_path = os.path.join(self.temp_base_dir, "05_logs", f"segment_{segment_index:03d}_duplicates.txt")
        with open(dup_record_path, 'w', encoding='utf-8') as dup_file:
            dup_file.write(f"ç‰‡æ®µ {segment_index} é‡å¤å¸§è®°å½•\n")
            dup_file.write(f"å“ˆå¸Œé˜ˆå€¼: {self.hash_threshold_var.get()}\n")
            dup_file.write(f"SSIMé˜ˆå€¼: {self.ssim_threshold_var.get()}\n")
            dup_file.write(f"å“ˆå¸Œæ£€æµ‹: {'å¯ç”¨' if self.use_hash_var.get() else 'ç¦ç”¨'}\n")
            dup_file.write(f"SSIMæ£€æµ‹: {'å¯ç”¨' if self.use_ssim_var.get() else 'ç¦ç”¨'}\n")
            dup_file.write(f"å†å²å¸§åŠŸèƒ½: {'å¯ç”¨' if self.enable_history_var.get() else 'ç¦ç”¨'}\n")
            if self.enable_history_var.get():
                history_size = int(self.history_size_var.get())
                dup_file.write(f"å†å²å¸§æ•°é‡: {history_size}\n")
            dup_file.write("=" * 50 + "\n")
            dup_file.write("å¸§å·\tæ˜¯å¦é‡å¤\tåŒ¹é…å¸§å·\tåŒ¹é…åŸå› \n")

        # åˆå§‹åŒ–å¸§è®¡æ•°å™¨
        frames_processed = 0
        segment_dup_count = 0  # å½“å‰ç‰‡æ®µçš„é‡å¤å¸§æ•°

        # ç»Ÿè®¡è®¡æ—¶
        total_frame_time = 0
        total_save_time = 0
        total_dup_detect_time = 0

        while True:
            # æ£€æŸ¥æ˜¯å¦è¢«åœæ­¢
            if self.stopped:
                self.log(f"åœæ­¢å¤„ç†ï¼šç‰‡æ®µ {segment_index} çš„ç¬¬ {frame_idx + 1} å¸§")
                break

            # æ£€æŸ¥æ˜¯å¦æš‚åœ - ä½¿ç”¨é«˜æ•ˆç­‰å¾…
            if self.paused:
                self.log(f"å¤„ç†æš‚åœäºç‰‡æ®µ {segment_index} çš„ç¬¬ {frame_idx + 1} å¸§")
                self.save_progress(force=True)  # æš‚åœæ—¶ç«‹å³ä¿å­˜è¿›åº¦

                # é‡Šæ”¾GPUå†…å­˜ä»¥é™ä½å ç”¨
                if not self.test_mode_var.get():
                    torch.cuda.empty_cache()

                # é«˜æ•ˆç­‰å¾…ï¼Œè€Œä¸æ˜¯å¿™ç­‰å¾…
                while self.paused and not self.stopped:
                    time.sleep(1.0)  # ä½¿ç”¨è¾ƒé•¿çš„ä¼‘çœ æ—¶é—´å‡å°‘CPUå ç”¨
                    if self.paused:  # å†æ¬¡æ£€æŸ¥ï¼Œé¿å…é”™è¿‡çŠ¶æ€å˜åŒ–
                        # åœ¨ç­‰å¾…æœŸé—´å®šæœŸé‡Šæ”¾GPUå†…å­˜
                        if frame_idx % 10 == 0 and not self.test_mode_var.get():
                            torch.cuda.empty_cache()

                if self.stopped:
                    break

                # æ¢å¤æ—¶åº”ç”¨æœ€æ–°çš„è®¾ç½®
                self.log("æš‚åœåç»§ç»­ï¼Œæ­£åœ¨æ£€æŸ¥å¹¶åº”ç”¨æ–°è®¾ç½®...")
                self.apply_new_settings()

                # æ¢å¤æ—¶é‡æ–°åŠ è½½æ¨¡å‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if not self.test_mode_var.get() and self.generator is None:
                    try:
                        self.generator = self.load_model()
                    except Exception as e:
                        self.log(f"æ¢å¤æ—¶é‡æ–°åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
                        break

                self.log(f"å¤„ç†ç»§ç»­äºç‰‡æ®µ {segment_index} çš„ç¬¬ {frame_idx + 1} å¸§")

            # è¯»å–å¸§
            ret, frame = cap.read()
            if not ret:
                break

            # ä¿å­˜åŸå§‹å¸§åˆ°beforeç›®å½•
            save_start = time.time()
            before_path = os.path.join(before_dir, f"frame_{frame_idx:06d}.png")
            cv2.imwrite(before_path, frame)
            save_time = time.time() - save_start
            total_save_time += save_time

            # ä½¿ç”¨å¢å¼ºçš„é‡å¤å¸§æ£€æµ‹å¤„ç†å¸§
            process_start = time.time()
            sr_frame, current_hash, current_thumbnail, is_duplicate = \
                self.process_frame_with_enhanced_dup_detect(frame, frame_idx)
            frame_process_time = time.time() - process_start
            total_frame_time += frame_process_time

            if is_duplicate:
                total_dup_detect_time += frame_process_time

            # ä¿å­˜å¤„ç†åçš„å¸§åˆ°afterç›®å½•
            after_save_start = time.time()
            after_path = os.path.join(after_dir, f"frame_{frame_idx:06d}.png")
            sr_frame_bgr = cv2.cvtColor(sr_frame, cv2.COLOR_RGB2BGR)
            cv2.imwrite(after_path, sr_frame_bgr)
            after_save_time = time.time() - after_save_start
            total_save_time += after_save_time

            # æ·»åŠ åˆ°å¸§æ–‡ä»¶åˆ—è¡¨
            if not self.test_mode_var.get():
                frame_files.append(after_path)

            # è®°å½•é‡å¤å¸§ä¿¡æ¯
            with open(dup_record_path, 'a', encoding='utf-8') as dup_file:
                if is_duplicate:
                    matched_idx = self.frame_idx_history[0] if self.frame_idx_history else "æœªçŸ¥"
                    dup_file.write(f"{frame_idx}\tæ˜¯\t{matched_idx}\té‡å¤å¸§ï¼Œä½¿ç”¨å†å²ç»“æœ\n")
                    segment_dup_count += 1
                else:
                    dup_file.write(f"{frame_idx}\tå¦\t-\tæ­£å¸¸å¤„ç†\n")

            # æ›´æ–°å½“å‰å¸§
            self.current_frame_in_segment = frame_idx + 1
            frames_processed += 1

            # æ›´æ–°è¯¦ç»†è¿›åº¦
            self.update_detailed_progress(self.current_frame_in_segment, total_frames)

            # æ¯å¤„ç†10å¸§ä¿å­˜ä¸€æ¬¡è¿›åº¦
            if frames_processed % 10 == 0:
                self.save_progress(force=True)

            # æ›´æ–°è¿›åº¦æ¡
            progress = (self.current_frame_in_segment / total_frames) * 100
            self.update_progress(progress)

            frame_idx += 1

            # æ¯å¤„ç†50å¸§æ¸…ç†ä¸€æ¬¡GPUå†…å­˜
            if frame_idx % 50 == 0 and not self.test_mode_var.get():
                torch.cuda.empty_cache()

        cap.release()

        # è®°å½•ç‰‡æ®µå¤„ç†ç»Ÿè®¡
        segment_elapsed = time.time() - segment_start_time
        avg_frame_time = total_frame_time / max(frames_processed, 1)
        avg_save_time = total_save_time / max(frames_processed, 1)

        self.log(f"ç‰‡æ®µå¤„ç†å®Œæˆ: {segment_name}ï¼Œæ€»è€—æ—¶: {segment_elapsed:.2f}ç§’")
        self.log(f"  å¤„ç†å¸§æ•°: {frames_processed}ï¼Œå¹³å‡æ¯å¸§è€—æ—¶: {avg_frame_time:.3f}ç§’")
        self.log(f"  æ–‡ä»¶ä¿å­˜å¹³å‡è€—æ—¶: {avg_save_time:.3f}ç§’")

        if self.enable_dup_detect_var.get():
            self.log(f"  æ£€æµ‹åˆ°é‡å¤å¸§: {segment_dup_count}ä¸ªï¼Œé‡å¤æ£€æµ‹æ€»è€—æ—¶: {total_dup_detect_time:.2f}ç§’")
            if segment_dup_count > 0:
                avg_dup_time = total_dup_detect_time / segment_dup_count
                self.log(f"  å¹³å‡æ¯ä¸ªé‡å¤å¸§æ£€æµ‹è€—æ—¶: {avg_dup_time:.3f}ç§’")

        # æ¸…ç©ºå†å²ç¼“å­˜ä»¥é‡Šæ”¾å†…å­˜
        self.frame_history.clear()
        self.frame_hash_history.clear()
        if hasattr(self, 'frame_thumbnail_history'):
            self.frame_thumbnail_history.clear()
        self.frame_sr_history.clear()
        self.frame_idx_history.clear()

        return frame_files, audio_path

    def frames_to_video(self, frame_files, output_path, fps, width, height, audio_path=None):
        """å°†å¸§åºåˆ—è½¬æ¢ä¸ºè§†é¢‘"""
        self.log(f"æ­£åœ¨ç”Ÿæˆè§†é¢‘: {output_path}")
        start_time = time.time()

        if not frame_files:
            self.log("é”™è¯¯: æ²¡æœ‰å¯ç”¨çš„å¸§æ–‡ä»¶")
            return False

        # åˆ›å»ºä¸´æ—¶è§†é¢‘æ–‡ä»¶ï¼ˆæ— éŸ³é¢‘ï¼‰
        temp_video_path = output_path.replace('.mp4', '_temp.mp4')

        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(temp_video_path, fourcc, fps, (width, height))

        # æŒ‰é¡ºåºå†™å…¥æ‰€æœ‰å¸§
        write_start = time.time()
        for frame_file in sorted(frame_files):
            if os.path.exists(frame_file):
                frame = cv2.imread(frame_file)
                if frame is not None:
                    # è°ƒæ•´å¸§å¤§å°ä»¥åŒ¹é…è¾“å‡ºå°ºå¯¸
                    if frame.shape[1] != width or frame.shape[0] != height:
                        frame = cv2.resize(frame, (width, height))
                    out.write(frame)
        write_time = time.time() - write_start
        out.release()

        # å¦‚æœæœ‰éŸ³é¢‘ï¼Œåˆå¹¶éŸ³é¢‘å’Œè§†é¢‘
        if audio_path and os.path.exists(audio_path):
            self.log("åˆå¹¶éŸ³é¢‘å’Œè§†é¢‘...")
            merge_start = time.time()

            # ä½¿ç”¨ffmpegåˆå¹¶
            cmd = [
                'ffmpeg', '-y',
                '-i', temp_video_path,
                '-i', audio_path,
                '-c:v', 'copy',
                '-c:a', 'aac',
                '-map', '0:v:0',
                '-map', '1:a:0',
                '-shortest',
                output_path
            ]

            try:
                subprocess.run(cmd, check=True, capture_output=True, text=True)
                merge_time = time.time() - merge_start

                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_video_path):
                    os.remove(temp_video_path)

                total_time = time.time() - start_time
                self.log(
                    f"éŸ³é¢‘è§†é¢‘åˆå¹¶æˆåŠŸï¼Œè€—æ—¶: {total_time:.2f}ç§’ (å†™å…¥: {write_time:.2f}s, åˆå¹¶: {merge_time:.2f}s)")
                return True
            except subprocess.CalledProcessError as e:
                self.log(f"éŸ³é¢‘è§†é¢‘åˆå¹¶å¤±è´¥: {e.stderr}")
                # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œä½¿ç”¨ä¸´æ—¶è§†é¢‘æ–‡ä»¶ä½œä¸ºè¾“å‡º
                if os.path.exists(temp_video_path):
                    shutil.move(temp_video_path, output_path)
                return True
        else:
            # å¦‚æœæ²¡æœ‰éŸ³é¢‘ï¼Œç›´æ¥ä½¿ç”¨ä¸´æ—¶è§†é¢‘æ–‡ä»¶
            if os.path.exists(temp_video_path):
                shutil.move(temp_video_path, output_path)
                total_time = time.time() - start_time
                self.log(f"è§†é¢‘ç”ŸæˆæˆåŠŸï¼Œè€—æ—¶: {total_time:.2f}ç§’ (å†™å…¥: {write_time:.2f}s)")
                return True

        return False

    def concatenate_videos(self, video_list, output_path):
        """æ‹¼æ¥è§†é¢‘ç‰‡æ®µ"""
        self.log("å¼€å§‹æ‹¼æ¥è§†é¢‘ç‰‡æ®µ...")
        start_time = time.time()

        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶åˆ—è¡¨
        list_file = tempfile.mktemp(suffix=".txt")

        with open(list_file, 'w', encoding='utf-8') as f:
            for video in video_list:
                f.write(f"file '{os.path.abspath(video)}'\n")

        # ä½¿ç”¨ffmpegæ‹¼æ¥
        cmd = [
            'ffmpeg', '-y',
            '-f', 'concat',
            '-safe', '0',
            '-i', list_file,
            '-c', 'copy',
            output_path
        ]

        try:
            subprocess.run(cmd, check=True, capture_output=True, text=True)

            elapsed = time.time() - start_time
            self.log(f"è§†é¢‘æ‹¼æ¥å®Œæˆ: {output_path}ï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
            return True
        except subprocess.CalledProcessError as e:
            self.log(f"è§†é¢‘æ‹¼æ¥å¤±è´¥: {e.stderr}")
            raise
        finally:
            if os.path.exists(list_file):
                os.remove(list_file)

    def immediate_merge_segment(self, processed_segment_path, segment_index):
        """ç«‹å³åˆå¹¶å½“å‰å¤„ç†å¥½çš„ç‰‡æ®µåˆ°æ•´ä½“è§†é¢‘ä¸­"""
        if not self.immediate_merge_var.get() or self.test_mode_var.get():
            return None

        start_time = time.time()

        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰åˆå¹¶çš„è§†é¢‘
        merge_dir = os.path.join(self.temp_base_dir, "06_immediate_merge")
        merged_video_path = os.path.join(merge_dir, f"merged_up_to_{segment_index:03d}.mp4")

        # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªç‰‡æ®µï¼Œç›´æ¥å¤åˆ¶
        if segment_index == 0 or not os.path.exists(
                merged_video_path.replace(f"_{segment_index:03d}.mp4", f"_{segment_index - 1:03d}.mp4")):
            shutil.copy2(processed_segment_path, merged_video_path)
            elapsed = time.time() - start_time
            self.log(f"ç«‹å³åˆæˆ: åˆ›å»ºåˆå§‹åˆå¹¶è§†é¢‘ {segment_index:03d}ï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
            return merged_video_path

        # è·å–ä¸Šä¸€ä¸ªåˆå¹¶çš„è§†é¢‘
        prev_merged_video = os.path.join(merge_dir, f"merged_up_to_{segment_index - 1:03d}.mp4")

        if not os.path.exists(prev_merged_video):
            self.log(f"ç«‹å³åˆæˆ: æ‰¾ä¸åˆ°ä¸Šä¸€ä¸ªåˆå¹¶è§†é¢‘ï¼Œè·³è¿‡")
            return None

        # åˆå¹¶å½“å‰ç‰‡æ®µåˆ°ä¸Šä¸€ä¸ªåˆå¹¶è§†é¢‘
        try:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶åˆ—è¡¨
            list_file = tempfile.mktemp(suffix=".txt")

            with open(list_file, 'w', encoding='utf-8') as f:
                f.write(f"file '{os.path.abspath(prev_merged_video)}'\n")
                f.write(f"file '{os.path.abspath(processed_segment_path)}'\n")

            # ä½¿ç”¨ffmpegåˆå¹¶
            cmd = [
                'ffmpeg', '-y',
                '-f', 'concat',
                '-safe', '0',
                '-i', list_file,
                '-c', 'copy',
                merged_video_path
            ]

            subprocess.run(cmd, check=True, capture_output=True, text=True)

            elapsed = time.time() - start_time
            self.log(f"ç«‹å³åˆæˆ: æˆåŠŸåˆå¹¶ç‰‡æ®µ {segment_index} åˆ°æ•´ä½“è§†é¢‘ï¼Œè€—æ—¶: {elapsed:.2f}ç§’")

            # åˆ é™¤ä¸Šä¸€ä¸ªåˆå¹¶è§†é¢‘ä»¥èŠ‚çœç©ºé—´
            if os.path.exists(prev_merged_video):
                os.remove(prev_merged_video)

            return merged_video_path

        except Exception as e:
            self.log(f"ç«‹å³åˆæˆå¤±è´¥: {e}")
            return None
        finally:
            if os.path.exists(list_file):
                os.remove(list_file)

    def process_single_video(self, video_path):
        """å¤„ç†å•ä¸ªè§†é¢‘"""
        try:
            self.log(
                f"å¼€å§‹å¤„ç†è§†é¢‘ {self.current_video_index + 1}/{len(self.input_paths)}: {os.path.basename(video_path)}")
            video_start_time = time.time()

            # è®¾ç½®è§†é¢‘åŸºç¡€åç§°
            self.video_base_name = Path(video_path).stem

            # è®¾ç½®ä¸´æ—¶ç›®å½•ï¼ˆåŸºäºè§†é¢‘æ–‡ä»¶åå’Œæµ‹è¯•æ¨¡å¼ï¼‰
            temp_dirs = self.setup_temp_dirs(video_path)
            if not temp_dirs:
                raise ValueError("æ— æ³•åˆ›å»ºä¸´æ—¶ç›®å½•")

            self.log(f"ä¸´æ—¶æ–‡ä»¶ç›®å½•: {temp_dirs['base']}")
            if self.is_test_mode_folder:
                self.log("æ³¨æ„ï¼šå½“å‰ä¸ºæµ‹è¯•æ¨¡å¼æ–‡ä»¶å¤¹")

            if self.test_mode_var.get():
                self.log("æµ‹è¯•æ¨¡å¼ï¼šä»…è¿›è¡Œé‡å¤å¸§æ£€æµ‹ï¼Œä¸è¿›è¡Œè¶…åˆ†è¾¨ç‡å¤„ç†")

            # é‡ç½®é‡å¤å¸§è®¡æ•°ï¼ˆæ¯ä¸ªè§†é¢‘å¼€å§‹æ—¶é‡ç½®ï¼‰
            self.dup_frame_count = 0
            self.update_dup_info(self.dup_frame_count)

            # æ£€æŸ¥æ˜¯å¦æœ‰è¯¥è§†é¢‘çš„è¿›åº¦æ•°æ®
            progress_file = os.path.join(self.temp_base_dir, "progress_data.pkl")

            if os.path.exists(progress_file):
                try:
                    with open(progress_file, 'rb') as f:
                        progress_data = pickle.load(f)

                    # æ£€æŸ¥æ˜¯å¦æ˜¯ä»æµ‹è¯•æ¨¡å¼æ¢å¤çš„è¿›åº¦
                    saved_test_mode = progress_data.get('is_test_mode_folder', False)
                    if saved_test_mode != self.is_test_mode_folder:
                        self.log(
                            f"è­¦å‘Šï¼šè¿›åº¦æ–‡ä»¶çš„æµ‹è¯•æ¨¡å¼çŠ¶æ€({saved_test_mode})ä¸å½“å‰è®¾ç½®({self.is_test_mode_folder})ä¸åŒ¹é…")
                        if self.is_test_mode_folder:
                            self.log("å½“å‰ä¸ºæµ‹è¯•æ¨¡å¼ï¼Œå°†å¿½ç•¥æµ‹è¯•æ¨¡å¼çš„è¿›åº¦æ–‡ä»¶")
                            # åˆ é™¤æµ‹è¯•æ¨¡å¼çš„è¿›åº¦æ–‡ä»¶
                            os.remove(progress_file)
                            self.log("å·²åˆ é™¤æµ‹è¯•æ¨¡å¼è¿›åº¦æ–‡ä»¶")
                        else:
                            # æ­£å¸¸æ¨¡å¼ä¸‹å‘ç°æµ‹è¯•æ¨¡å¼è¿›åº¦æ–‡ä»¶
                            response = messagebox.askyesno("å‘ç°æµ‹è¯•æ¨¡å¼è¿›åº¦",
                                                           "å‘ç°æµ‹è¯•æ¨¡å¼çš„è¿›åº¦æ–‡ä»¶ï¼Œæ˜¯å¦åˆ é™¤å¹¶é‡æ–°å¼€å§‹ï¼Ÿ")
                            if response:
                                os.remove(progress_file)
                                self.log("å·²åˆ é™¤æµ‹è¯•æ¨¡å¼è¿›åº¦æ–‡ä»¶ï¼Œé‡æ–°å¼€å§‹å¤„ç†")
                            else:
                                self.log("ä½¿ç”¨æµ‹è¯•æ¨¡å¼è¿›åº¦ç»§ç»­å¤„ç†")

                    # æ¢å¤è¿›åº¦
                    self.current_segment_index = progress_data.get('current_segment_index', 0)
                    self.current_frame_in_segment = progress_data.get('current_frame_in_segment', 0)
                    self.total_segments = progress_data.get('total_segments', 0)
                    self.segments = progress_data.get('segments', [])
                    self.processed_segments = progress_data.get('processed_segments', [])
                    # æ³¨æ„ï¼šä¸æ¢å¤dup_frame_countï¼Œå·²é‡ç½®ä¸º0

                    self.log(
                        f"æ¢å¤è¿›åº¦: ç‰‡æ®µ {self.current_segment_index + 1}/{self.total_segments} çš„ç¬¬ {self.current_frame_in_segment + 1} å¸§")
                    self.log(f"é‡å¤å¸§è®¡æ•°å·²é‡ç½®")
                except Exception as e:
                    self.log(f"åŠ è½½è¿›åº¦æ•°æ®æ—¶å‡ºé”™: {e}")
                    self.current_segment_index = 0
                    self.current_frame_in_segment = 0
                    self.processed_segments = []
                    self.dup_frame_count = 0

            # æ­¥éª¤1: åŠ è½½æ¨¡å‹
            if not self.test_mode_var.get():
                self.log("æ­¥éª¤1: åŠ è½½æ¨¡å‹...")
                self.update_progress(0)
                model_load_start = time.time()
                self.generator = self.load_model()
                model_load_time = time.time() - model_load_start
                self.log(f"æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {model_load_time:.2f}ç§’")
                self.update_progress(5)
            else:
                self.log("æµ‹è¯•æ¨¡å¼ï¼šè·³è¿‡æ¨¡å‹åŠ è½½")
                self.update_progress(5)

            # æ­¥éª¤2: åˆ†å‰²è§†é¢‘ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if not self.segments or self.current_segment_index == 0:
                self.log("æ­¥éª¤2: åˆ†å‰²è§†é¢‘...")
                segment_duration = float(self.segment_duration.get())
                split_start = time.time()
                self.segments = self.split_video_by_keyframes(video_path, segment_duration, temp_dirs['base'])
                split_time = time.time() - split_start

                self.total_segments = len(self.segments)
                self.log(f"è§†é¢‘åˆ†å‰²å®Œæˆï¼Œå…±{len(self.segments)}æ®µï¼Œè€—æ—¶: {split_time:.2f}ç§’")
                self.update_progress(10)

                if not self.segments:
                    raise ValueError("è§†é¢‘åˆ†å‰²å¤±è´¥")

                # é‡ç½®è¿›åº¦
                self.current_segment_index = 0
                self.current_frame_in_segment = 0
                self.processed_segments = []
            else:
                self.log(f"æ­¥éª¤2: ä½¿ç”¨å·²æœ‰çš„ {len(self.segments)} ä¸ªç‰‡æ®µ")
                self.update_progress(10)

            # ä¿å­˜åˆå§‹è¿›åº¦
            self.save_progress(force=True)

            # æ­¥éª¤3: é€å¸§å¤„ç†æ¯ä¸ªç‰‡æ®µ
            self.log("æ­¥éª¤3: å¤„ç†è§†é¢‘ç‰‡æ®µ...")

            all_processed_frames = []
            all_audio_paths = []

            total_segment_time = 0
            total_frames_processed = 0

            for i in range(self.current_segment_index, len(self.segments)):
                # æ£€æŸ¥æ˜¯å¦è¢«åœæ­¢
                if self.stopped:
                    self.log(f"å¤„ç†è¢«ç”¨æˆ·åœæ­¢äºç‰‡æ®µ {i + 1}")
                    self.save_progress(force=True)
                    break

                segment = self.segments[i]
                segment_name = os.path.basename(segment)

                # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡
                if segment_name in self.processed_segments:
                    self.log(f"è·³è¿‡å·²å¤„ç†çš„ç‰‡æ®µ {i + 1}/{len(self.segments)}: {segment_name}")
                    self.current_segment_index = i + 1
                    self.current_frame_in_segment = 0
                    continue

                self.log(f"å¤„ç†ç‰‡æ®µ {i + 1}/{len(self.segments)}: {segment_name}")
                segment_start = time.time()
                frame_files, audio_path = self.process_segment_frames(segment, i + 1)
                segment_time = time.time() - segment_start
                total_segment_time += segment_time

                # æ£€æŸ¥æ˜¯å¦è¢«åœæ­¢
                if self.stopped:
                    self.save_progress(force=True)
                    break

                if frame_files and not self.test_mode_var.get():
                    # ç”Ÿæˆå¤„ç†åçš„ç‰‡æ®µè§†é¢‘
                    output_segment = os.path.join(temp_dirs['processed_segments'], f"processed_{segment_name}")

                    # è·å–è§†é¢‘å‚æ•°
                    cap = cv2.VideoCapture(segment)
                    fps = cap.get(cv2.CAP_PROP_FPS)
                    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                    cap.release()

                    # è®¡ç®—è¾“å‡ºå°ºå¯¸
                    scale = int(self.scale_var.get())
                    downsample_threshold = int(self.downsample_threshold.get())
                    short_side = min(height, width)

                    if downsample_threshold != -1 and short_side > downsample_threshold:
                        rescale_factor = short_side / downsample_threshold
                    else:
                        rescale_factor = 1

                    output_width = int(width * scale / rescale_factor)
                    output_height = int(height * scale / rescale_factor)

                    # å°†å¸§è½¬æ¢ä¸ºè§†é¢‘
                    self.frames_to_video(frame_files, output_segment, fps, output_width, output_height, audio_path)

                    # ç«‹å³åˆå¹¶è§†é¢‘ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    if self.immediate_merge_var.get():
                        merged_video = self.immediate_merge_segment(output_segment, i)
                        if merged_video:
                            self.log(f"ç‰‡æ®µ {i + 1} å·²ç«‹å³åˆå¹¶åˆ°æ•´ä½“è§†é¢‘")

                    all_processed_frames.extend(frame_files)
                    if audio_path:
                        all_audio_paths.append(audio_path)
                elif self.test_mode_var.get():
                    self.log(f"æµ‹è¯•æ¨¡å¼ï¼šç‰‡æ®µ {i + 1} å¤„ç†å®Œæˆï¼Œå¸§æ–‡ä»¶å·²ä¿å­˜")

                # æ›´æ–°è¿›åº¦
                self.current_segment_index = i + 1
                self.current_frame_in_segment = 0
                self.processed_segments.append(segment_name)
                self.update_progress_info()

                # ä¿å­˜è¿›åº¦
                self.save_progress(force=True)

                # æ¸…ç†å½“å‰ç‰‡æ®µçš„å¸§ç›®å½•
                self.log(f"æ¸…ç†ç‰‡æ®µ {i + 1} çš„ä¸´æ—¶å¸§æ–‡ä»¶...")
                self.cleanup_segment_frame_dirs(i + 1)

                # æ›´æ–°æ€»ä½“è¿›åº¦
                overall_progress = 10 + (i + 1) / len(self.segments) * 60
                self.update_progress(overall_progress)

                # å¤„ç†å®Œä¸€ä¸ªç‰‡æ®µåæ¸…ç†GPUå†…å­˜
                if not self.test_mode_var.get():
                    torch.cuda.empty_cache()

            if self.stopped:
                self.log(
                    f"å¤„ç†å·²åœæ­¢ï¼Œè¿›åº¦å·²ä¿å­˜äºç‰‡æ®µ {self.current_segment_index} çš„ç¬¬ {self.current_frame_in_segment} å¸§")
                self.save_progress(force=True)
                return False

            # æ­¥éª¤4: å¦‚æœå¤„ç†äº†å¤šä¸ªç‰‡æ®µä¸”ä¸æ˜¯æµ‹è¯•æ¨¡å¼ï¼Œæ‹¼æ¥è§†é¢‘
            if not self.test_mode_var.get():
                # æ£€æŸ¥æ˜¯å¦æœ‰ç«‹å³åˆæˆçš„æœ€ç»ˆè§†é¢‘
                merge_dir = os.path.join(self.temp_base_dir, "06_immediate_merge")
                if self.immediate_merge_var.get() and os.path.exists(merge_dir):
                    # æŸ¥æ‰¾æœ€æ–°çš„åˆå¹¶è§†é¢‘
                    merged_files = []
                    for f in os.listdir(merge_dir):
                        if f.startswith("merged_up_to_") and f.endswith(".mp4"):
                            merged_files.append(os.path.join(merge_dir, f))

                    if merged_files:
                        # æŒ‰æ•°å­—æ’åº
                        merged_files.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))
                        latest_merged = merged_files[-1]

                        # å°†æœ€ç»ˆåˆå¹¶è§†é¢‘ç§»åŠ¨åˆ°è¾“å‡ºç›®å½•
                        output_filename = f"{self.video_base_name}_super_resolved.mp4"
                        final_output = os.path.join(self.output_dir.get(), output_filename)

                        merge_start = time.time()
                        shutil.copy2(latest_merged, final_output)
                        merge_time = time.time() - merge_start

                        self.update_progress(95)
                        self.log(f"ä½¿ç”¨ç«‹å³åˆæˆçš„è§†é¢‘ä½œä¸ºæœ€ç»ˆè¾“å‡º: {final_output}ï¼Œå¤åˆ¶è€—æ—¶: {merge_time:.2f}ç§’")

                        # æ¸…ç†ç«‹å³åˆæˆç›®å½•
                        shutil.rmtree(merge_dir)
                        self.log("å·²æ¸…ç†ç«‹å³åˆæˆç›®å½•")
                    else:
                        # å¦‚æœæ²¡æœ‰ç«‹å³åˆæˆè§†é¢‘ï¼Œåˆ™ä½¿ç”¨ä¼ ç»Ÿæ‹¼æ¥æ–¹å¼
                        self.log("æ­¥éª¤4: æ‹¼æ¥å¤„ç†åçš„è§†é¢‘ç‰‡æ®µ...")
                        processed_segments_paths = []
                        for segment_name in self.processed_segments:
                            processed_path = os.path.join(temp_dirs['processed_segments'], f"processed_{segment_name}")
                            if os.path.exists(processed_path):
                                processed_segments_paths.append(processed_path)

                        if processed_segments_paths:
                            output_filename = f"{self.video_base_name}_super_resolved.mp4"
                            final_output = os.path.join(self.output_dir.get(), output_filename)

                            if len(processed_segments_paths) > 1:
                                self.concatenate_videos(processed_segments_paths, final_output)
                            else:
                                # å¦‚æœåªæœ‰ä¸€ä¸ªç‰‡æ®µï¼Œç›´æ¥å¤åˆ¶
                                copy_start = time.time()
                                shutil.copy2(processed_segments_paths[0], final_output)
                                copy_time = time.time() - copy_start
                                self.log(f"å¤åˆ¶å•ä¸ªç‰‡æ®µï¼Œè€—æ—¶: {copy_time:.2f}ç§’")

                            self.update_progress(95)
                            self.log(f"æœ€ç»ˆè¾“å‡ºæ–‡ä»¶: {final_output}")
                        else:
                            self.log("æ²¡æœ‰å¯æ‹¼æ¥çš„ç‰‡æ®µ")
                else:
                    # ä¼ ç»Ÿæ‹¼æ¥æ–¹å¼
                    self.log("æ­¥éª¤4: æ‹¼æ¥å¤„ç†åçš„è§†é¢‘ç‰‡æ®µ...")
                    processed_segments_paths = []
                    for segment_name in self.processed_segments:
                        processed_path = os.path.join(temp_dirs['processed_segments'], f"processed_{segment_name}")
                        if os.path.exists(processed_path):
                            processed_segments_paths.append(processed_path)

                    if processed_segments_paths:
                        output_filename = f"{self.video_base_name}_super_resolved.mp4"
                        final_output = os.path.join(self.output_dir.get(), output_filename)

                        if len(processed_segments_paths) > 1:
                            self.concatenate_videos(processed_segments_paths, final_output)
                        else:
                            # å¦‚æœåªæœ‰ä¸€ä¸ªç‰‡æ®µï¼Œç›´æ¥å¤åˆ¶
                            copy_start = time.time()
                            shutil.copy2(processed_segments_paths[0], final_output)
                            copy_time = time.time() - copy_start
                            self.log(f"å¤åˆ¶å•ä¸ªç‰‡æ®µï¼Œè€—æ—¶: {copy_time:.2f}ç§’")

                        self.update_progress(95)
                        self.log(f"æœ€ç»ˆè¾“å‡ºæ–‡ä»¶: {final_output}")
                    else:
                        self.log("æ²¡æœ‰å¯æ‹¼æ¥çš„ç‰‡æ®µ")
            else:
                self.log("æµ‹è¯•æ¨¡å¼ï¼šè·³è¿‡è§†é¢‘åˆæˆæ­¥éª¤")
                self.update_progress(95)

            # æ­¥éª¤5: æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œè¿›åº¦è®°å½•
            self.log("æ­¥éª¤5: æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")

            # åˆ é™¤è¿›åº¦æ–‡ä»¶
            if os.path.exists(progress_file):
                os.remove(progress_file)

            self.update_progress(100)

            # è§†é¢‘å¤„ç†å®Œæˆç»Ÿè®¡
            total_video_time = time.time() - video_start_time
            avg_frame_time = total_segment_time / max(total_frames_processed, 1) if total_frames_processed > 0 else 0

            if self.test_mode_var.get():
                self.log(f"æµ‹è¯•æ¨¡å¼å®Œæˆï¼æ€»è€—æ—¶: {total_video_time:.2f}ç§’")
                self.log(f"é‡å¤å¸§æ£€æµ‹ç»Ÿè®¡ï¼šæ€»è®¡æ£€æµ‹åˆ° {self.dup_frame_count} ä¸ªé‡å¤å¸§")
                self.log(f"æµ‹è¯•ç»“æœä¿å­˜åœ¨: {temp_dirs['base']}")
                # æµ‹è¯•æ¨¡å¼ä¸‹ä¸åˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼Œä¾›ç”¨æˆ·æŸ¥çœ‹ç»“æœ
            else:
                self.log(f"å¤„ç†å®Œæˆï¼æ€»è€—æ—¶: {total_video_time:.2f}ç§’")
                self.log(f"è¾“å‡ºæ–‡ä»¶: {self.video_base_name}_super_resolved.mp4")
                if total_frames_processed > 0:
                    self.log(f"å¹³å‡æ¯å¸§å¤„ç†æ—¶é—´: {avg_frame_time:.3f}ç§’")
                # æ˜¾ç¤ºé‡å¤å¸§ç»Ÿè®¡
                if self.enable_dup_detect_var.get():
                    self.log(f"æ€»è®¡æ£€æµ‹åˆ° {self.dup_frame_count} ä¸ªé‡å¤å¸§ï¼Œå·²å¤ç”¨å¤„ç†ç»“æœï¼ŒåŠ é€Ÿäº†å¤„ç†é€Ÿåº¦")

            # é‡ç½®çŠ¶æ€
            self.current_segment_index = 0
            self.current_frame_in_segment = 0
            self.total_segments = 0
            self.segments = []
            self.processed_segments = []
            self.dup_frame_count = 0
            self.update_dup_info(0)

            # æ¸…ç©ºå†å²ç¼“å­˜
            self.frame_history.clear()
            self.frame_hash_history.clear()
            if hasattr(self, 'frame_thumbnail_history'):
                self.frame_thumbnail_history.clear()
            self.frame_sr_history.clear()
            self.frame_idx_history.clear()

            return True

        except Exception as e:
            self.log(f"å¤„ç†è§†é¢‘å¤±è´¥: {str(e)}")
            # ä¿å­˜è¿›åº¦ä»¥ä¾¿æ¢å¤
            self.save_progress(force=True)
            return False

    def process_videos(self):
        """ä¸»å¤„ç†å‡½æ•° - å¤„ç†å¤šä¸ªè§†é¢‘"""
        try:
            # æ£€æŸ¥è¾“å…¥
            if not self.input_paths:
                messagebox.showerror("é”™è¯¯", "è¯·é€‰æ‹©æœ‰æ•ˆçš„è¾“å…¥è§†é¢‘æ–‡ä»¶")
                return

            output_dir = self.output_dir.get()
            if not output_dir:
                messagebox.showerror("é”™è¯¯", "è¯·é€‰æ‹©è¾“å‡ºç›®å½•")
                return

            # éªŒè¯å‚æ•°
            try:
                hash_threshold = int(self.hash_threshold_var.get())
                ssim_threshold = float(self.ssim_threshold_var.get())
                history_size = int(self.history_size_var.get())

                if hash_threshold < 0 or hash_threshold > 10:
                    messagebox.showwarning("è­¦å‘Š", "å“ˆå¸Œç›¸ä¼¼åº¦é˜ˆå€¼å¿…é¡»åœ¨0-10ä¹‹é—´")
                    self.hash_threshold_var.set("3")
                    return

                if ssim_threshold < 0.9 or ssim_threshold > 1.0:
                    messagebox.showwarning("è­¦å‘Š", "SSIMé˜ˆå€¼å¿…é¡»åœ¨0.9-1.0ä¹‹é—´")
                    self.ssim_threshold_var.set("0.98")
                    return

                if history_size < 1 or history_size > 100:
                    messagebox.showwarning("è­¦å‘Š", "å†å²å¸§æ•°é‡å¿…é¡»åœ¨1-100ä¹‹é—´")
                    self.history_size_var.set("20")
                    return
            except ValueError:
                messagebox.showerror("é”™è¯¯", "å‚æ•°æ ¼å¼é”™è¯¯")
                return

            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)

            # æ›´æ–°çŠ¶æ€
            self.processing = True
            self.paused = False
            self.stopped = False
            self.process_btn.config(state='disabled')
            self.pause_btn.config(state='normal')
            self.stop_btn.config(state='normal')
            self.update_status("æ‰¹é‡å¤„ç†ä¸­...", "blue")

            # å¤„ç†æ¯ä¸ªè§†é¢‘
            total_videos = len(self.input_paths)
            for i in range(self.current_video_index, total_videos):
                if self.stopped:
                    break

                self.current_video_index = i
                video_path = self.input_paths[i]

                # æ›´æ–°è¿›åº¦ä¿¡æ¯
                self.progress_info.config(text=f"æ­£åœ¨å¤„ç†è§†é¢‘ {i + 1}/{total_videos}: {os.path.basename(video_path)}")
                self.root.update_idletasks()

                # å¤„ç†å•ä¸ªè§†é¢‘
                success = self.process_single_video(video_path)

                if not success and not self.stopped:
                    # å•ä¸ªè§†é¢‘å¤„ç†å¤±è´¥ï¼Œä½†ç”¨æˆ·æ²¡æœ‰åœæ­¢ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª
                    self.log(f"è§†é¢‘å¤„ç†å¤±è´¥ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªè§†é¢‘")
                    continue

                if self.stopped:
                    break

            if self.stopped:
                self.log(f"æ‰¹é‡å¤„ç†å·²åœæ­¢ï¼Œè¿›åº¦å·²ä¿å­˜")
                self.update_status("å·²åœæ­¢ï¼Œè¿›åº¦å·²ä¿å­˜", "orange")
                return

            # æ‰€æœ‰è§†é¢‘å¤„ç†å®Œæˆ
            if self.test_mode_var.get():
                self.update_status("æµ‹è¯•å®Œæˆï¼", "green")
                messagebox.showinfo("æµ‹è¯•å®Œæˆ",
                                    f"æ‰¹é‡æµ‹è¯•å®Œæˆï¼\n\n"
                                    f"å…±å¤„ç† {total_videos} ä¸ªè§†é¢‘\n"
                                    f"æµ‹è¯•ç»“æœä¿å­˜åœ¨å„è§†é¢‘çš„ä¸´æ—¶ç›®å½•ä¸­")
            else:
                self.update_status("æ‰¹é‡å¤„ç†å®Œæˆï¼", "green")
                messagebox.showinfo("å®Œæˆ",
                                    f"æ‰¹é‡å¤„ç†å®Œæˆï¼\n\n"
                                    f"å…±å¤„ç† {total_videos} ä¸ªè§†é¢‘\n"
                                    f"è¾“å‡ºç›®å½•: {output_dir}")

            # é‡ç½®çŠ¶æ€
            self.current_video_index = 0

        except Exception as e:
            self.log(f"æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}")
            self.update_status(f"å¤„ç†å¤±è´¥: {str(e)}", "red")
            messagebox.showerror("é”™è¯¯", f"å¤„ç†å¤±è´¥: {str(e)}")
            # ä¿å­˜è¿›åº¦ä»¥ä¾¿æ¢å¤
            self.save_progress(force=True)
        finally:
            self.processing = False
            self.paused = False
            self.stopped = False
            self.process_btn.config(state='normal')
            self.pause_btn.config(state='disabled', text="â¸ æš‚åœ")
            self.stop_btn.config(state='disabled')

            # æ¸…ç†GPUå†…å­˜
            if self.generator and not self.test_mode_var.get():
                del self.generator
                torch.cuda.empty_cache()

            # ä¿å­˜é…ç½®
            self.save_config()

    def start_processing(self):
        """å¼€å§‹å¤„ç†"""
        if self.processing:
            return

        # éªŒè¯å‚æ•°
        try:
            scale = int(self.scale_var.get())
            model = self.model_var.get()
            batch_size = int(self.batch_size_var.get())
            history_size = int(self.history_size_var.get())

            if model in ["GRL", "DAT"] and scale != 4:
                messagebox.showwarning("è­¦å‘Š", f"{model}æ¨¡å‹åªæ”¯æŒ4å€ç¼©æ”¾")
                self.scale_var.set("4")
                return

            if scale not in [2, 4]:
                messagebox.showwarning("è­¦å‘Š", "ç¼©æ”¾å› å­å¿…é¡»æ˜¯2æˆ–4")
                return

            if batch_size < 1 or batch_size > 2:
                messagebox.showwarning("è­¦å‘Š", "6GB GPUæ‰¹å¤„ç†å¤§å°å»ºè®®ä¸º1-2")
                self.batch_size_var.set("1")
                return

            if history_size < 1 or history_size > 100:
                messagebox.showwarning("è­¦å‘Š", "å†å²å¸§æ•°é‡å¿…é¡»åœ¨1-100ä¹‹é—´")
                self.history_size_var.set("20")
                return
        except ValueError:
            messagebox.showerror("é”™è¯¯", "å‚æ•°æ ¼å¼é”™è¯¯")
            return

        # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œå¤„ç†
        self.processing_thread = threading.Thread(target=self.process_videos)
        self.processing_thread.daemon = True
        self.processing_thread.start()

    def toggle_pause(self):
        """åˆ‡æ¢æš‚åœ/ç»§ç»­çŠ¶æ€"""
        if not self.processing:
            return

        if self.paused:
            # ç»§ç»­å¤„ç†
            self.paused = False
            self.pause_btn.config(text="â¸ æš‚åœ")
            self.update_status("å¤„ç†ä¸­...", "blue")
            self.log("å¤„ç†ç»§ç»­")

            # é€šçŸ¥æš‚åœçš„çº¿ç¨‹ç»§ç»­
            with self.pause_cv:
                self.pause_cv.notify_all()
        else:
            # æš‚åœå¤„ç†
            self.paused = True
            self.pause_btn.config(text="â–¶ ç»§ç»­")
            self.update_status("å·²æš‚åœ", "orange")
            self.log("å¤„ç†æš‚åœï¼Œä¿å­˜è¿›åº¦...")
            self.save_progress(force=True)

    def stop_processing(self):
        """åœæ­¢å¤„ç†"""
        if not self.processing:
            return

        response = messagebox.askyesnocancel("åœæ­¢å¤„ç†",
                                             "è¯·é€‰æ‹©åœæ­¢æ–¹å¼ï¼š\n\n"
                                             "æ˜¯ï¼šä¿å­˜è¿›åº¦å¹¶åœæ­¢ï¼Œä¸‹æ¬¡å¯ä»¥ç»§ç»­\n"
                                             "å¦ï¼šç›´æ¥åœæ­¢ï¼Œä¸ä¿å­˜è¿›åº¦\n"
                                             "å–æ¶ˆï¼šè¿”å›ç»§ç»­å¤„ç†")

        if response is None:  # å–æ¶ˆ
            return

        if response:  # æ˜¯ï¼šä¿å­˜è¿›åº¦å¹¶åœæ­¢
            self.log("æ­£åœ¨åœæ­¢å¤„ç†å¹¶ä¿å­˜è¿›åº¦...")
            self.update_status("æ­£åœ¨åœæ­¢å¹¶ä¿å­˜è¿›åº¦...", "orange")
            self.stopped = True
            self.paused = False  # ç¡®ä¿æš‚åœçŠ¶æ€è¢«æ¸…é™¤

            # é€šçŸ¥æš‚åœçš„çº¿ç¨‹ç»§ç»­ï¼ˆå¦‚æœæ˜¯æš‚åœçŠ¶æ€ï¼‰
            with self.pause_cv:
                self.pause_cv.notify_all()

            # ç­‰å¾…å¤„ç†çº¿ç¨‹å“åº”
            time.sleep(0.5)

            # å¼ºåˆ¶ä¿å­˜è¿›åº¦
            self.save_progress(force=True)

            # ç­‰å¾…å¤„ç†çº¿ç¨‹ç»“æŸ
            if self.processing_thread and self.processing_thread.is_alive():
                self.processing_thread.join(timeout=2.0)

            self.log("å¤„ç†å·²åœæ­¢ï¼Œè¿›åº¦å·²ä¿å­˜")
            self.update_status("å·²åœæ­¢ï¼Œè¿›åº¦å·²ä¿å­˜", "orange")

        else:  # å¦ï¼šç›´æ¥åœæ­¢ï¼Œä¸ä¿å­˜è¿›åº¦
            self.log("æ­£åœ¨åœæ­¢å¤„ç†ï¼Œä¸ä¿å­˜è¿›åº¦...")
            self.update_status("æ­£åœ¨åœæ­¢...", "orange")
            self.stopped = True
            self.paused = False  # ç¡®ä¿æš‚åœçŠ¶æ€è¢«æ¸…é™¤

            # é€šçŸ¥æš‚åœçš„çº¿ç¨‹ç»§ç»­ï¼ˆå¦‚æœæ˜¯æš‚åœçŠ¶æ€ï¼‰
            with self.pause_cv:
                self.pause_cv.notify_all()

            # ç­‰å¾…å¤„ç†çº¿ç¨‹å“åº”
            time.sleep(0.5)

            # åˆ é™¤è¿›åº¦æ–‡ä»¶
            if self.temp_base_dir:
                progress_file = os.path.join(self.temp_base_dir, "progress_data.pkl")
                if os.path.exists(progress_file):
                    try:
                        os.remove(progress_file)
                        self.log("å·²åˆ é™¤è¿›åº¦æ–‡ä»¶")
                    except:
                        pass

            # ç­‰å¾…å¤„ç†çº¿ç¨‹ç»“æŸ
            if self.processing_thread and self.processing_thread.is_alive():
                self.processing_thread.join(timeout=2.0)

            self.log("å¤„ç†å·²åœæ­¢ï¼Œè¿›åº¦æœªä¿å­˜")
            self.update_status("å·²åœæ­¢ï¼Œè¿›åº¦æœªä¿å­˜", "orange")

            # é‡ç½®è¿›åº¦
            self.current_video_index = 0
            self.current_segment_index = 0
            self.current_frame_in_segment = 0
            self.dup_frame_count = 0
            self.update_dup_info(0)

        # é‡ç½®æŒ‰é’®çŠ¶æ€
        self.process_btn.config(state='normal')
        self.pause_btn.config(state='disabled', text="â¸ æš‚åœ")
        self.stop_btn.config(state='disabled')
        self.paused = False
        self.processing = False

    def run(self):
        """è¿è¡ŒGUI"""
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)

        # å±…ä¸­æ˜¾ç¤ºçª—å£
        self.root.update_idletasks()
        width = self.root.winfo_width()
        height = self.root.winfo_height()
        x = (self.root.winfo_screenwidth() // 2) - (width // 2)
        y = (self.root.winfo_screenheight() // 2) - (height // 2)
        self.root.geometry(f'{width}x{height}+{x}+{y}')

        self.root.mainloop()

    def on_closing(self):
        """å…³é—­çª—å£æ—¶çš„æ¸…ç†"""
        # ä¿å­˜é…ç½®
        self.save_config()

        if self.processing:
            response = messagebox.askyesnocancel("é€€å‡º",
                                                 "å¤„ç†ä»åœ¨è¿›è¡Œä¸­ï¼Œæ‚¨å¯ä»¥é€‰æ‹©:\n\n"
                                                 "æ˜¯: ä¿å­˜è¿›åº¦å¹¶é€€å‡º\n"
                                                 "å¦: ä¸ä¿å­˜è¿›åº¦ç›´æ¥é€€å‡º\n"
                                                 "å–æ¶ˆ: ç»§ç»­å¤„ç†")

            if response is True:  # ä¿å­˜è¿›åº¦å¹¶é€€å‡º
                self.log("ä¿å­˜è¿›åº¦å¹¶é€€å‡º...")
                self.save_progress(force=True)
                self.processing = False
                self.stopped = True
                self.paused = False

                # é€šçŸ¥æš‚åœçš„çº¿ç¨‹ç»§ç»­ï¼ˆå¦‚æœæ˜¯æš‚åœçŠ¶æ€ï¼‰
                with self.pause_cv:
                    self.pause_cv.notify_all()

                time.sleep(1.0)  # ç»™çº¿ç¨‹æ›´å¤šæ—¶é—´å“åº”
                self.root.destroy()
            elif response is False:  # ç›´æ¥é€€å‡º
                self.log("ç›´æ¥é€€å‡ºï¼Œä¸ä¿å­˜è¿›åº¦")
                self.processing = False
                self.stopped = True
                self.paused = False

                # é€šçŸ¥æš‚åœçš„çº¿ç¨‹ç»§ç»­ï¼ˆå¦‚æœæ˜¯æš‚åœçŠ¶æ€ï¼‰
                with self.pause_cv:
                    self.pause_cv.notify_all()

                time.sleep(1.0)  # ç»™çº¿ç¨‹æ›´å¤šæ—¶é—´å“åº”
                self.root.destroy()
            # å¦‚æœé€‰æ‹©å–æ¶ˆï¼Œä»€ä¹ˆéƒ½ä¸åšï¼Œç»§ç»­å¤„ç†
        else:
            self.root.destroy()


def main():
    """ä¸»å‡½æ•°"""
    app = APISRVideoProcessor()
    app.run()


if __name__ == "__main__":
    main()